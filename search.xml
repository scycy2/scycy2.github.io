<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>3.31æºç¨‹åç«¯ï¼ˆå‡‰ï¼‰é¢ç»</title>
      <link href="2022/03/31/3-31%E6%90%BA%E7%A8%8B%E5%90%8E%E7%AB%AF%EF%BC%88%E5%87%89%EF%BC%89%E9%9D%A2%E7%BB%8F/"/>
      <url>2022/03/31/3-31%E6%90%BA%E7%A8%8B%E5%90%8E%E7%AB%AF%EF%BC%88%E5%87%89%EF%BC%89%E9%9D%A2%E7%BB%8F/</url>
      
        <content type="html"><![CDATA[<p>ç¬¬ä¸€æ¬¡æ‰¾å·¥ä½œé¢è¯•ï¼Œå‡‰é€ã€‚ã€‚ã€‚æ„æ–™ä¹‹ä¸­</p><p>3.23é€šçŸ¥ç¬”è¯•ï¼Œ3.24ç¬”è¯•ï¼Œå››é“ç®—æ³•é¢˜ï¼Œaäº†ä¸¤é¢˜å¤š</p><p>3.30é€šçŸ¥é¢è¯•ï¼Œé¢„çº¦é¢è¯•æ—¶é—´åªå‰©3.31äº†ğŸ˜­ï¼Œå› ä¸ºå­¦æ ¡ä½œä¸šå¤šï¼Œæ‰€ä»¥åªå‡†å¤‡äº†ä¸€å¤©ï¼ŒèƒŒäº†ä¸€å †å…«è‚¡æ–‡ï¼Œç»“æœä¸€ç‚¹æ²¡ç”¨ä¸Šã€‚ã€‚ã€‚</p><p>é¢è¯•å®˜è¿›æ¥å…ˆçœ‹äº†æˆ‘ç®€å†ï¼Œä¼°è®¡å‘ç°æˆ‘åšçš„é¡¹ç›®å’ŒæŠ•é€’çš„å²—ä½æ²¡å•¥å…³ç³»ï¼Œç›´æ¥è¯´æˆ‘è¿™é‡Œé¢è¯•æ˜¯ä¸¤é“ç¼–ç¨‹é¢˜ã€‚ã€‚ã€‚</p><h5 id="1-HashMap"><a href="#1-HashMap" class="headerlink" title="1. HashMap"></a>1. HashMap</h5><p>å…ˆé—®æˆ‘å¯¹HashMapæœ‰æ²¡æœ‰äº†è§£ï¼Œæˆ‘è¯´è¿™ä¸ªçœ‹è¿‡ï¼Œç„¶åè¯´äº†ä¸€ç‚¹åº•å±‚å®ç°åŸç†ï¼ŒåŒ…æ‹¬å¦‚ä½•è§£å†³å“ˆå¸Œå†²çªå•¥çš„ï¼Œä¹Ÿè¯´åˆ°äº†å½“é“¾è¡¨é•¿åº¦è¶…è¿‡8æ—¶ä¼šè½¬æˆçº¢é»‘æ ‘ï¼Œé¢è¯•å®˜å¥½åƒè¿˜æŒºæƒŠè®¶ï¼Œè¯´ç«Ÿç„¶çœ‹è¿‡æºç ï¼Œç„¶åå°±è®©æˆ‘å®ç°HashMapï¼Œåªè¦getå’Œputæ–¹æ³•ã€‚ä¸€åˆ°è‡ªå·±ä¸Šæ‰‹å°±å¯„ï¼ŒHashMapæ˜¯å¤§ä¸‰æ—¶å­¦çš„ï¼Œå½“æ—¶ä¹Ÿè‡ªå·±å®ç°è¿‡ï¼Œä½†æ˜¯é¢è¯•ä¸€ç‚¹æ²¡æƒ³èµ·æ¥ï¼Œæœ€åå†™äº†ä¸ªè´¼æ‹‰å®çš„ä»£ç ï¼Œæ²¡è§£å†³å“ˆå¸Œå†²çªã€‚ã€‚ã€‚å­”å­æ›°ï¼šå­¦è€Œæ—¶ä¹ ä¹‹ã€‚å¤ªæœ‰é“ç†äº†ï¼ï¼ï¼</p><p>ä¸‹é¢æ˜¯æˆ‘é¢è¯•ç»“æŸåå¤ä¹ äº†ä¸€ä¸‹è¯¾ä»¶ï¼Œé‡æ–°å†™äº†ä¸€éçš„ä»£ç </p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyHashMap</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MAX_LEN <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> List<span class="token operator">&lt;</span>Pair<span class="token operator">&lt;</span>Integer<span class="token punctuation">,</span> String<span class="token operator">>></span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token punctuation">[</span>MAX_LEN<span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">MyHashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>i <span class="token operator">&lt;</span> arr<span class="token punctuation">.</span>length<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">int</span> key<span class="token punctuation">,</span> String value<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> k <span class="token operator">=</span> <span class="token function">calHash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> pos <span class="token operator">=</span> <span class="token function">getPos</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>pos <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Pair</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Pair</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> String <span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">int</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> k <span class="token operator">=</span> <span class="token function">calHash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> null<span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>key <span class="token operator">==</span> arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token keyword">return</span> arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> null<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPos</span><span class="token punctuation">(</span><span class="token keyword">int</span> key<span class="token punctuation">,</span> String value<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> k <span class="token operator">=</span> <span class="token function">calHash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>arr<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token keyword">return</span> i<span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">calHash</span><span class="token punctuation">(</span><span class="token keyword">int</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> key <span class="token operator">%</span> MAX_LEN<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="2-å¤šçº¿ç¨‹"><a href="#2-å¤šçº¿ç¨‹" class="headerlink" title="2. å¤šçº¿ç¨‹"></a>2. å¤šçº¿ç¨‹</h5><p>å…ˆé—®æˆ‘æœ‰æ²¡æœ‰äº†è§£è¿‡javaä¸­çº¿ç¨‹æ± æ€ä¹ˆä½¿ç”¨ï¼Œæ˜¾ç„¶æ²¡æœ‰ï¼Œæ ¹æœ¬å°±æ²¡åšè¿‡javaçš„é¡¹ç›®ã€‚ã€‚ã€‚</p><p>ç„¶åå°±é—®äº†æ€ä¹ˆç”¨å¤šçº¿ç¨‹å®ç°æ‰“å°ä¸€ä¸ªæ•°ç»„ï¼Œåœ¨æ‰“å°å®Œæˆåè¾“å‡ºæ‰“å°å®Œæˆã€‚ã€‚ã€‚æ˜¾ç„¶æˆ‘ä¹Ÿä¸ä¼šï¼Œç›´æ¥å’Œé¢è¯•å®˜è¯´äº†ã€‚ã€‚ã€‚åˆé—®æˆ‘gcçŸ¥ä¸çŸ¥é“ï¼Œä¹Ÿæ˜¯ä¸ä¼šğŸ¤¦â€â™‚ï¸é¢è¯•å®˜ç›´æ¥è¯´æ„Ÿè§‰å‡†å¤‡ä¸å……åˆ†ï¼ˆggï¼‰</p><p>é¢è¯•åçœ‹äº†å¥½ä¹…å¤šçº¿ç¨‹ï¼Œå†™äº†ä»¥ä¸‹ä»£ç ï¼Œä¸çŸ¥é“å¯¹é”™</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Main</span> <span class="token punctuation">{</span>    <span class="token keyword">static</span> <span class="token keyword">volatile</span> <span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">int</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">final</span> CountDownLatch latch <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">CountDownLatch</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> arr<span class="token punctuation">.</span>length<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>            arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> i<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Thread1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">synchronized</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>i<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>                latch<span class="token punctuation">.</span><span class="token function">countDown</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Thread2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">synchronized</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>i<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>                latch<span class="token punctuation">.</span><span class="token function">countDown</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            latch<span class="token punctuation">.</span><span class="token function">await</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">InterruptedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"æ‰“å°ç»“æŸ"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="3-ç»å…¸TopKé—®é¢˜"><a href="#3-ç»å…¸TopKé—®é¢˜" class="headerlink" title="3. ç»å…¸TopKé—®é¢˜"></a>3. ç»å…¸TopKé—®é¢˜</h5><p>æ€»æ„Ÿè§‰Leetcodeä¸Šçœ‹è§è¿‡ï¼Œä½†å°±æ˜¯æ²¡åˆ·è¿‡ã€‚ã€‚ã€‚</p><p>é—®äº†ä»¥åç›´æ¥æ‡µäº†ï¼Œæ²¡æ€è·¯ï¼ˆè¿˜æ˜¯é¢˜åˆ·çš„ä¸å¤Ÿå¤šï¼‰ã€‚ã€‚ã€‚é¢è¯•å®˜ä¸€ç›´æé†’æˆ‘è¯´ç”¨å †ï¼Œæˆ‘ä»¥ä¸ºæŠŠæ•°ç»„å»ºå †ï¼Œæ¯æ¬¡å–æ ¹èŠ‚ç‚¹ï¼Œå†è°ƒæ•´å †ã€‚ã€‚ã€‚ç„¶åä»–é—®äº†ä¸‹ç®—æ³•å¤æ‚åº¦ï¼Œæˆ‘è¯´æ˜¯$O(n\log (n))$ï¼Œç¡®å®ç®—æ³•å¤æ‚åº¦å’Œå¿«æ’æ²¡åŒºåˆ«ã€‚ã€‚é¢è¯•ç»“æŸåæŸ¥äº†æ‰çŸ¥é“ï¼Œå…ˆå°†æ•°ç»„å‰kä¸ªå€¼å»ºå †ï¼Œå†æ˜¯åé¢çš„å…ƒç´ ä¾æ¬¡å’Œå †é¡¶å…ƒç´ æ¯”è¾ƒï¼Œè¿™æ ·ç®—æ³•å¤æ‚åº¦æ˜¯$O(n\log(k))$ã€‚ã€‚ã€‚è¿‡æ®µæ—¶é—´å»åšä¸‹è¿™ä¸ªé¢˜ï¼Œå†é™„ä¸Šä»£ç </p><p>4æœˆ3æ—¥æ›´æ–°ï¼Œä»Šå¤©åšäº†ä¸€ä¸‹TopKé—®é¢˜ï¼Œæœ‰æ€è·¯ä»¥åå…¶å®ä¸éš¾ï¼Œä»£ç æ ¸å¿ƒè¿˜æ˜¯è°ƒæ•´å †çš„ä»£ç </p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TopK</span><span class="token punctuation">{</span>      <span class="token comment" spellcheck="true">//ç‰›å®¢ä¸Šè¿™é“é¢˜çš„è¾“å…¥è¾“å‡º</span>      <span class="token keyword">public</span> ArrayList<span class="token operator">&lt;</span>Integer<span class="token operator">></span> <span class="token function">GetLeastNumbers_Solution</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> input<span class="token punctuation">,</span> <span class="token keyword">int</span> k<span class="token punctuation">)</span> <span class="token punctuation">{</span>        ArrayList<span class="token operator">&lt;</span>Integer<span class="token operator">></span> ans <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>k <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> ans<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>k <span class="token operator">>=</span> input<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> input<span class="token punctuation">.</span>length<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>                ans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>input<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">return</span> ans<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> ks <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">int</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> k<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            ks<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> input<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token punctuation">(</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span> i <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">--</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token function">adjustHeap</span><span class="token punctuation">(</span>ks<span class="token punctuation">,</span> i<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> k<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> input<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>input<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;</span> ks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                ks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> input<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token function">adjustHeap</span><span class="token punctuation">(</span>ks<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> k<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>            ans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>ks<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> ans<span class="token punctuation">;</span>    <span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">//æ ¸å¿ƒä»£ç ï¼Œå’Œå †æ’ä¸€æ ·ï¼Œæ ¹æ®é—®é¢˜å»å»ºç«‹æœ€å¤§å †æˆ–è€…æœ€å°å †</span>      <span class="token comment" spellcheck="true">//è¿™é‡Œæ˜¯å»ºç«‹æœ€å¤§å †ï¼Œå› ä¸ºè¦å–å‰kä¸ªæœ€å°å€¼ï¼Œæ¯æ¬¡æŠŠå †é¡¶å³æœ€å¤§å€¼å’Œæ•°ç»„æ¥ä¸‹æ¥çš„å€¼æ¯”è¾ƒï¼Œæ¯”å †é¡¶å…ƒç´ å°çš„å€¼å°±å’Œå †é¡¶å…ƒç´ äº¤æ¢</span>      <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">adjustHeap</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">,</span> <span class="token keyword">int</span> parent<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>parent<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> leftnode <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>parent <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>leftnode <span class="token operator">&lt;</span> length<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">int</span> rightnode <span class="token operator">=</span> leftnode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>rightnode <span class="token operator">&lt;</span> length <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>rightnode<span class="token punctuation">]</span> <span class="token operator">></span> nums<span class="token punctuation">[</span>leftnode<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                leftnode<span class="token operator">++</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>temp <span class="token operator">>=</span> nums<span class="token punctuation">[</span>leftnode<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            nums<span class="token punctuation">[</span>parent<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>leftnode<span class="token punctuation">]</span><span class="token punctuation">;</span>            parent <span class="token operator">=</span> leftnode<span class="token punctuation">;</span>            leftnode <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>parent <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        nums<span class="token punctuation">[</span>parent<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="4-æ€»ç»“"><a href="#4-æ€»ç»“" class="headerlink" title="4. æ€»ç»“"></a>4. æ€»ç»“</h5><p>å°±æ˜¯é€å¿ƒå‡‰ï¼Œè¢«è™æ€çš„æ„Ÿè§‰ã€‚ã€‚è¿˜æ˜¯å¤ªèœï¼Œåç«¯çŸ¥è¯†ç‚¹ç¡®å®ä¹Ÿå¤šï¼Œè¿˜æœ‰ä¸€å †æ²¡é¢„ä¹ è¿‡hhh</p><p>ä¸ç®¡æ€ä¹ˆè¯´ï¼Œä¹Ÿç®—æ˜¯ç§¯ç´¯äº†ä¸€å®šçš„ç»éªŒï¼Œä¹Ÿæ˜¯å¾ˆæœ‰æ„ä¹‰çš„ä¸€æ¬¡é¢è¯•ï¼Œæ¯•ç«Ÿç¬¬ä¸€æ¬¡æ‰¾å·¥é¢è¯•å°±ç›´æ¥ç¼–ç¨‹é¢˜ã€‚ã€‚ã€‚</p><p>æœ€åæˆ‘å’Œé¢è¯•å®˜è§£é‡Šäº†ä¸€ä¸‹ï¼Œè¯´æˆ‘æŠ•é”™å²—ä½äº†ï¼ŒæŠ•æˆæ˜¥æ‹›å…¨èŒäº†ã€‚ã€‚ã€‚æˆ‘è¯´æˆ‘9æœˆä»½è¿˜è¦å»HKUè¯»ç ”ç©¶ç”Ÿï¼Œé¢è¯•å®˜ä¹Ÿæ˜¯æ­å–œæˆ‘ğŸ¤¦â€â™‚ï¸ã€‚</p><p>æœ€åæˆ‘é—®äº†ä¸€ä¸‹ä»€ä¹ˆæ—¶å€™å‡ºç»“æœï¼Œä»–è¯´å¤§æ¦‚ä¸€å‘¨åï¼Œæˆ‘è¯´ä¼°è®¡æ˜¯æ²¡äº†ï¼Œä»–å°±ç¬‘ç¬‘ã€‚ã€‚ã€‚é‚£å°±æ˜¯çœŸçš„æ²¡äº†</p><p>æœ€åçš„æœ€åï¼šä¸ç§¯è·¬æ­¥ï¼Œæ— ä»¥è‡³åƒé‡Œï¼›ä¸ç§¯å°æµï¼Œæ— ä»¥æˆæ±Ÿæµ·ã€‚â€”â€”ã€Šè€å­ã€‹</p>]]></content>
      
      
      <categories>
          
          <category> è‡ªè¨€è‡ªè¯­ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> é¢ç» </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convolutional Neural Networks</title>
      <link href="2021/10/24/Convolutional-Neural-Networks/"/>
      <url>2021/10/24/Convolutional-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Edge-Detection"><a href="#1-Edge-Detection" class="headerlink" title="1. Edge Detection"></a>1. Edge Detection</h4><ul><li><p>Vertical Edge Detection</p><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 4.36.38 PM.png" style="zoom:50%;"></li><li><p>Vertical and Horizontal Edge Detection</p><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 4.38.54 PM.png" style="zoom:50%;"><ul><li>By using different filter kernel.</li></ul></li></ul><h4 id="2-Padding"><a href="#2-Padding" class="headerlink" title="2. Padding"></a>2. Padding</h4><ul><li>If there is no padding:<ul><li>shrink output</li><li>throw away info from edge</li></ul></li><li><strong>Zero-Padding</strong></li></ul><img src="/2021/10/24/Convolutional-Neural-Networks/apple/Desktop/selfstudy/CNN/pics/Screen Shot 2021-10-24 at 4.41.20 PM.png" style="zoom:50%;"><ul><li>Suppose input image is $n\times n$, filter is $f\times f$, padding is $p$, then the output is $(n+2p-f+1)\times (n+2p-f+1)$</li><li><strong>Valid and Same convolutions</strong><ul><li><strong>Valid</strong>: no padding, output $(n-f+1)*(n-f+1)$</li><li><strong>Same</strong>: Pad so that output size is the same as the input size<ul><li>$n+2p-f+1=n \Rightarrow p=\frac{f-1}{2}$</li><li>$f$ is usually odd</li></ul></li></ul></li></ul><h4 id="3-Strided-convolutions"><a href="#3-Strided-convolutions" class="headerlink" title="3. Strided convolutions"></a>3. Strided convolutions</h4><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 4.48.50 PM.png" style="zoom:50%;"><ul><li><p>$n\times n$ * $f\times f$</p><p>padding $p$, stride $s$</p><p>Output size: $\lfloor\frac{n+2p-f}{s}+1\rfloor \times \lfloor\frac{n+2p-f}{s}+1\rfloor$</p></li></ul><h4 id="4-Convolutions-over-volumes"><a href="#4-Convolutions-over-volumes" class="headerlink" title="4. Convolutions over volumes"></a>4. Convolutions over volumes</h4><ul><li><p>Convolutions on RGB images</p><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 4.54.49 PM.png" style="zoom:50%;"><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 4.57.05 PM.png" style="zoom:50%;"></li><li><p>Summary:</p><p>$n\times n \times n_c$ * $f\times f \times n_c$ $\Rightarrow$ $(n-f+1) \times (n-f+1) \times n_câ€™$</p><p>where $n_câ€™$ is the number of filters</p></li></ul><h4 id="5-One-layer-of-a-convolutional-network"><a href="#5-One-layer-of-a-convolutional-network" class="headerlink" title="5. One layer of a convolutional network"></a>5. One layer of a convolutional network</h4><ul><li><p>one example:</p><p>input image $n\times n \times C$ $\rightarrow$ 10 filters $\rightarrow$ Relu(convolutional output $\lfloor\frac{n+2p-f}{s}+1\rfloor \times \lfloor\frac{n+2p-f}{s}+1\rfloor \times n_câ€™$ + bias $b$)</p><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 5.20.02 PM.png" style="zoom:50%;"></li><li><p>Number of parameters in one layer</p><p>If you have 10 filters that are 3 x 3 x 3 in one layer of a neural network, how many parameters does that layer have?</p><img src="/2021/10/24/Convolutional-Neural-Networks/Screen Shot 2021-10-24 at 5.21.12 PM.png" style="zoom:50%;"></li><li><p>Summary of notation</p><p>If layer $l$ is a convolution layer:</p><p>$f^{[l]} = \text{filter size}$<br>$p^{[l]} = \text{padding}$<br>$s^{[l]} = \text{stride}$<br>$n_c^{[l]} = \text{number of filters}$<br>$\text{Each filter is: } f^{[l]} \times f^{[l]} \times n_c^{[l-1]}$<br>$\text{Activations: } a^{[l]} \rightarrow n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$<br>$\text{Weights: } f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \times n_c^{[l]}$<br>$\text{bias: } (1,1,1,n_c^{[l]})$<br>$\text{Input: } n_H^{[l-1]} \times n_W^{[l-1]}\times n_c^{[l-1]}$<br>$\text{Output: } n_H^{[l-1]} \times n_W^{[l-1]}\times n_c^{[l]}$</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gossip</title>
      <link href="2021/10/05/Gossip/"/>
      <url>2021/10/05/Gossip/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Multicast-Problem"><a href="#1-Multicast-Problem" class="headerlink" title="1. Multicast Problem"></a>1. Multicast Problem</h4><ul><li><p>Multicast</p><img src="/2021/10/05/Gossip/Screen Shot 2021-10-05 at 12.06.15 PM.png" style="zoom:50%;"></li><li><p>Fault-Tolerance and Scalability</p><img src="/2021/10/05/Gossip/Screen Shot 2021-10-05 at 12.12.36 PM.png" style="zoom:50%;"><ul><li>The protocal that is executed at the individual nodes, as well as the senders, what is known as the multicast protocol.</li><li>The multicast protocal typically sits at the application level, meaning that is does not deal with the underlying network. IP multicast is whatâ€™s available in the underlying network, typically this is implemented in routers and switches.</li></ul></li><li><p>Centralized</p><img src="/2021/10/05/Gossip/Screen Shot 2021-10-05 at 12.18.26 PM.png" style="zoom:50%;"><ul><li>Problem 1: when it comes to fault tolerance, if the sender fails when itâ€™s halfway through its for loop, essentially, only half the receivers would have received the multicast.</li><li>Problem 2: the overhead on the sender is very high. Imagine a group where you have thousands of nodes in the group, and the sender has to send a lot of messages (increases the latency). The average time of for a reveiver to receive a multicast could be as high as $O(N)$.</li></ul></li><li><p>Tree-based</p><img src="/2021/10/05/Gossip/Screen Shot 2021-10-05 at 12.25.08 PM.png" style="zoom:50%;"><ul><li>Protocols develop a spanning tree among the nodes or the processes in the group.</li><li>The latency for a message to reach any of the nodes in the group is $O(\log (N))$.</li><li>The overhead on each member in the group, both the sender and any of the receivers, is constant especially if the number of children is constant.</li><li>Problem 1: set up and maintain the tree. When load failures happen, the nodes in the system might actually not receive multicast for a while. </li><li>Use either acknowledgments (ACKs) or negative acknowledgments (NAKs) to repair multicasts not received.</li><li>SRM (Scalable Reliable Multicast)<ul><li>Uses NAKs</li><li>But adds random delays, and uses exponential backoff to avoid NAK storms</li></ul></li><li>RMTP (Reliable Multicast Transport Protocol)<ul><li>Uses ACKs</li><li>But ACKs only sent to designated receivers, which then re-transmit missing multicasts</li></ul></li><li>These protocols still cause an $O(N)$ ACK/NCK overhead</li></ul></li></ul><h4 id="2-The-Gossip-Protocol"><a href="#2-The-Gossip-Protocol" class="headerlink" title="2. The Gossip Protocol"></a>2. The Gossip Protocol</h4>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloud Computing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compiler</title>
      <link href="2021/10/02/Compiler/"/>
      <url>2021/10/02/Compiler/</url>
      
        <content type="html"><![CDATA[<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="1-1-What-is-a-Compiler"><a href="#1-1-What-is-a-Compiler" class="headerlink" title="1.1 What is a Compiler?"></a>1.1 What is a Compiler?</h4><ul><li><p>Compilers are <strong>program translators</strong>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-09-23 at 10.43.33 AM.png" style="zoom:50%;"></li><li><p>To make it easier for human beings to write programs.</p></li></ul><h4 id="1-2-Source-and-Target-Languages"><a href="#1-2-Source-and-Target-Languages" class="headerlink" title="1.2 Source and Target Languages"></a>1.2 Source and Target Languages</h4><ul><li>Large spectrum of possibilities, for example:<ul><li>Source languages:<ul><li>(High-level) programming languages</li><li>Modelling languages</li><li>Document Markup languages</li><li>Database query languages</li></ul></li><li>Target languages:<ul><li>High-level programming language</li><li>Low-level programming language (assembly or machine code, byte code)</li></ul></li></ul></li></ul><h4 id="1-3-Compilers-vs-Interpreters"><a href="#1-3-Compilers-vs-Interpreters" class="headerlink" title="1.3 Compilers vs. Interpreters"></a>1.3 Compilers vs. Interpreters</h4><p><strong>Intepreters</strong> are another class of translators:</p><ul><li>Compiler: translates a program once for all into target language.</li><li>Interpreter: effectively translates (the used parts of) a source program, on the fly, every time it is run.</li><li>Techniques such as <strong>Just-In-Time Compilation</strong> (JIT) blur this distinction.</li><li>Compilers and interpreters are sometimes used together, e.g., in Java:<ul><li>Java is first complied into Java byte code;</li><li>Then, the byte code is interpreted by a Java Virtual Machine (JVM).</li><li>JVM might use JIT.</li></ul></li></ul><h4 id="1-4-Inside-the-Compiler"><a href="#1-4-Inside-the-Compiler" class="headerlink" title="1.4 Inside the Compiler"></a>1.4 Inside the Compiler</h4><ul><li><p>A compiler is usually composed of several components, such as:</p><ul><li><strong>Scanner</strong>: lexical analysis</li><li><strong>Parser</strong>: syntactic analysis</li><li><strong>Checker</strong>: contextual analysis (e.g. type checking)</li><li><strong>Optimizer</strong>: code improvement</li><li><strong>Code generator</strong></li></ul></li><li><img src="/2021/10/02/Compiler/Screen Shot 2021-09-23 at 11.01.40 AM.png" style="zoom:50%;"></li><li><p>The aim of lexical analysis is to:</p><ul><li>verify that the input character sequence is lexically valid.</li><li>group characters into sequence of lexical symbols, i.e., <strong>tokens</strong>.</li><li>discard white space and comments (typically).</li></ul></li><li><p>The purpose of syntactic analysis/parsing is to:</p><ul><li>verify that the input program is syntactically valid, i.e., conforms to the <strong>Context Free Grammer</strong> of the language.</li><li>determine the program structure.</li><li>construct a representation of the program reflecting that structure without unnecessary details, usually an <strong>Abstract Syntax Tree</strong> (AST).</li></ul></li><li><p>Contexttual Analysis/Checking Static Semantics:</p><ul><li>Resolve meaning of symbols.</li><li>Report undefined symbols.</li><li>Type checking.</li></ul></li><li><p>Optimization:</p><ul><li>Making the generated code run faster, use less space, energy, etc.</li><li>Almost always <strong>heuristic</strong>: cannot <strong>guarantee</strong> optimal result.</li></ul></li><li><p>Code Generation:</p><ul><li>Output the appropriate sequence of target language instructions.</li><li>Might involve further <strong>low-level</strong> (target-specific) optimization.</li></ul></li></ul><h3 id="2-Defining-Programming-Languages"><a href="#2-Defining-Programming-Languages" class="headerlink" title="2. Defining Programming Languages"></a>2. Defining Programming Languages</h3><h4 id="2-1-Syntax-and-Semantics"><a href="#2-1-Syntax-and-Semantics" class="headerlink" title="2.1 Syntax and Semantics"></a>2.1 Syntax and Semantics</h4><ul><li>Notions of <strong>Syntax</strong> and <strong>Semantics</strong> are central to languages.</li><li>In fact, they have their origins in mathematical logic.</li></ul><h5 id="2-1-1-Syntax-the-form-of-programs"><a href="#2-1-1-Syntax-the-form-of-programs" class="headerlink" title="2.1.1 Syntax: the form of programs"></a>2.1.1 Syntax: the form of programs</h5><ul><li><strong>Concrete Syntax</strong> (or Surface Syntax): What program â€œlook likeâ€<ul><li>Usually <strong>strings</strong> of characters or symbols.</li><li>Some languages have <em>graphical</em> syntax</li></ul></li><li><strong>Abstract Syntax</strong>: A <strong>tree</strong> representing the essential structure of a syntactically valid program.</li></ul><h5 id="2-1-2-Semantics-the-meaning-of-a-program"><a href="#2-1-2-Semantics-the-meaning-of-a-program" class="headerlink" title="2.1.2 Semantics: the meaning of a program"></a>2.1.2 Semantics: the meaning of a program</h5><ul><li><strong>Static Semantics</strong>:<ul><li>Refers to the meaning of (a fragment of) a program, as may be infered at <strong>compile-time</strong>.</li><li>Typically, aspects related to scope and type.</li></ul></li><li><strong>Dynamic Semantics</strong>:<ul><li>What (a fragment of) a program means when executed.</li><li>Hence, the meaning as referred at <strong>run-time</strong>, rather than compile-time.</li><li>For example, what a fragment of a program:<ul><li><em>evaluates</em> to, if it is an expression.</li><li><em>does</em>, if it is a set of instructions.</li></ul></li></ul></li></ul><h4 id="2-2-Defining-Programming-Languages"><a href="#2-2-Defining-Programming-Languages" class="headerlink" title="2.2 Defining Programming Languages"></a>2.2 Defining Programming Languages</h4><h5 id="2-2-1"><a href="#2-2-1" class="headerlink" title="2.2.1"></a>2.2.1</h5><ul><li>In order to develop a compiler:<ul><li>the <strong>Source</strong> and <strong>Target</strong> languages must be defined<ul><li>syntax</li><li>semantics</li></ul></li></ul></li><li>In theory, to avoid inaccuracies, language definitions must be fully formalized.</li><li>In practice, language <strong>specifications</strong> are presented using a mixture of <strong>formal</strong> or <strong>informal</strong> descriptions, to make it easier for human readers.</li></ul><h5 id="2-2-2"><a href="#2-2-2" class="headerlink" title="2.2.2"></a>2.2.2</h5><p>Why is it important to define the source and target languages precisely?</p><ul><li>The <strong>source language syntax</strong> must be known to design the <strong>scanner</strong> and <strong>parser</strong> properly</li><li>The <strong>target language syntax</strong> must be known to generate <strong>syntactically correct target code</strong></li><li>The <strong>semantics</strong> of source and target languages must be known to ensure that the translation <strong>preserves the meaning</strong> of source programs, i.e., <strong>compiler correctness</strong>.<ul><li><strong>compiler correctness is of utmost importance</strong>.</li><li>For instance, it is not acceptable to sacrifice compiler correctness to optimize the generated code.</li></ul></li></ul><h4 id="2-3-Object-Language-and-Metalanguage"><a href="#2-3-Object-Language-and-Metalanguage" class="headerlink" title="2.3 Object Language and Metalanguage"></a>2.3 Object Language and Metalanguage</h4><ul><li>In any language definition, informal or formal, a careful distinction must be made between<ul><li>the <strong>Object Language</strong>: the language being defined:<ul><li>Java, Haskell, Assembly, etc.</li></ul></li><li>the <strong>Metalanguage</strong>: the language of the definition it self.<ul><li>English, for informal specifications.</li><li>BNF, or context-free grammars (CFGs) in general, for formal specifications.</li></ul></li></ul></li><li>The semantics of the metalanguage must be well understood.<ul><li>e.g., how a context-free language (CFL) is generated from a CFG, how the production rules are used, parsing issues, etc.</li></ul></li></ul><h4 id="2-4-Informal-Specifications"><a href="#2-4-Informal-Specifications" class="headerlink" title="2.4 Informal Specifications"></a>2.4 Informal Specifications</h4><ul><li>In an informal specification, the metalanguage is a natural language, e.g., English.</li><li>Most programming languages are defined more or less informally.</li><li>â€˜Informalâ€™ does not mean imprecise: it is possible to be precise also in a natural language.</li></ul><h4 id="2-5-Formal-Specifications"><a href="#2-5-Formal-Specifications" class="headerlink" title="2.5 Formal Specifications"></a>2.5 Formal Specifications</h4><ul><li>A <strong>Formal Specification</strong> is mathematically precise</li><li>Usually, a <strong>Formal Metalanguage</strong> is used, e.g.<ul><li><strong>ENBF</strong> for specifying context-free syntax</li><li><strong>inference rules and logic</strong> for specifying static and/or dynamic semantics</li><li><strong>denotational semantics</strong> for specifying dynamic semantics</li></ul></li><li>Languages with rich denotational semantics are ideal where:<ul><li>absolute correctness is essential, e.g., in safety-critical systems.</li><li>high efficiency is required, e.g., energy efficient computation.</li></ul></li><li>Compared with imperative languages (e.g., C or Java), functional languages (e.g., Lisp pr Haskell) have richer denotational semantics.</li></ul><h4 id="2-6-Context-Free-Grammers"><a href="#2-6-Context-Free-Grammers" class="headerlink" title="2.6 Context-Free Grammers"></a>2.6 Context-Free Grammers</h4><p><strong>Context-free grammars</strong> generate <strong>context-free languages</strong>:</p><ul><li>CFLs are suitable for specifying some common programming language constructs, e.g.<ul><li>balanced parentheses</li><li>nested structures</li><li>matching keywords such as <strong>begin</strong> and <strong>end</strong>.</li></ul></li><li>In language design, CFLs that can be recognized by <strong>deterministic pushdown automata (DPDAs)</strong> are preferred over non-deterministic ones.</li></ul><h4 id="2-7-CFG-Notation"><a href="#2-7-CFG-Notation" class="headerlink" title="2.7 CFG Notation"></a>2.7 CFG Notation</h4><p>We will give CFGs by stating the productions in one of the two styles:</p><ul><li><p><strong>Formal languages style</strong></p><ul><li>Used for: small, abstract examples; at meta level when talking about grammars</li><li>Simple naming conventions used to distinguish terminals and variables (i.e., nonterminals):<ul><li>variables: uppercase letters, e.g., <em>A</em>, <em>B</em>, <em>S</em></li><li>terminals: lowercase letters or digits, e.g., <em>a</em>, <em>b</em>, 3</li></ul></li><li>Start symbol usually called <em>S</em></li></ul></li><li><p><strong>Programming Language Specification style</strong>:</p><ul><li><p>Used for larger and more applied examples.</p></li><li><p>Typographical conventions used to distinguish terminals and variables:</p><ul><li>Variables are written like <em>this</em></li><li>Terminals are written like <font color="blue">this</font></li><li>Terminals with variable spelling and special symbols are written like <u><em><font color="blue">this</font></em></u></li></ul></li><li><p>The start symbol is often implied by the context.</p></li><li><p>For example:</p><p><em>AssignStmt -&gt; <u><font color="blue">Identifier</font></u></em> <font color="blue">:=</font> <em>Expr</em></p><p>Here,</p><ul><li><em>AssignStme</em> and <em>Expr</em> are nonterminals</li><li><font color="blue">:=</font> is a terminal</li><li><u><em><font color="blue">Identifier</font></em></u> is also a terminal, but its possible spellings are defined elsewhere, usually by a lexical (ie, regular) grammar.</li></ul></li></ul></li></ul><h4 id="2-8-BNF-and-Extended-BNF"><a href="#2-8-BNF-and-Extended-BNF" class="headerlink" title="2.8 BNF and Extended BNF"></a>2.8 BNF and Extended BNF</h4><p>The previous CFGs were essentially in <strong>Backus-Naur form (BNF)</strong>.</p><p><strong>Extended Backus-Naur form (EBNF)</strong> is a bit more convenient.</p><ul><li>Additional EBNF constructs:<ul><li>parentheses for grouping</li><li>| for alternatives within parentheses</li><li>* for iteration</li></ul></li><li>EBNF is <strong>no more powerful</strong> than BNF:<ul><li>any EBNF grammar can be transformed into an equivalent BNF.</li></ul></li><li>EBNF is more concise and readable than plain BNF.</li></ul><h4 id="2-9-Concrete-Syntax"><a href="#2-9-Concrete-Syntax" class="headerlink" title="2.9 Concrete Syntax"></a>2.9 Concrete Syntax</h4><p>The <strong>Concrete Syntax</strong> (a. k. a. surface syntax) of a language is usually defined at two levels:</p><ul><li>The <strong>Lexical syntax</strong>: usually a <strong>regular language</strong>, with grammar rules written as regular expressions, specifying the syntax of:<ul><li><strong>language symbols</strong> or <strong>tokens</strong></li><li><strong>white space</strong></li><li><strong>comments</strong></li></ul></li><li>The <strong>Context-Free syntax</strong></li></ul><h4 id="2-10-MiniTriangle-Lexical-Syntax"><a href="#2-10-MiniTriangle-Lexical-Syntax" class="headerlink" title="2.10 MiniTriangle Lexical Syntax"></a>2.10 MiniTriangle Lexical Syntax</h4><img src="/2021/10/02/Compiler/Screen Shot 2021-10-12 at 10.28.53 PM.png" style="zoom:50%;"><ul><li><p>Essentially a (left-)linear grammar; i. e., the lexical syntax specifies a <strong>regular</strong> language.</p></li><li><p>Not completely formal (e. g., the use of â€œexceptâ€ for excluding keywords from identifiers).</p></li><li><p>Each individual character of a terminal is actually a terminal symbol, i. e., it should be:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-12 at 10.32.04 PM.png" style="zoom:50%;"></li><li><p>Special characters are written like <u><em><font color="blue">this</font></em></u>. They are single terminal symbols.</p></li></ul><h4 id="2-11-MiniTriangle-Tokens"><a href="#2-11-MiniTriangle-Tokens" class="headerlink" title="2.11 MiniTriangle Tokens"></a>2.11 MiniTriangle Tokens</h4><p>Some valid MiniTriangle tokens:</p><ul><li>const3 (Identifier)</li><li>const (Keyword)</li><li>42 (Integer Literal)</li><li>+ (Operator)</li></ul><h4 id="2-11-MiniTriangle-Maximal-Munch-Principle"><a href="#2-11-MiniTriangle-Maximal-Munch-Principle" class="headerlink" title="2.11 MiniTriangle: Maximal Munch Principle"></a>2.11 MiniTriangle: Maximal Munch Principle</h4><p><strong>Question</strong>: Is const3 a single token?</p><p><strong>Answer</strong>: It is hard to tell.</p><ul><li>The grammar is ambiguous.</li><li>This type of ambiguity exists in the grammar of almost all commonly used programming languages.</li><li>The ambiguity is handled by using the <em>longest match</em> - a.k.a., maximal munch - principle</li><li>Essentially, the tokens must be built from the maximum possible number of characters from the input stream.</li></ul><h4 id="2-12-MiniTriangle-Context-Free-Syntax"><a href="#2-12-MiniTriangle-Context-Free-Syntax" class="headerlink" title="2.12 MiniTriangle Context-Free Syntax"></a>2.12 MiniTriangle Context-Free Syntax</h4><img src="/2021/10/02/Compiler/Screen Shot 2021-10-19 at 3.36.56 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-10-19 at 3.37.03 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-10-19 at 3.37.09 PM.png" style="zoom:50%;"><h4 id="2-12-Why-a-Lexical-Grammar"><a href="#2-12-Why-a-Lexical-Grammar" class="headerlink" title="2.12 Why a Lexical Grammar?"></a>2.12 Why a Lexical Grammar?</h4><p>Together, the lexical grammar and the context-free grammar specify the concrete syntax.</p><p>In our case, both grammars are expressed in (E)BNF and look similar.</p><ul><li>Why not join them?</li><li>Why not do away with scanning, and just do parsing?</li></ul><p>Answer:</p><ul><li><strong>Simplicity</strong>:<ul><li>Dealing with white space and comments in the context free grammar becomes unnecessarily complicated</li><li>In constrast, the lexical grammar manages tokenization by using regular grammars.</li></ul></li><li><strong>Efficiency</strong>:<ul><li>Working on classified groups of characters (tokens) facilitates parsing, i.e., makes it possible to use a simpler parsing algorithm.</li><li>Grouping and classifying characters by simple means increases efficiency.</li></ul></li></ul><h4 id="2-13-MiniTriangle-Abstract-Syntax"><a href="#2-13-MiniTriangle-Abstract-Syntax" class="headerlink" title="2.13 MiniTriangle Abstract Syntax"></a>2.13 MiniTriangle Abstract Syntax</h4><p>This grammar specifies the <strong>phrase structure</strong> of MiniTriangle. In addition, it gives node labels to be used when drawing Abstract Syntax Trees.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 2.57.47 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 2.57.52 PM.png" style="zoom:50%;"><p><strong>Notes:</strong></p><ul><li>Keywords and other fixed-spelling terminals serve only to make the connection with the concrete syntex clear.</li><li><font color="blue"><u><em>Identifier</em></u></font> $\cup$ <font color="blue"><u><em>Operator</em></u></font> $\subseteq$ <font color="blue"><u><em>Name</em></u></font></li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 3.08.18 PM.png" style="zoom:50%;"><p>Note: <strong>fixed-spelling</strong> terminals are <strong>omitted</strong> because they are implied by the node labels.</p><h4 id="2-14-Concrete-vs-Abstract-Syntax"><a href="#2-14-Concrete-vs-Abstract-Syntax" class="headerlink" title="2.14 Concrete vs. Abstract Syntax"></a>2.14 Concrete vs. Abstract Syntax</h4><p>Key points:</p><ul><li>Concrete syntax: <strong>string</strong> (generated from the lexical and context-free grammars)</li><li>Abstract syntax: <strong>tree</strong></li></ul><p>(Ways to describe <strong>graphical</strong> concrete syntax are more varied)</p><h4 id="2-17-Concrete-AST-Representation"><a href="#2-17-Concrete-AST-Representation" class="headerlink" title="2.17 Concrete AST Representation"></a>2.17 Concrete AST Representation</h4><p>Algebraic datatypes (as in Haskell) allow a direct way to represent the abstract syntax:</p><ul><li>Each non-terminal is mapped to a <strong>type</strong></li><li>Each label is mapped to a <strong>constructor</strong> for the corresponding type</li><li>The constructors get one argument for each non-terminal and â€œvariableâ€ terminal in the RHS of the production</li><li>Sequences are represented by lists</li><li>Options are represented by values of type $Maybe$</li><li>â€œLiteralâ€ terminals are ignored</li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 3.24.08 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 3.24.13 PM.png" style="zoom:50%;"><p>One may use labeled fields. It is also possible to include source position for error reporting to facilitate debugging:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 3.24.19 PM.png" style="zoom:50%;"><h3 id="3-Syntactic-Analysis-Bottom-Up-Parsing"><a href="#3-Syntactic-Analysis-Bottom-Up-Parsing" class="headerlink" title="3. Syntactic Analysis: Bottom-Up Parsing"></a>3. Syntactic Analysis: Bottom-Up Parsing</h3><h4 id="3-1-Parsing-Strategies"><a href="#3-1-Parsing-Strategies" class="headerlink" title="3.1 Parsing Strategies"></a>3.1 Parsing Strategies</h4><ul><li>There are two basic strategies for parsing:<ol><li><em><strong>Top-down parsing</strong></em>:<ul><li>Attempts to construct the parse tree <em>from the root downward</em>.</li><li>Traces out a <em><strong>leftmost derivation</strong></em>.</li></ul></li><li><em><strong>Bottom-up parsing</strong></em>:<ul><li>Attempts to construct the parse tree <em>from the leaves working up toward the root</em>.</li><li>Traces out a <em><strong>rightmost derivation in reverse</strong></em>.</li></ul></li></ol></li></ul><h4 id="3-2-Top-Down-Leftmost-Derivation"><a href="#3-2-Top-Down-Leftmost-Derivation" class="headerlink" title="3.2 Top-Down: Leftmost Derivation"></a>3.2 Top-Down: Leftmost Derivation</h4><p> Consider the grammar:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 4.26.37 PM.png" style="zoom:50%;"><p>Call sequence for predictive parser on <em>abccde</em>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 4.27.32 PM.png" style="zoom:50%;"><h4 id="3-3-Bottom-Up-Parsing"><a href="#3-3-Bottom-Up-Parsing" class="headerlink" title="3.3 Bottom-Up Parsing"></a>3.3 Bottom-Up Parsing</h4><ul><li>In practice, bottom-up parsers are more common, because they are more efficient.</li><li>The machinery behind them, however, is significantly more complicated than that of top-down parsers.</li><li>Thus, it is advisable to use <strong>parse generator tools</strong>, instead of coding parsers by hand in conventional programming languages.</li><li>Using these specialized tools makes the process a lot simpler, <strong>yet it is important to acquire some basic knowledge of the operations involved in bottom-up parsing.</strong></li></ul><h4 id="3-4-Shift-Reduce-Parsing"><a href="#3-4-Shift-Reduce-Parsing" class="headerlink" title="3.4 Shift-Reduce Parsing"></a>3.4 Shift-Reduce Parsing</h4><p>There are many different approaches to bottom-up parsing, but most implementations are based on <strong>shift-reduce parsing</strong>.</p><p>A shift-reduce parser:</p><ul><li>performs a single left-to-right pass over the input without any backtracking.</li><li>works from leaves toward the root of the parse tree.</li><li>has two basic actions:<ul><li><em><strong>Shift</strong></em> (read) next terminal symbol</li><li><em><strong>Reduce</strong></em> a sequence of terminals (that have been read already) and previously reduced nonterminals, corresponding to the right-hand side (RHS) of a production, to left-hand side (LHS) nonterminal of that production.</li></ul></li></ul><h4 id="3-5-Bottom-Up-A-Simple-Example"><a href="#3-5-Bottom-Up-A-Simple-Example" class="headerlink" title="3.5 Bottom-Up: A Simple Example"></a>3.5 Bottom-Up: A Simple Example</h4><ul><li><p>Consider the context-free grammar (CFG) $G$ with productions:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-21 at 1.50.09 PM.png" style="zoom:50%;"><p>for simple arithmetic expressions, with:</p><ul><li>a single terminal â€˜<em>a</em>â€˜</li><li>two operations + and *</li><li>all ending in $<ul><li>(This makes the example easier to handle.)</li></ul></li></ul></li><li><p>The aim is to design a pushdown automaton (PDA) $NB(G)$ that accepts the language $L(G)$, effectively performing a bottom-up parsing, and producing rightmost derivations in reverse.</p></li><li><p>In the nondeterministic bottom-up PDA $NB(G)$, the two types of moves, other than the initial move and the moves to accept, are shifts and reductions.</p></li><li><p>There are five possible reductions in the PDA $NB(G)$, two requiring only one move and three requiring two or more.</p></li><li><p>Nondeterminism arises in two ways: first, in choosing whether to shift or to reduce, and second, in making a choice of reductions if more than one is possible.</p></li><li><p>There is only one correct move at each step, and $G$ turns out to be a grammar for which the combination of the input symbol and stack symbol will allow us to find the correct move.</p></li><li><p>One basic principle is that, if there is a reduction that should be made, then it should be made as soon as it is possible.</p></li><li><p>For example, if â€˜$a$â€™ is on top of the stack, then a reduction, not a shift, is the move to make.</p><ul><li>Any symbol that goes onto the stack, will have to be removed later in order to execute the reduction of â€˜$a$â€™ or $T*a$ to $T$.</li><li>The only way to remove it is to do another reduction</li><li>and because the derivation tree is built from the bottom up, any subsequent reduction to construct the portion of the tree involving the â€˜<em>a</em>â€˜ node needs its parent, not the node itself.</li></ul></li><li><p>Another principle that is helpful is that, in the moves made by $NB(G)$, the current string in the derivation being simulated contains the reverse of the stack contents (not including $Z_0$) followed by the remaining input.</p></li><li><p>We can use this to answer the question of which reduction to execute if there seems to be a choice:</p><ul><li>If $a * T$ (the reverse of $T<em>a$) were on top of the stack, and we simply reduced $a$ to $T$, then the current string in a rightmost derivation would contain the substring $T</em>T$, which is never possible.</li><li>Similarly, if $T<em>S_1$ (the reverse of $S_1</em>T$) were on top, then reducing $T$ to $S_1$ cannot be correct.</li></ul></li><li><p>These two situations can summarized by saying that <strong>when a reduction is executed, the longest possible string should be removed from the stack during the reduction.</strong></p></li><li><p>Essentially, the only remaining question is what to do when $T$ is the top stack symbol: shift or reduce?</p></li><li><p>We can answer this by considering the possibilities for the next input symbol.</p><ul><li>If it is $+$, then this $+$ should eventually be part of the expression $S_1 + T$ (in reverse) on the stack, so that $S_1 + T$ can be reduced to $S_1$; therefore, the non-terminal $T$ should eventually be reduced to $S_1$, and so the time to do it is now.</li><li>Similarly, if the next input is $$$, then the non-terminal $T$ should be reduced to $S_1$, so that $S_1$$ can be reduced to $S$.</li><li>The only other symbol that can follow $T$ in a rightmost derivation is $<em>$, and $</em>$ cannot follow any other symbol; therefore, $*$ should be shifted onto the stack.</li></ul></li></ul><p>With these observations, we can formulate the rules that the deterministic bottom-up PDA should follow in choosing its moves:</p><ol><li>If the top stack symbol is $Z_0$, $S_1$, $+$, or $*$, shift the next input symbol to the stack. (None of these four symbols is the rightmost symbol in the right side of a production.)</li><li>If the top stack symbol is $$$, reduce $S_1$$ to $S$.</li><li>If the top stack symbol is â€˜$a$â€™, reduce $T*a$ to $T$ if possible; otherwise reduce $a$ to $T$.</li><li>If the top stack symbol is $T$, then reduce (to $S_1$) if the next input is $+$ or $$$, otherwise shift.</li><li>If the top stack symbol is $S$, then pop it from the stack; if $Z_0$ is the next top symbol, accept, otherwise reject.</li></ol><ul><li><p>All these rules, except rule 4, are easily incorporated into a transition table for a deterministic pushdown automaton (DPDA), but the fourth may require a little clarification:</p><ul><li>If the PDA sees the combination ($<em>$, $T$) of next input symbol and stack symbol, then it shifts $</em>$ onto the stack.</li><li>If it sees ($+$, $T$) or ($$$, $T$), then the moves it makes are the ones that carry out the appropriate reduction, and then shift the input symbol onto the stack.</li></ul></li><li><p>The point is that â€œseeingâ€ ($+$, $T$), for example, implies reading the $+$, and the PDA then uses auxiliary states to remember that after it has performed a reduction, it should place $+$ on the stack.</p></li><li><p>We now have the essential specifications for a DPDA.</p></li><li><p>Like the non-deterministic PDA $NB(G)$, the moves it makes in accepting a string simulate, <strong>in reverse</strong>, the steps in a <strong>rightmost derivation</strong> of that string.</p></li><li><p>and in this sense, our DPDA serves as a bottom-up parser for $G$.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-25 at 2.59.01 PM.png" style="zoom:50%;"></li><li><p>The moves for the DPDA and the input string $a+a*a$$ are shown in the table above.</p></li><li><p>For each configuration, we show the rule (from the set of five rules) that the PDA used to get there, and, in the case of rule 4, whether the move was a shift or a reduction.</p></li><li><p>As mentioned before, the details of the shift-reduce theory are quite involved.</p></li><li><p>The previous example serves as a relatively simpler starting point for obtaining a general understanding of the method.</p></li><li><p>In what follows, we will discuss some details that are helpful in understanding the general concepts.</p></li><li><p>This will make it easier to understand how to use parser generators.</p></li></ul><h4 id="3-6-Bottom-Up-Rightmost-Derivation-in-Reverse"><a href="#3-6-Bottom-Up-Rightmost-Derivation-in-Reverse" class="headerlink" title="3.6 Bottom-Up: Rightmost Derivation in Reverse"></a>3.6 Bottom-Up: Rightmost Derivation in Reverse</h4><p>Consider (again) the grammar:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 4.26.37 PM.png" style="zoom:50%;"><p>The reduction steps for the sentence $abccde$ to $S$:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-25 at 3.11.18 PM.png" style="zoom:50%;"><p>trace out a rightmost derivation in reverse:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-25 at 3.11.49 PM.png" style="zoom:50%;"><p>How can we know when and what to reduce?</p><p><strong>Idea</strong>:</p><ul><li>Construct a deterministic finite automaton (DFA) in which:<ul><li><strong>each state is labeled by â€œall possibilitiesâ€</strong>, considering the input and reductions thus far.</li></ul></li><li>A bit similar to the subset construction that we had for converting a non-deterministic finite automaton (NFA) to an equivalent DFA.</li><li>Whenever reduction is possible,<ul><li>if there is only one possible reduction, then it is clear what to do.</li></ul></li></ul><h4 id="3-7-LL-LR-and-LALR-parsing"><a href="#3-7-LL-LR-and-LALR-parsing" class="headerlink" title="3.7 LL, LR, and LALR parsing"></a>3.7 LL, LR, and LALR parsing</h4><p>Three important classes of parsing methods:</p><ul><li><em><strong>LL(k):</strong></em><ul><li>input scanned left to right</li><li>Leftmost derivation</li><li>$k$ symbols of lookahead</li></ul></li><li><em><strong>LR(k):</strong></em><ul><li>input scanned left to right</li><li>Rightmost derivation in reverse</li><li>$k$ symbols of lookahead</li></ul></li><li><em><strong>LALR(k):</strong></em> Look Ahead <em><strong>LR</strong></em>, simplified LR parsing</li></ul><p>By extension, the classes of grammars these methods can handle are also classified as LL($k$), LR($k$), and LALR($k$).</p><h4 id="3-8-Why-study-LR-and-LALR-parsing"><a href="#3-8-Why-study-LR-and-LALR-parsing" class="headerlink" title="3.8 Why study LR and LALR parsing?"></a>3.8 Why study LR and LALR parsing?</h4><ul><li>These methods handle a wide class of grammars of <strong>practical significance</strong>.</li><li>In particular, <strong>left- and right-recursive grammars</strong><ul><li>but left-recursive needs smaller stack.</li></ul></li><li>LALR is a good compromise between <strong>expressiveness and space cost</strong> of implementation.</li><li>Consequently, <strong>many parser generator tools are based on LALR</strong>.</li><li>We will mainly study LR(0) parsing because:<ul><li>it is the simplest,</li><li>yet, it used the same fundamental principles as LR(1) and LALR(1).</li></ul></li></ul><h4 id="3-9-Shift-Reduce-Parsing-Theory"><a href="#3-9-Shift-Reduce-Parsing-Theory" class="headerlink" title="3.9 Shift-Reduce Parsing Theory"></a>3.9 Shift-Reduce Parsing Theory</h4><p>Terminology:</p><p>An <strong>item</strong> for a CFG is a production with a dot anywhere in the RHS.</p><p>For example, the items for the grammar</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-25 at 3.32.33 PM.png" style="zoom:50%;"><p>are</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-25 at 3.33.05 PM.png" style="zoom:50%;"><ul><li><p>Given a CFG $G=(N,T,P,A)$, a string $\phi \in (N\cup T)^*$ is a <strong>sentantial form</strong> for $G$ iff $S\mathop{\stackrel*\Rightarrow}_{G} \phi$.</p></li><li><p>A <strong>right-sentential form</strong> is a sentential form that can be derived by a <strong>rightmost derivation</strong>.</p></li><li><p>A <strong>handle</strong> of a right-sentential form $\phi = \delta \alpha w$ is the substring $\alpha$ such that:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 1.49.12 PM.png" style="zoom:50%;"><p>where $\alpha, \delta, \phi \in (N\cup T)^*$, and $w\in T^*$.</p><ul><li>The grammar must have the production $A\rightarrow \alpha$.</li></ul></li></ul><p>For example, consider the grammar:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 4.26.37 PM.png" style="zoom:50%;"><p>The following is a rightmost derivation:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 1.53.15 PM.png" style="zoom:50%;"><ul><li>$aABe$, $aAde$ and $abcAde$ are right-sentential forms.</li><li>Handle for each? $aABe$, $d$, and $bcA$, respectively.</li></ul><p>For an unambiguous grammar, the rightmost derivation is unique. Thus, we can talk about <em>â€œthe handleâ€</em> rather than merely â€œa handleâ€.</p><ul><li><p><em>Finding handles is a central issue in bottom-up parsing.</em></p></li><li><p>Efficient handle finding is the key to efficient bottom-up parsing.</p></li><li><p>A <strong>viable prefix</strong> of a right-sentential form $\phi$ is any <strong>prefix $\gamma$</strong> of $\phi$ ending <strong>no farther</strong> right than the right end of the handle of $\phi$.</p></li><li><p>An item $A\rightarrow \alpha Â· \beta$ is <strong>valid</strong> for a viable prefix $\gamma$ if there is a rightmost derivation</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 2.00.45 PM.png" style="zoom:50%;"><p>and $\delta \alpha = \gamma$.</p></li><li><p>An item in <strong>complete</strong> if the <strong>dot is the rightmost</strong> symbol in the item.</p></li><li><p>The right-sentential form $abcAde$ has handle $bcA$.</p></li><li><p>Viabel prefixes? $\epsilon, a, ab, abc, abcA$.</p></li></ul><p>Last derivation step <img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 2.07.33 PM.png" style="zoom:50%;"> by production $A\rightarrow bcA$, indicating that the handle is $bcA$.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 2.08.34 PM.png" style="zoom:50%;"><p>Knowing the valid items for a viable prefix allows us to find a rightmost derivation in reverse:</p><ul><li>If $A\rightarrow \alphaÂ·$ is a <strong>complete</strong> valid item for a viable prefix $\gamma = \delta \alpha$ of a right-sentential form $\gamma w$, then it <strong>appears</strong> that $A\rightarrow \alpha$ can be used at the last step, and that the previous right-sentential form is $\delta A w$.</li><li>If this is <strong>always the case</strong> for a CFG $G$, then for any $x\in L(G)$, since $x$ is a right-sentential form, previous right-sentential forms can be determined until $S$ is reached, giving a right-most derivation of $x$.</li></ul><p>If $A\rightarrow \alphaÂ·$ is a complete valid item for a viable prefix $\gamma = \delta \alpha$, we only know that it may be possible to use $A\rightarrow \alpha$ to derive $\gamma w$ from $\delta Aw$.</p><p>For example:</p><ul><li><p>$A\rightarrow \alphaÂ·$ may be valid because of a <strong>different</strong> rightmost derivation <img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 2.18.08 PM.png" style="zoom:50%;"></p></li><li><p>There could be <strong>two or more complete items</strong> valid for $\gamma$.</p></li><li><p>There could be a handle of $\gamma w$ that <strong>includes symbols of $w$</strong>.</p></li></ul><h4 id="3-10-LR-0-Parsing"><a href="#3-10-LR-0-Parsing" class="headerlink" title="3.10 LR(0) Parsing"></a>3.10 LR(0) Parsing</h4><ul><li><p><strong>LR(0) grammar:</strong></p><p>A CFG for which knowing a complete valid item is enough to determine the previous right-sentential form.</p></li><li><p>The set of viable prefixes for any CFG is <strong>regular</strong>!</p><p>(A bit unexpected: the language of a CFG is not regular in general.)</p></li><li><p>We can develop an <strong>efficient parser</strong> for the LR(0) CFG based on a <strong>DFA for recognizing viable prefixes and their valid items</strong>.</p></li><li><p>The <strong>states of the DFA</strong> are <strong>sets of items</strong> valid for a recognized viable prefix.</p></li></ul><p>A DFA recognizing viable prefixes for thr CFG</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 4.26.37 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 2.30.28 PM.png" style="zoom:50%;"><p>Drawing conventions for â€œLR DFAsâ€:</p><ul><li>For the purpose of recognizing the set of viable prefixes, all drawn states are considered accepting.</li><li>Error transitions and error states are not drawn.</li></ul><p>Recall that:</p><ul><li>the <strong>viable prefixes</strong> for the right-sentential form $abcAde$ are $\epsilon, a, ab, abc, abcA$. They are indeed all recognized by the DFA (all states are considered accepting).</li><li>the item $A\rightarrow bcÂ·A$ is valid for the viable prefix $abc$. The corresponding DFA state indeed contains that item. (Along with <em><strong>more items</strong></em> in this case!)</li><li>item $A\rightarrow bcAÂ·$ is a <strong>complete</strong> valid item for the viable prefix $abcA$. The corresponding DFA state indeed contains that item (and <em><strong>only</strong></em> that item).</li></ul><p>Given a DFA recognizing viable prefixes, an LR(0) parser can be constructed as follows:</p><ul><li>In a state <em>without complete items</em>: <em><strong>Shift</strong></em><ul><li>Read the next terminal symbol and push it onto an internal parse stack.</li><li>Move to new state by following the edge labeled by the terminal symbol just read.</li></ul></li><li>In a state with a <em>single complete item</em>: <em><strong>Reduce</strong></em><ul><li>The top of the parse stack contains the <em><strong>handle</strong></em> of the current right-sentential form (since we have recognized a viable prefix for which a single <em><strong>complete</strong></em> item is valid).</li><li>The handle is just the <em><strong>RHS</strong></em> of the valid item.</li><li>Reduce to the previous right-sentential form by <em><strong>replacing the handle</strong></em> on the parse stack with the <em><strong>LHS</strong></em> of the valid item.</li><li><em><strong>Move</strong></em> to the state indicated by the new viable prefix on the parse stack.</li></ul></li><li>If a state contains both complete and incomplete items, or if a state contains more than one complete item, then the grammar <em><strong>is not LR(0)</strong></em>.</li></ul><p>Complete sequence ($\gamma w$ is right-sentential form):</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 4.57.23 PM.png" style="zoom:50%;"><p>Cf: <img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 5.04.41 PM.png" style="zoom:50%;"></p><p>To see more clearly that the parser carries out the rightmost derivation in reverse, look at the right-sentential forms $\gamma w$ of the <strong>reduction steps only</strong>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 5.06.10 PM.png" style="zoom:50%;"><h4 id="3-11-LR-Parsing-amp-Left-Right-Recursion"><a href="#3-11-LR-Parsing-amp-Left-Right-Recursion" class="headerlink" title="3.11 LR Parsing &amp; Left/Right Recursion"></a>3.11 LR Parsing &amp; Left/Right Recursion</h4><p>Consider parsing of strings such as:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-26 at 5.16.18 PM.png" style="zoom:50%;"><ul><li>Note how the <em><strong>right-recursive</strong></em> production $A\rightarrow bcA$ causes symbols $bc$ to pile up on the parse stack until a reduction by $A\rightarrow c$ can occur, which, in turn, allows the stacked symbols to be reduced away.</li><li><em><strong>Left-recursive</strong></em> allows reduction to happen sooner, thus keeping the size of the parse stack down.</li><li>This is why left-recursive grammars are often preferred for LR parsing.</li></ul><h4 id="3-12-LR-1-Grammars"><a href="#3-12-LR-1-Grammars" class="headerlink" title="3.12 LR(1) Grammars"></a>3.12 LR(1) Grammars</h4><ul><li>In practice, LR(0) tends to be a bit too restrictive.</li><li>If we add one symbol of â€œlookaheadâ€ by determining the set of <em><strong>terminals that could possibly follow a handle</strong></em> being reduced by a production $A\rightarrow \beta$, then a wider class of grammars can be handled.</li><li>Such grammars are called <em><strong>LR(1)</strong></em>.</li></ul><p>Idea:</p><ul><li><p>Associate a <em><strong>lookahead set</strong></em> with items:<br>$$<br>A \rightarrow \alpha Â· \beta, {a_1, a_2, \cdots, a_n}<br>$$</p></li><li><p>On reduction, a complete item is <em><strong>only valid</strong></em> if the next input symbol belongs to its lookahead set.</p></li><li><p>Thus, it is OK to have two or more simultaneously valid complete items, as long as their lookahead sets are <em><strong>disjoint</strong></em>.</p></li></ul><h3 id="4-Syntactic-Analysis-Parser-Generators"><a href="#4-Syntactic-Analysis-Parser-Generators" class="headerlink" title="4. Syntactic Analysis: Parser Generators"></a>4. Syntactic Analysis: Parser Generators</h3><h4 id="4-1-Parser-Genereators"><a href="#4-1-Parser-Genereators" class="headerlink" title="4.1 Parser Genereators"></a>4.1 Parser Genereators</h4><ul><li><p>Constructing parsers by hand can be very tedious and time consuming.</p></li><li><p>This is true in particular for LR(<em>k</em>) and LALR parsers: constructing the corresponding deterministic finite automata (DFAs) is extremely laborious.</p></li><li><p>For instance, this simple grammar:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-10-20 at 4.26.37 PM.png" style="zoom:50%;"><p>gives rise to a 10 state LR(0) DFA.</p></li><li><p><strong>Parser construction</strong> is, for the most part, an <strong>algorithmic</strong> process.</p></li><li><p>Why not write a program to do the heavy and tedious work for us?</p></li><li><p>A <strong>Parser Generator</strong> (or â€œcompiler compilerâ€) takes a grammar as input and outputs a parser (i.e., a program) for that grammar.</p></li><li><p>The input grammar is augmented with <strong>â€œsemantic actionsâ€</strong>, i.e., code fragments that get invoked when a derivation step is performed.</p></li><li><p>The semantic actions typically:</p><ul><li>construct an abstract syntax tree (AST) or</li><li>interpret the program being parsed.</li></ul></li></ul><p>Consider an LR shift-reduce parser:</p><ul><li>A <strong>reduction</strong> corresponds to a derivation step in the grammar:<ul><li>Remember that an LR parser performs a rightmost derivation in reverse.</li></ul></li><li>At a reduction, the terminals and non-terminals of the right-hand side (RHS) of the production (the <strong>handle</strong>) are on the parse stack, associated with:<ul><li><strong>semantic information</strong>, e. g., the correspoding AST fragments, or</li><li><strong>semantic values</strong>, e. g., expression values.</li></ul></li><li>Both construction of an AST and evaluation of expressions proceed in <strong>bottom-up</strong> order.</li></ul><h4 id="4-2-Happy-Parser-for-TXL"><a href="#4-2-Happy-Parser-for-TXL" class="headerlink" title="4.2 Happy Parser for TXL"></a>4.2 Happy Parser for TXL</h4><ul><li>In order to impart associativity, a <strong>left-recursive</strong> grammar is provided.<ul><li>A grammar $G$ is left-recursive if and only if there exists a nonterminal symbol $A$ that can derive to a sentential form with itself as the leftmost symbol, i. e., $A\rightarrow^+ A\alpha$ in which $\alpha$ is any sequence of terminal and nonterminal symbols.</li><li>The dual definition provides right-recursive grammars.</li></ul></li><li>LR parsers have no problem with left- or right-recursion, except that right-recursion requires more stack.</li></ul><p>We are going to use Happy to develop a parser for the TXL language, generated by the CFG:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 7.57.32 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 7.57.59 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 7.58.21 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 7.58.42 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 7.59.02 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 7.59.22 PM.png" style="zoom:50%;"><ul><li>The code fragment between curly braces is a Haskell <strong>pattern</strong> that is matched against the actual tokens returned by the parsing function.</li><li>If this pattern contains the special variable $$, then the corresponding part of the matched token becomes the semantic value.</li><li>Otherwise the entire token becomes the semantic value.</li><li>The semantic values of different terminal symbols may thus have different types.</li></ul><p>The grammar productions are written in BNF, with an additional semantic action defining the semantic value for each production:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.03.40 PM.png" style="zoom:50%;"><p>It is also possible to add type annotations:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.04.23 PM.png" style="zoom:50%;"><h4 id="4-3-Shift-Red-and-Red-Red-Conflicts"><a href="#4-3-Shift-Red-and-Red-Red-Conflicts" class="headerlink" title="4.3 Shift/Red. and Red./Red. Conflicts"></a>4.3 Shift/Red. and Red./Red. Conflicts</h4><p>In LR-parsing, ambiguous grammars lead to <strong>shift/reduce</strong> and <strong>reduce/reduce</strong> conflicts:</p><ul><li><p>shift/reduce: some states of the DFA have mixed complete and incomplete items:<br>$$<br>A\rightarrow aÂ·\<br>A\rightarrow aÂ·b<br>$$</p></li><li><p>reduce/reduce: some states have more than one complete item:<br>$$<br>A\rightarrow aÂ·\<br>B\rightarrow aÂ·<br>$$</p></li><li><p>Shift/reduce conflicts are often resolved by <strong>opting for shifting</strong>:</p><ul><li>Typically the default option.</li><li>Usually gives the desired result. For instance, it resolves the dangling else problem in a natural way.</li></ul></li><li><p>Reduce/reduce conflicts are not so easy, because there is no obvious reason for picking one production over another: the grammar <strong>must</strong> be manually disambiguated.</p></li></ul><h4 id="4-4-Precedence-and-Associativity"><a href="#4-4-Precedence-and-Associativity" class="headerlink" title="4.4 Precedence and Associativity"></a>4.4 Precedence and Associativity</h4><p>Happy (like Yacc and Bison) allows operator precedence and associativity to be explicitly specified to disambiguate a grammar:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.14.10 PM.png" style="zoom:50%;"><p>The relative precedence is implicit in the ordering: lower precedences precede higher precedences. For instance, â€˜+â€™ and â€˜-â€˜ appear before â€˜*â€™ and â€˜/â€˜.</p><h4 id="4-5-A-TXL-Interpreter"><a href="#4-5-A-TXL-Interpreter" class="headerlink" title="4.5 A TXL Interpreter"></a>4.5 A TXL Interpreter</h4><ul><li><p>The semantic actions do not have to construct an AST.</p></li><li><p>An alternative is to <strong>interpret</strong> the code being parsed.</p></li><li><p>Basic idea:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.31.06 PM.png" style="zoom:50%;"></li><li><p>But TXL has a <strong>let</strong>-construct</p><ul><li><p>What about TXL <strong>variables</strong>? For instance, how should we reflect the assignment of $3$ to $x$ in the following expression?</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.32.49 PM.png" style="zoom:50%;"></li></ul></li></ul><p>One option:</p><ul><li><p>Each semantic action returns a function of type</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.33.37 PM.png" style="zoom:50%;"></li></ul><p>â€‹        where (for example)</p><p>â€‹                                                                <img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.34.07 PM.png" style="zoom:50%;"></p><ul><li><p>The semantic action for evaluating a composite expression passes on the environment. For instance, the semantic action for + could be:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.35.45 PM.png" style="zoom:50%;"></li><li><p>The semantic action for a variable looks up the variable value in the environment:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.36.32 PM.png" style="zoom:50%;"></li><li><p>The semantic action for $let$ extends the argument environment and then evaluates the body in the extended environment:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.37.34 PM.png" style="zoom:50%;"></li><li><p>The semantic action for literal just returns the value of the literal, ignoring the environment:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.38.19 PM.png" style="zoom:50%;"></li><li><p>A program get evaluated by applying the overall result function to the <strong>empty environment</strong>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-11-10 at 8.39.05 PM.png" style="zoom:50%;"></li></ul><h3 id="5-Contextual-Analysis-Scope-1"><a href="#5-Contextual-Analysis-Scope-1" class="headerlink" title="5. Contextual Analysis: Scope 1"></a>5. Contextual Analysis: Scope 1</h3><h4 id="5-1-Contextual-Analysis"><a href="#5-1-Contextual-Analysis" class="headerlink" title="5.1 Contextual Analysis"></a>5.1 Contextual Analysis</h4><p>The aim of contextual analysis is to ensure that a program is <strong>statically well-formed</strong>.</p><ul><li>But syntax is also related to â€œformâ€.</li><li>So, why is it not possible to perform contextual analysis using the context-free grammar (CFG) that generates the context-free syntax?</li><li>For instance, is it possible to use CFGs to express <em>type constraints</em>?<ul><li>Note that, if we could do this, then the parser would be able to do the type checking for us as well.</li></ul></li></ul><h4 id="5-2-Limitations-of-CFGs"><a href="#5-2-Limitations-of-CFGs" class="headerlink" title="5.2 Limitations of CFGs"></a>5.2 Limitations of CFGs</h4><p>Let us see if we can enforce the â€œdeclare before useâ€ requirement using a CFG.</p><p>If we have only <strong>one</strong> variable <strong>a</strong>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-22 at 2.17.09 PM.png" style="zoom:50%;"><p>Now, let us see how the same approach may be generalized to <strong>two</strong> variables, <strong>a</strong> and <strong>b</strong>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-22 at 2.18.05 PM.png" style="zoom:50%;"><p>Some observations:</p><ul><li>Already for two variables, the grammar is a lot more complicated.</li><li>If we extend the same approach to <em>n</em> variables, then how many â€œ<em>ExprXYZ</em>â€œ rules will be needed?<ul><li>The number of nonterminals grows exponentially: for a set of $n$ variables $V = {a_i\mid 1\le i \le n}$, we need $2^n$ nonterminals $Expr[W]$, one for each subset $W\subseteq V$.</li><li>Moreover, normally, the number of variables is <strong>unlimited</strong>, which would imply <strong>infinitely</strong> many productions.<ul><li>This will no longer be a CFG.</li></ul></li></ul></li></ul><p>Attempt to describe simple type constraints using a CFG:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-22 at 2.24.16 PM.png" style="zoom:50%;"><p>This might look reasonable at first sight. <strong>However</strong>:</p><ul><li>The scheme hinges on partitioning the variables <strong>by name</strong> into two groups, i. e.:<ul><li>integer variables and boolean variables.</li></ul></li><li>But in most languages the type of a variable is given by the <strong>context</strong>, not its name.</li><li>Furthermore, how could we, in general, infer argument types from the name of a procedure or function?</li></ul><p>In simple terms, <strong>context-free</strong> grammars are not powerful enough to capture <strong>context-sensitive</strong> information.</p><h4 id="5-3-Unrestricted-Grammars"><a href="#5-3-Unrestricted-Grammars" class="headerlink" title="5.3 Unrestricted Grammars"></a>5.3 Unrestricted Grammars</h4><ul><li><p>These previous arguments and examples do not form a mathematical <strong>proof</strong> that it is impossible to check static semantics using CFGs.</p></li><li><p>For a clear proof, using the pumping lemma for context-free languages (CFLs).</p></li><li><p>Contextual constraints result in <strong>context sensitive</strong>, or even <strong>recursively enumerable</strong>, languages:</p><ul><li>Recall the Chomsky hierarchy.</li><li>Such languages cannot be described by CFGs.</li></ul></li><li><p><strong>Unrestricted grammars</strong> with productions<br>$$<br>\alpha \rightarrow \beta,<br>$$<br>where $\alpha$ and $\beta$ are both <strong>arbitrary strings</strong>, could be used to express arbitrary contextual constraints.</p></li><li><p>Unrestricted grammars are, however, equivalent to Turing Machines in their expressive power.</p></li><li><p>Thus, to check contextual constraints, we must use Turing machines.</p></li><li><p>Simpler machines such as pushdown automata (PDAs) are not powerful enough.</p></li></ul><h4 id="5-4-Expressing-Contextual-Constraints"><a href="#5-4-Expressing-Contextual-Constraints" class="headerlink" title="5.4 Expressing Contextual Constraints"></a>5.4 Expressing Contextual Constraints</h4><p>Turing Machines are abstract models and Unrestricted Grammars are not very practical. Therefore, we consider the following approach:</p><ul><li>Specifying contextual constraints:<ul><li>Informally: using natural language.</li><li>Formally: using a mathematical formalism such as logical inference rules.</li></ul></li><li>Implementing contextual checks:<ul><li>General purpose programming languages.</li><li>Direct support of mathematical formalism, unifying specification and implementation.</li></ul></li></ul><h4 id="5-5-Contexual-Analysis"><a href="#5-5-Contexual-Analysis" class="headerlink" title="5.5 Contexual Analysis"></a>5.5 Contexual Analysis</h4><p>Two important contextual constraints on which we will focus in this course:</p><ul><li><strong>Scope rules</strong>: where in a program a declaration is valid.</li><li><strong>Type rules</strong>: ensuring that every expression computes a value of acceptable form, i. e., has a valid type.</li></ul><p>Corresponding subphrases of the contextual analysis:</p><ul><li><strong>Identification</strong> or <strong>Name Resolution</strong>: applying the scope rules in order to relate each applied identifier occurrence to its declaration.</li><li><strong>Type checking</strong>: applying the type rules to infer the type of each expression, and compare it with the expected type.</li></ul><p>Note that, there exist other kinds of contextual constraints in common programming languages.</p><p>For instance, Java has rules concerning:</p><ul><li><strong>Abstract class</strong>; e. g.:<ul><li>Only abstract classes may have abstract methods.</li><li>Abstract classes may not be instantiated.</li></ul></li><li><strong>Final classes</strong>; e. g.:<ul><li>a final class cannot be extended.</li><li>a class cannot be both final and abstract.</li></ul></li><li><strong>Exceptions</strong>; e. g., the set of exceptions that a method can raise must be declared (except for unchecked exceptions).</li><li><strong>Definite assignment</strong>: Each local variable and every blank final field must have a definitely assigned value when any access of its value occurs.</li></ul><h4 id="5-6-Identification"><a href="#5-6-Identification" class="headerlink" title="5.6 Identification"></a>5.6 Identification</h4><p><strong>Identification</strong> (or <strong>Name Resolution</strong>) is the task of relating each <strong>applied</strong> identifier occurrence to its <strong>declaration</strong>.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-22 at 2.57.02 PM.png" style="zoom:50%;"><p>In the body of set, the applied occurrence of:</p><ul><li>$x$ refers to the <strong>instance variable</strong> $x$.</li><li>$n$ refers to the <strong>argument</strong> $n$, not the instance variable $n$.</li></ul><h4 id="5-7-Scope-and-Scope-Rules"><a href="#5-7-Scope-and-Scope-Rules" class="headerlink" title="5.7 Scope and Scope Rules"></a>5.7 Scope and Scope Rules</h4><p>The identification process is governed by the <strong>scope rules</strong> of the language.</p><p>Important terms:</p><ul><li><strong>Scope</strong>: the section of a program over which a declaration takes effect.</li><li><strong>Block</strong>: a program phrase that delimits the scope of declarations within it.</li></ul><p>Consider the MiniTriangle $let$ block command: $let$ <em>decls</em> $in$ <em>body</em></p><p>The scope of each declaration is the rest of the block.</p><p>For example:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-22 at 3.02.05 PM.png" style="zoom:50%;"><p>In contrast with MiniTriangle, in Haskellâ€™s let-expression: $let$ <em>id = expr</em> $in$ <em>body</em></p><p>the scope of <em>id</em> includes both <em>expr</em> and <em>body</em>.</p><p>For example:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-22 at 3.10.09 PM.png" style="zoom:50%;"><p>In addition to deciding the range of declarations, the scope rules also deal with issues such as:</p><ul><li>whether explicit declarations are required;</li><li>whether multiple declarations at the same level are allowed;</li><li>whether shadowing/hiding is allowed.</li></ul><p>Let us now consider a version of Mini-Triangle extended with procedures and functions.</p><ul><li>The scope of a declared entity is extended to include the bodies of <strong>all</strong> procedures and functions declared in the same let-block.</li><li>This allows procedures and functions to be (mutually) recursive.</li><li>However, definition/initialization expressions for constants/variables must not use functions defined in the same let-block.<ul><li>This avoids calling function that may refer to as-yet uninitialized variables.</li></ul></li></ul><p>With the above scope rule, it is possible to write programs such as:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 8.19.49 PM.png" style="zoom:50%;"><h4 id="5-8-Some-Java-Scope-Rules"><a href="#5-8-Some-Java-Scope-Rules" class="headerlink" title="5.8 Some Java Scope Rules"></a>5.8 Some Java Scope Rules</h4><p>From the Java Language Specification ver. 1.0:</p><ul><li>The scope of a member declared in, or inherited by, a class type or interface type, is the <em>entire</em> declaration of the class or interface type.</li><li>The declaration of a member needs to appear before it is used only when the use is in a field initialization.</li><li>The scope of a parameter of a method is the entire body of the method.</li><li>Hiding the name of a local variable is not permitted.</li></ul><h4 id="5-9-Symbol-Table"><a href="#5-9-Symbol-Table" class="headerlink" title="5.9 Symbol Table"></a>5.9 Symbol Table</h4><p>A <strong>symbol table</strong>, also called <strong>identification table</strong> or <strong>environment</strong>, is used during identification to keep track of <strong>symbols</strong> and their <strong>attributes</strong>, such as:</p><ul><li>kind of symbol (class name, local variable, etc.)</li><li>scope level</li><li>type</li><li>source code position</li></ul><h4 id="5-10-Block-Structure"><a href="#5-10-Block-Structure" class="headerlink" title="5.10 Block Structure"></a>5.10 Block Structure</h4><p>The organization of the symbol table depends on the source languageâ€™s <strong>block structure</strong>:</p><ul><li><strong>Monolithic block structure</strong>: one common, global scope.</li><li><strong>Flat block strucrure</strong>: blocks with local scope enclosed in a global scope.</li><li><strong>Nested block structure</strong>: blocks can be nested to arbitrary depth.</li></ul><p>We focus on <strong>nested block structure</strong> because:</p><ul><li>Nested block structure is by far the most common in modern high-level languages.</li><li>Monolithic and flat block structures may be considered special cases of nested block structure.</li></ul><h4 id="5-11-Using-the-Symbol-Table"><a href="#5-11-Using-the-Symbol-Table" class="headerlink" title="5.11 Using the Symbol Table"></a>5.11 Using the Symbol Table</h4><p>For a simple language with:</p><ol><li>a declare-before-use rule and</li><li>redeclarations not allowed,</li></ol><p>during identification, the symbol table would be used as follows:</p><ul><li>Initialize the table; e. g., enter the standard environment.</li><li>When a declaration is encountered:<ul><li>check if declared identifier clashes with existing symbol;</li><li>if it does, then report error;</li><li>if not, then enter the declared identifier into the table, along with its attributes.</li></ul></li><li>When an applied identifier occurrence is encountered:<ul><li>look up the identifier in the table, taking scope rules into account;</li><li>if the identifier is not found, then report error;</li><li>if found, then annotate the applied occurrence with symbol attributes from the table.</li></ul></li></ul><p>Before identification:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 8.38.19 PM.png" style="zoom:50%;"><p>After identification:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 8.38.50 PM.png" style="zoom:50%;"><p>(Textual representation of annotated abstract syntax tree (AST).)</p><p>Suppose variables have to be declared, and that redeclarations are not allowed.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 8.41.00 PM.png" style="zoom:50%;"><p>During symbol table insert and lookup it would be discovered that:</p><ul><li>$x$ is declared twice at the same scope level,</li><li>$y$ is not declared at all.</li></ul><ul><li>When entering a new block, arrange so that symbols that are entered subsequently become associated with the scope corresponding to the block (<strong>â€œopen scopeâ€</strong>).</li><li>When leaving a block, remove/make inaccessible symbols declared in that block (<strong>â€œclose scopeâ€</strong>).</li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 8.45.31 PM.png" style="zoom:50%;"><ul><li>A new scope is opened for the inner let-block (on line 3) when it is analyzed.</li><li>When the inner let-block has been analyzed, its scope is closed.</li><li>It is then discovered that $y$ (at the end of line 3) is no longer in scope. ($x$ is, however, still in scope.)</li></ul><h4 id="5-12-Summary"><a href="#5-12-Summary" class="headerlink" title="5.12 Summary"></a>5.12 Summary</h4><ul><li>Contextual analysis includes checking scope rules and types.</li><li>Contextual constraints lead to <strong>context-sensitive</strong> languages and thus cannot be captured by a context-free grammar.</li><li><strong>Identification</strong> is the task of relating each <strong>applied</strong> identifier occurrence to its declaration. This is a key step for any contextual analysis.</li><li>The <strong>Symbol Table</strong> or <strong>Environment</strong> records information about declared entities and is the central data structure during contextual analysis.</li></ul><h3 id="6-Types-and-Type-Systems"><a href="#6-Types-and-Type-Systems" class="headerlink" title="6. Types and Type Systems"></a>6. Types and Type Systems</h3><h4 id="6-1-Types-and-Type-Systems"><a href="#6-1-Types-and-Type-Systems" class="headerlink" title="6.1 Types and Type Systems"></a>6.1 Types and Type Systems</h4><p>Type systems that we study in this course are an example of <strong>lightweight formal methods</strong>, in that they are:</p><ul><li>highly automated</li><li>but with limited expressive power.</li></ul><p>Note that:</p><ul><li><p>The aim of <strong>static checking</strong> is to prove <strong>absence</strong> of certain errors.</p></li><li><p>Done by <strong>classifying</strong> syntactic phrases (or <strong>terms</strong>) according to the <strong>kinds</strong> of values they compute:</p><ul><li>A type system computes a <strong>static approximation</strong> of the run-time behavior.</li></ul></li><li><p>Example:</p><ul><li>If we know that two program fragments $exp_1$ and $exp_2$ compute integers (<strong>classification</strong>), then it is safe to add those numbers together (<strong>absence of errors</strong>)</li><li>We also know that the result is an integer.</li><li>While we do not know what the values are, we know for sure that they are integers and nothing else (<strong>static approximation</strong>).</li></ul></li><li><p><strong>Dynamically typed</strong> languages do not have a type system according to this definition.</p><ul><li>Perhaps, <strong>â€˜dynamically checkedâ€™</strong> is a more appropriate phrase for describing these languages.</li></ul></li></ul><p>A type system is necessarily <strong>conservative</strong>, in the sense that, some well-behaved programs will be rejected.</p><ul><li><p>For example, typically:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 9.48.26 PM.png" style="zoom:50%;"><p>will be rejected as ill-typed, even if we know that complex_test always evaluates to true.</p></li><li><p>The reason is that, in general, these tests cannot be automatically proved.</p></li></ul><p>A type system checks for <strong>certain</strong> kinds of bad program behavior (<strong>run-time errors</strong>). Exactly which depends on the type system and the language design.</p><p>For example: current main-stream type systems typically:</p><ul><li><strong>do check</strong> that arithmetic operations are done only on numbers;</li><li><strong>do not check</strong> that the second operand of division is not zero, or that array indices are within bounds.</li></ul><p>The <strong>safety</strong> or <strong>soundness</strong> of a type system must be judged with respect to its own set of run-time errors.</p><h4 id="6-2-Language-Safety"><a href="#6-2-Language-Safety" class="headerlink" title="6.2 Language Safety"></a>6.2 Language Safety</h4><ul><li>Programming languages typically make a distiction between normal program actions and erroneous actions.</li><li>For Turing-complete languages (such as C, Java, Haskell, Python, etc.) it is impossible to decide (statically) whether a program will end up in an error or not. In fact, even simpler problems-e. g., checking whether a program terminates or not-may not be decidable</li><li>The only option is to run the code and see.</li><li>In a safe programming language, errors are <strong>trapped</strong> as they happen.</li><li>Java, for example, is largely safe via its exception system.</li><li>In an <strong>unsafe</strong> programming language, errors are not trapped.</li><li>After executing an erroneous operation, the computation continues, but in a silent and faulty way that may have severe consequences.</li><li>C and C++ are unsafe in a strong sense:<ul><li>executing an erroneous operation causes the entire program to be meaningless,</li><li>as opposed to just the erroneous operation having an unpredictable result.</li></ul></li><li>In these languages, erroneous operations are said to have undefined behavior.</li><li>Language safety is <strong>not</strong> the same as static typing:<ul><li>Safety can be achieved through static typing <strong>and/or</strong> dynamic run-time checks.</li><li>There are languages that are dynamically checked and safe, e. g., <strong>Lisp</strong>.</li></ul></li><li>A statically typed language may also perform dynamic checks, e. g.:<ul><li>checking of array bounds</li><li>down-casting (e. g., Java)</li><li>checking for division by zero</li><li>pattern-matching failure</li></ul></li></ul><p>Some examples of statically and dynamically checked safe and unsafe high-level languages:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-23 at 10.08.48 PM.png" style="zoom:50%;"><h4 id="6-3-Advantages-of-Typing"><a href="#6-3-Advantages-of-Typing" class="headerlink" title="6.3 Advantages of Typing"></a>6.3 Advantages of Typing</h4><ul><li><strong>Detecting errors earlier</strong>: Programs in richly typed languages often â€œjust workâ€, for the following reasons:<ul><li>Many of the simple and common mistakes arise from type inconsistencies.</li><li>Programmers are forced to think a bit more before coding.</li></ul></li><li><strong>Enforcing disciplined programming</strong>: Type systems form the backbone of:<ul><li>Modules</li><li>Classes</li></ul></li><li><strong>Documentation</strong>:<ul><li>Unlike comments, type signatures will always remain current.</li></ul></li><li><strong>Efficiency</strong>:<ul><li>First use of types in computing was to distinguish between integer and floating point numbers.</li><li>This led to the elimination of many of the dynamic checks that otherwise would have been needed to guarantee safety.</li></ul></li></ul><h4 id="6-4-Disadvantages-of-Typing"><a href="#6-4-Disadvantages-of-Typing" class="headerlink" title="6.4 Disadvantages of Typing"></a>6.4 Disadvantages of Typing</h4><ul><li>Type systems sometimes do get in the way:<ul><li>Simple concepts may require complicated coding if one has to work around the type system, e. g., heterogeneous lists in Haskell.</li><li>Sometimes it becomes impossible to do what one wants to do, at least not without loss of efficiency.</li></ul></li><li>Increasingly sophisticated type systems can help. But that can make the type systems harder to understand and less automatic.</li></ul><h4 id="6-5-Static-and-Dynamic-Semantics"><a href="#6-5-Static-and-Dynamic-Semantics" class="headerlink" title="6.5 Static and Dynamic Semantics"></a>6.5 Static and Dynamic Semantics</h4><p>In summary:</p><ul><li>A type system <strong>statically</strong> proves properties about the <strong>dynamic</strong> behavior of a program.</li><li>To make precise exactly what these properties are, and formally <strong>prove</strong> that a type system achieves its goals, both of the following must be formalized first:<ul><li><strong>static semantics</strong>,</li><li><strong>dynamic semantics</strong>.</li></ul></li></ul><h4 id="6-6-Example-Language-Abstract-Syntax"><a href="#6-6-Example-Language-Abstract-Syntax" class="headerlink" title="6.6 Example Language: Abstract Syntax"></a>6.6 Example Language: Abstract Syntax</h4><p>Example language. (Will be extended later.)</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 12.46.56 PM.png" style="zoom:50%;"><h4 id="6-7-Values"><a href="#6-7-Values" class="headerlink" title="6.7 Values"></a>6.7 Values</h4><ul><li>The <strong>values</strong> of a language are a subset of the terms that are <strong>possible results of evaluation</strong>.</li><li>In other words, values are the <strong>meaning</strong> of terms according to the <strong>dynamic semantics</strong> of the language.</li><li>A term is <strong>reduced</strong> using a given set of evaluation rules until a value is obtained, at which point no further reduction is possible.<ul><li>For instance, <strong>pred(succ(0))</strong> may be reduced to <strong>0</strong>, at which point, no further reduction is possible.</li></ul></li><li>In general, a term to which no (further) evaluation rule applies is said to be in <strong>normal form</strong>.</li><li>All values are in normal form.</li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 12.52.24 PM.png" style="zoom:50%;"><h4 id="6-8-One-Step-Evaluation-Relation"><a href="#6-8-One-Step-Evaluation-Relation" class="headerlink" title="6.8 One Step Evaluation Relation"></a>6.8 One Step Evaluation Relation</h4><p>$t\rightarrow tâ€™$ is an <strong>evaluation relation</strong> on terms.</p><p><strong>Read</strong>: $t$ evaluates to $tâ€™$ in one step.</p><p>The evaluation relation constitutes an <strong>operational</strong> (dynamic) <strong>semantics</strong> for the example language.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 12.55.09 PM.png" style="zoom:50%;"><ul><li><p>Evaluation Relation</p><ul><li><p>Recall that a <strong>relation</strong> between two sets $X$ and $Y$ is just a subset of $X\times Y$.</p></li><li><p>For example, the â€œless than or equalâ€ relation $\le$ on $N$ is a subset of $N\times N$, and we have:</p><p>${(1,1),(1,2),(1,3),(2,2),(2,3)} \subseteq (\le)$</p></li><li><p>The â€œone step evaluationâ€ is a relation on <strong>terms</strong>. <strong>One term is related to another iff the first evaluates to the second in one step</strong>.</p></li><li><p>For example:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.11.41 PM.png" style="zoom:50%;"></li><li><p>The evaluation relation is infinite. Hence, we cannot enumerate all pairs.</p></li><li><p>Instead, (schematic) <strong>inference rules</strong> are used to specify relations:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.13.50 PM.png" style="zoom:50%;"></li><li><p>If there are no premises, the line is often omitted:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.14.56 PM.png" style="zoom:50%;"></li><li><p><strong>Schematic</strong> means that universally quantified variables are allowed in the rules.</p></li><li><p>For example, the following holds <strong>for all</strong> $t_2$ and $t_3$:</p></li><li><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.20.09 PM.png" style="zoom:50%;"></li><li><p>In other words, such a <strong>rule schema</strong> actually stands for an <strong>infinite set</strong> of rules:</p></li><li><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.21.07 PM.png" style="zoom:50%;"></li><li><p>The <strong>domain</strong> of a variable is often specified by <strong>naming conventions</strong>.</p></li><li><p>For example, the name of a variable may indicate some specific <strong>syntactic category</strong> such as $t$ (for terms), $v$ (for values), or $nv$ (for numeric values):</p></li><li><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.22.48 PM.png" style="zoom:50%;"></li></ul></li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.35.35 PM.png" style="zoom:50%;"><p><strong>Note:</strong> We have the rule $\text{pred}\ 0 \rightarrow 0$ instead of $\text{pred}\ 0$ reducing to $-1$ because the domain of our numeric values is the set of natural numbers $N = {0,1,2,\cdots}$.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-24 at 1.37.47 PM.png" style="zoom:50%;"><h4 id="6-9-Values-and-Stuck-Terms"><a href="#6-9-Values-and-Stuck-Terms" class="headerlink" title="6.9 Values and Stuck Terms"></a>6.9 Values and Stuck Terms</h4><p>Note that:</p><ul><li><strong>Values</strong> cannot be evaluated further, e. g.:<ul><li><strong>true</strong></li><li>$0$</li><li>$\text{succ}(\text{succ}\ 0)$</li></ul></li><li>Certain â€œobviously nonsensicalâ€ states result in the computation process <strong>getting stuck</strong>: the term cannot be evaluated further, but it is not a value.</li><li>Definition: A term is <strong>stuck</strong> if it is a normal form but not a value.</li><li>Why stuck?<ul><li>The program is <strong>not well-defined</strong> according to the dynamic semantics of the language.</li><li>The <strong>abstractions</strong> of the language are being <strong>broken</strong>.</li></ul></li></ul><h4 id="6-10-Stuckness-and-Run-Time-Errors"><a href="#6-10-Stuckness-and-Run-Time-Errors" class="headerlink" title="6.10 Stuckness and Run-Time Errors"></a>6.10 Stuckness and Run-Time Errors</h4><ul><li>The notion of <strong>getting stuck</strong> models <strong>run-time errors</strong>.</li><li>The <strong>goal</strong> of a type system is to <strong>guarantee</strong> that a program <strong>never gets stuck</strong> in this manner.</li></ul><h4 id="6-11-Why-Should-We-Care-About-Safety"><a href="#6-11-Why-Should-We-Care-About-Safety" class="headerlink" title="6.11 Why Should We Care About Safety?"></a>6.11 Why Should We Care About Safety?</h4><ul><li>One reason: security.</li><li>C and C++ are unsafe: <strong>buffer overruns</strong> are possible.</li><li>Buffer overruns allow input data to be executed as code.</li><li>This is one of the most common security holes. In other words, had a safe variant of C been used, one might speculate that billions of dollars would have been saved.</li></ul><h4 id="6-12-Types"><a href="#6-12-Types" class="headerlink" title="6.12 Types"></a>6.12 Types</h4><p>At this point, there are only two <strong>types</strong>, booleans and the natural numbers:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-26 at 9.32.56 PM.png" style="zoom:50%;"><h4 id="6-13-Typing-Relation"><a href="#6-13-Typing-Relation" class="headerlink" title="6.13 Typing Relation"></a>6.13 Typing Relation</h4><p>We will define a <strong>typing relation</strong> between terms and types:</p><p>$t:T$</p><p>Read:</p><p>$t$ has type $T$</p><ul><li>A term that has a type, i. e., is related to a type by such a typing relation, is said to be <strong>well-typed</strong>.</li><li>The typing relation will be defined by (schematic) typing rules, in the same way as we defined the evaluation relation.</li></ul><h4 id="6-14-Typing-Rules"><a href="#6-14-Typing-Rules" class="headerlink" title="6.14 Typing Rules"></a>6.14 Typing Rules</h4><img src="/2021/10/02/Compiler/Screen Shot 2021-12-26 at 9.35.40 PM.png" style="zoom:50%;"><h4 id="6-15-Safety-Progress-Preservation"><a href="#6-15-Safety-Progress-Preservation" class="headerlink" title="6.15 Safety = Progress + Preservation"></a>6.15 Safety = Progress + Preservation</h4><ul><li>An important reason for having a type system is <strong>safety</strong>.</li><li>In other words, <strong>â€œwell typed programs do not go wrongâ€</strong>, where â€œwrongâ€ means entering a â€œstuck stateâ€.</li></ul><p>This breaks down into two parts:</p><p><strong>Progress</strong>: A well-typed term is not stuck.</p><p><strong>Preservation</strong>: If a well-typed term is evaluated one step, then the resulting term is also well-typed (and has the same type).</p><p>Together, these two properties say that a well-typed term can never reach a stuck state during evaluation.</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-26 at 9.39.47 PM.png" style="zoom:50%;"><h4 id="6-16-Exceptions"><a href="#6-16-Exceptions" class="headerlink" title="6.16 Exceptions"></a>6.16 Exceptions</h4><p>What about terms such as the following that are (usually) considered well-typed?</p><ul><li>division by zero</li><li>head of empty list</li><li>array indexing out of bounds (buffer overrun)</li></ul><p>If the type system does not rule them out, we need to differentiate those from stuck terms, or we can no longer claim that â€œwell-typed programs do not go wrongâ€.</p><p><strong>Idea</strong>: Allow <strong>exceptions</strong> to be raised, and make it <strong>well-defined</strong> what happens when exceptions are raised.</p><p>For example:</p><ul><li><p>introduce a term <strong>error</strong></p></li><li><p>introduce evaluation rules like</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-26 at 9.47.29 PM.png" style="zoom:50%;"></li><li><p>typing rule: $error: T$</p></li><li><p>Introduce <strong>propagation rules</strong> to ensure that the <strong>entire</strong> program evaluates to <strong>error</strong> once the exception has been raised, unless there is some exception handling mechanism.</p></li><li><p>Change the Progress theorem slightly to allow for exceptions:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-26 at 9.49.42 PM.png" style="zoom:50%;"></li></ul><h4 id="6-17-Extension-Let-bound-Variables"><a href="#6-17-Extension-Let-bound-Variables" class="headerlink" title="6.17 Extension: Let-bound Variables"></a>6.17 Extension: Let-bound Variables</h4><p>Syntactic extension:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 9.53.13 PM.png" style="zoom:50%;"><p>New evaluation rules:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 9.53.43 PM.png" style="zoom:50%;"><ul><li><p>We now need a <strong>typing context</strong> or <strong>type environment</strong> to keep track of types of variables.</p></li><li><p>This is an abstract version of a â€œsymbol tableâ€/</p></li><li><p>The typing relation thus becomes a <strong>ternary relation</strong>:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.10.18 PM.png" style="zoom:50%;"><p><strong>Read:</strong> term $t$ has type $T$ in type environment $\Gamma$.</p></li></ul><p>Environment-related notation:</p><ul><li><p>Extending an environment:<br>$$<br>\Gamma, x : T<br>$$<br>The new declaration is understood to replace any earlier declaration for a variable with the same name.</p></li><li><p>Stating that the type of a variable is given by an environment:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.13.13 PM.png" style="zoom:50%;"></li></ul><p>Updating typing rules:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.13.43 PM.png" style="zoom:50%;"><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.15.23 PM.png" style="zoom:50%;"><p>New typing rules:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.15.47 PM.png" style="zoom:50%;"><p>Recursive bindings:</p><ul><li><p>Typing is straightforward if the recursively-defined entity is <strong>explicitly</strong> typed:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.17.04 PM.png" style="zoom:50%;"></li><li><p>If the recursively-defined entity is <strong>not explicitly</strong> typed, then the question is whether $T_1$ is uniquely defined (and in a type checker how to compute this type):</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.19.21 PM.png" style="zoom:50%;"></li></ul><h4 id="6-18-Introduction-to-lambda-Calculus"><a href="#6-18-Introduction-to-lambda-Calculus" class="headerlink" title="6.18 Introduction to $\lambda$-Calculus"></a>6.18 Introduction to $\lambda$-Calculus</h4><ul><li><p>Imperative languages (such as C, Java, and Python) are based on Turing machine model of computation.</p></li><li><p>In imperative languages, there is a clear distinction between <em>programs</em> and <em>data</em>:</p><p><strong>Programs</strong>: sequences of instructions that are executed sequentially;</p><p><strong>Data</strong>: values given as input, stored in memory, manipulated during computation, and returned as output.</p></li><li><p>Programs and data are distinct and are kept separated.</p></li><li><p>Programs are not modified during computation.</p><ul><li>Note that, in principle, it is possible to modify programs during computation, since they are stored in memory like any other data.</li><li>This approach is, however, very difficult to manage. Hence, it is generally avoided.</li></ul></li><li><p>In contrast, functional languages (such as Haskell and Lisp) are based on the $\lambda$-calculus model of computation.</p></li><li><p>In functional programming, there is no distiction between programs and data.</p><ul><li>Both are represented by terms/expressions belonging to the same language.</li><li>Computation consists in the <em>reduction</em> of terms to <em>normal forms</em>, including terms that represent functions, i. e., the programs themselves.</li></ul></li></ul><h4 id="6-19-Syntax-of-lambda-calculus"><a href="#6-19-Syntax-of-lambda-calculus" class="headerlink" title="6.19 Syntax of $\lambda$-calculus"></a>6.19 Syntax of $\lambda$-calculus</h4><ul><li>Lambda calculus is a pure theory of functions, i. e., all the objects are functions.<ul><li>The objects of $\lambda$-calculus are represented as $\lambda$-terms.</li><li>$\lambda$-terms represent both data structures and programs.</li></ul></li><li>As $\lambda$-calculus is a pure theory of functions, the construction of $\lambda$-terms is very simple.</li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.32.36 PM.png" style="zoom:50%;"><ul><li><p>At first glance, $\lambda$-terms seem rather limited:</p><ul><li>no numbers;</li><li>no arithmetic operations;</li><li>no data structures;</li><li>no programming primitives;</li><li>â€¦</li></ul></li><li><p>It turns out that we do not really need them!</p></li><li><p>All (computable) numbers and operations can be defined as purely functional constructions, built using only abstraction and application.</p></li><li><p>Nonetheless, for thr purposes of this lesson, we use some operations and numbers without defining them as $\lambda$-terms.</p></li><li><p>Furthermore, we will not work within the framework of pure $\lambda$-calculus. Instead, we just add some concepts from $\lambda$-calculus to our example language.</p></li><li><p>As an example, let $t:= x^2+1$.</p></li><li><p>By <strong>abstracting</strong> $x$, we are designating this variable as an â€˜inputâ€™ argument to the function that:</p><ul><li>takes the input of $x$;</li><li>squares it;</li><li>then adds 1 to the result.</li></ul></li><li><p>This function is written as $\lambda x.x^2+1$.</p></li><li><p>Finally, the function $\lambda x.x^2+1$ is applied on any given argument using <strong>application</strong>.</p></li><li><p>As another example, let $s:=x^2+y$.</p></li><li><p>By abstracting $x$ and $y$, we are designating these two variables as the â€˜inputâ€™ arguments to the function that:</p><ul><li>takes the inputs $x$ and $y$;</li><li>squares $x$;</li><li>then adds $y$ to the result.</li></ul></li><li><p>This function is written as $\lambda x.\lambda y.x^2+y$, or simply $\lambda xy.x^2+y$.</p></li><li><p>Now, we expect the result of:</p><ul><li>$((\lambda xy.x^2+y)3)5$</li></ul><p>to be $3^2+5=14$.</p></li></ul><h4 id="6-20-Some-conventions"><a href="#6-20-Some-conventions" class="headerlink" title="6.20 Some conventions"></a>6.20 Some conventions</h4><ul><li>For convenience, we use some conventions that allow us to save on parentheses:<ul><li>Application associates to the left. Hence, we write $(t_1t_1t_3)$ for $((t_1t_2)t_3)$;</li><li>$\lambda$-abstraction associates to the right. Thus, we write $\lambda x.\lambda y.x$ for $\lambda x.(\lambda y.x)$;</li><li>We can use a single $\lambda$ symbol followed by several variables to mean consecutive abstractions. So, we write $\lambda xy.x$ for $\lambda x.\lambda y.x$.</li></ul></li></ul><h4 id="6-21-Variables-in-lambda-calculus"><a href="#6-21-Variables-in-lambda-calculus" class="headerlink" title="6.21 Variables in $\lambda$-calculus"></a>6.21 Variables in $\lambda$-calculus</h4><ul><li>In $\lambda$-calculus, variables serve a different function to that of imperative programming.</li><li>In $\lambda$-calculus, <em>and as a consequence, pure functional programming</em>, a variable $x$ is just a place-holder to denote any possible value.</li><li>In imperative programming, on the other hand, variables represent mamory locations containing values that can be modified.</li><li>In other words, in pure functional programming, variables are <em>immutable</em>, while in imperative programming, they are <em>mutable</em>.</li></ul><h4 id="6-22-beta-reduction-beta-reduction"><a href="#6-22-beta-reduction-beta-reduction" class="headerlink" title="6.22 beta-reduction ($\beta$-reduction)"></a>6.22 beta-reduction ($\beta$-reduction)</h4><ul><li>As $\lambda$-calculus is a model of computation, we need to describe how a basic computation step is carried out over $\lambda$-terms.</li><li>In computing $(\lambda x.x^2+1)3$, we substitute 3 for the variable $x$ in the <em>body</em> of the function $\lambda x.x^2 +1$, to obtain $3^2+1=10$.</li><li>This is called $\beta$-reduction.<ul><li>It is essentially the only kind of computation done in $\lambda$-calculus.</li></ul></li><li>Let $t[x:=t_2]$ denote the term obtained from $t_1$ by substituting all occurrences of the variable $x$ with the term $t_2$.</li></ul><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.52.06 PM.png" style="zoom:50%;"><h4 id="6-23-Extension-Functions"><a href="#6-23-Extension-Functions" class="headerlink" title="6.23 Extension: Functions"></a>6.23 Extension: Functions</h4><p>Now, we return to our example language, and extend its syntax, as follows:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.53.37 PM.png" style="zoom:50%;"><p>New evaluation rules:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.54.02 PM.png" style="zoom:50%;"><p>Note:</p><ul><li><strong>Left to right evaluation order</strong>: first the function (E-APP1), then the argument (E-APP2).</li><li><strong>Call-by-value</strong>: the argument fully evaluated before function â€œinvokedâ€ (E-APPABS).</li></ul><p>New typing rules:</p><img src="/2021/10/02/Compiler/Screen Shot 2021-12-28 at 10.55.37 PM.png" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Compiler </tag>
            
            <tag> Continuously updated </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce Paradigm</title>
      <link href="2021/09/17/MapReduce-Paradigm/"/>
      <url>2021/09/17/MapReduce-Paradigm/</url>
      
        <content type="html"><![CDATA[<h4 id="1-What-is-MapReduce"><a href="#1-What-is-MapReduce" class="headerlink" title="1. What is MapReduce?"></a>1. What is MapReduce?</h4><ul><li><p>Terms are borrowed from Functional Language (e.g., Lisp)</p></li><li><p>Example: Sum of Square</p><ul><li><p>(map square â€˜(1 2 3 4))</p><ul><li>Output: (1 4 9 16)</li><li>processes each record sequentially and independently</li></ul></li><li><p>(reduce + â€˜(1 4 9 16))</p><ul><li><p>(+ 16 (+ 9 (+ 4 1)))</p></li><li><p>Output: 30</p></li><li><p>processes set of all records in batches</p></li></ul></li></ul></li><li><p><strong>Map</strong></p><ul><li>Parallelly Process a large number of individual records to generate intermediate key/value pairs</li></ul></li><li><p><strong>Reduce</strong></p><ul><li>Each key assigned to one Reduce</li><li>Parallelly Processes and merges all intermediate values by partitioning keys</li></ul></li></ul><h4 id="2-MapReduce-Scheduling"><a href="#2-MapReduce-Scheduling" class="headerlink" title="2. MapReduce Scheduling"></a>2. MapReduce Scheduling</h4><ul><li><p>Programming MapReduce</p><ul><li><p>Externally: For user</p><ol><li>Write a Map program (short), write a Reduce program (short)</li><li>Submit job: wait for result</li><li>Need to know nothing about parallel/distributed programming</li></ol></li><li><p>Internally: For the Paradigm and Scheduler</p><ol><li>Parallelize Map</li><li>Transfer data from Map to Reduce</li><li>Parallelize Reduce</li><li>Implement Storage for Map input, Map output, Reduce input and Reduce output</li></ol><p>(Ensure that no Reduce starts before all Maps are finished. That is, ensure the <em><strong>barrier</strong></em> between the Map phase and Reduce phase)</p></li></ul></li><li><p>Inside MapReduce</p><ul><li>For the cloud:<ol><li>Parallelize Map: each map task is independent of the other<ul><li>All Map outpur records with same key assigned to same Reduce</li></ul></li><li>Transfer data from Map to Reduce:<ul><li>All Map output records with same key assigned to same Reduce task</li><li>use partitioning function</li></ul></li><li>Parallelize Reduce: each reduce task is independent of the other</li><li>Implement Storage for Map input, Map output, Reduce input, and Reduce output<ul><li>Map input: from distributed file system</li><li>Map output: to local disk (at Map node); uses local file system</li><li>Reduce input: from (multiple) remote disks; uses local file systems</li><li>Reduce output: to distributed file system</li></ul></li></ol></li></ul></li><li><p><strong>The YARN Scheduler</strong></p><ul><li><p>Used in Hadoop 2.x +</p></li><li><p>YARN = Yet Another Resource Negotiator</p></li><li><p>Treats each server as a collection of <em>containers</em></p><ul><li>Container = some CPU + some memory</li></ul></li><li><p>Has 3 main components</p><ul><li><p>Global <em>Resource Manager (RM)</em></p><ul><li>Scheduling</li></ul></li><li><p>Per-server <em>Node Manager (NM)</em></p><ul><li>Daemon and server-specific functions</li></ul></li><li><p>Per-application (job) <em>Application Master (AM)</em></p><ul><li><p>Container negotiation with RM and NMs</p></li><li><p>Detecting task failures of that job</p></li></ul></li></ul></li><li><img src="/2021/09/17/MapReduce-Paradigm/Screen Shot 2021-09-17 at 1.58.30 PM.png" style="zoom:50%;"></li></ul></li></ul><h4 id="3-MapReduce-Fault-Tolerance"><a href="#3-MapReduce-Fault-Tolerance" class="headerlink" title="3. MapReduce Fault-Tolerance"></a>3. MapReduce Fault-Tolerance</h4><ul><li>Server Failure<ul><li>NM heartbeats to RM<ul><li>If server fails, RM lets all affected Ams know, and AMs take action</li></ul></li><li>NM keeps track of each task running at its server<ul><li>If task fails while in-progress, mark the task as idle and restart it</li></ul></li><li>AM heartbeats to RM<ul><li>On failure, RM restarts AM, which then syncs up with its running tasks</li></ul></li></ul></li><li>RM Failure<ul><li>Use old checkpoints and bring up secondary RM</li></ul></li><li>Heartbeats also used to piggyback container requests<ul><li>Avoid extra messages</li></ul></li><li>Slow Servers<ul><li>The slowest machine slows the entire job down</li><li>Dueto Bad Disk, Network Bandwidth, CPU, or Memory</li><li>Keep track of â€œprogressâ€ of each task (% done)</li><li>Perform backup (replicated) execution of straggler task: task considered done when first replica complete. Called <strong>Speculative Execution</strong></li></ul></li><li>Locality<ul><li>Since cloud has hierarchical topology (e.g. racks)</li><li>GFS/HDFS stores 3 replicas of each of chunks<ul><li>Maybe on different racks</li></ul></li><li>Mapreduce attempts to schedule a map task on<ul><li>a machine that contains a replica of corresponding input data, or failing that,</li><li>on the same rack as a machine containing the input, or failing that,</li><li>Anywhere</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloud Computing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Introduction to Clouds</title>
      <link href="2021/09/12/Introduction-to-Clouds/"/>
      <url>2021/09/12/Introduction-to-Clouds/</url>
      
        <content type="html"><![CDATA[<h4 id="1-What-is-a-Cloud"><a href="#1-What-is-a-Cloud" class="headerlink" title="1. What is a Cloud?"></a>1. What is a Cloud?</h4><ul><li><p>Cloud = Lots of storage + compute cycles nearby</p></li><li><p>A single-site cloud (aka â€œDatacenterâ€) consists of</p><ul><li>Compute nodes (grouped into racks)</li><li>Switches, connecting the racks</li><li>A network topology, e.g. hierarchical</li><li>Storage (backend) nodes connected to the network</li><li>Front-end for submitting jobs and receiving client requests</li><li>Software Services</li></ul></li><li><p>A geographically distributed cloud consists of</p><ul><li>Multiple such sites</li><li>Each site perhaps with a different structure and services</li></ul></li></ul><h4 id="2-Whatâ€™s-new-in-todayâ€™s-clouds"><a href="#2-Whatâ€™s-new-in-todayâ€™s-clouds" class="headerlink" title="2. Whatâ€™s new in todayâ€™s clouds"></a>2. Whatâ€™s new in todayâ€™s clouds</h4><ul><li>Four features new in todayâ€™s clouds<ul><li>Massive scale.</li><li>On-demand access: Pay-as-you-go, no upfront commitment.<ul><li>Anyone can access it.</li></ul></li><li>Data-intensive Nature: What was MBs has now become TBs, PBs, and XBs.<ul><li>Daily logs, forensics, Web data, etc.</li><li>Humans have data numbness: Wikipedia (large) compress is only about 10 GB!</li></ul></li><li>New Cloud Programming Paradigms: MapReduce/Hadoop, NoSQL/Cassandra/MongoDB and many others.<ul><li>High in accessibility and ease of programmability.</li><li>Lots of open-source</li></ul></li></ul></li></ul><h4 id="3-New-Aspects-of-Clouds"><a href="#3-New-Aspects-of-Clouds" class="headerlink" title="3. New Aspects of Clouds"></a>3. New Aspects of Clouds</h4><ol><li>Massive Scale (easy to understand)</li><li>On-demand Access: *aaS Classification<ul><li>HaaS: Hardware as a Service<ul><li>You get access to barebones hardware machines, do whatever you want with them</li><li>Not always a good idea because of security risks</li></ul></li><li>IaaS: Infrastructure as a Service<ul><li>You get access to flexible computing and storage infrastructure. Virtualization is one way of achieving this. Often said to subsume HaaS.</li></ul></li><li>PaaS: Platform as a Service<ul><li>You get access to flexible computing and storage infrastructure, coupled with a software platform (often tightly)</li></ul></li><li>SaaS: Software as a Service<ul><li>You get access to software services, when you need them. Often said to subsume SOA (Service Oriented Architectures).</li></ul></li></ul></li><li>Data-intensive Computing<ul><li>Computation-Intensive Computing<ul><li>Example areas: MPI-based, High-performance computing, Grids</li><li>Typically run on supercomputers</li></ul></li><li>Data-Intensive<ul><li>Typically store data at datacenters</li><li>Use compute nodes nearby</li><li>Compute nodes run computation services</li></ul></li><li>In data-intensive computing, the <strong>focus shifts from computation to the data</strong>: CPU utilization no longer the most important resource metric, instead I/O is (disk and/or network)</li></ul></li><li>New Cloud Programming Paradigms<ul><li>Easy to write and run highly parallel programs in new cloud programming paradigms</li></ul></li></ol><h4 id="4-Economics-of-Clouds"><a href="#4-Economics-of-Clouds" class="headerlink" title="4. Economics of Clouds"></a>4. Economics of Clouds</h4><ul><li>Two categories of clouds<ul><li>Can either be a public cloud, or private cloud</li><li>Private clouds are accessible only to company employees</li><li>Public clouds provide service to any paying customer</li></ul></li><li>To Outsource or Own?</li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloud Computing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Learning Optimization Methods</title>
      <link href="2021/09/03/Deep-Learning-Optimization-Methods/"/>
      <url>2021/09/03/Deep-Learning-Optimization-Methods/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Exponentially-Weighted-Moving-Average-EWMA"><a href="#1-Exponentially-Weighted-Moving-Average-EWMA" class="headerlink" title="1. Exponentially Weighted Moving Average (EWMA)"></a>1. Exponentially Weighted Moving Average (EWMA)</h4><ul><li><p>The Exponentially Weighted Moving Average (EWMA) is a quantitative or statistical measure used to model or describe a time series.</p></li><li><p>The moving average is designed as such that older observations are given lower weights. The weights fall exponentially as the data input gets older.</p></li><li><p>The only decision a user of the EWMA (denoted by $v$) must take is the parameter <strong>beta</strong>. The parameter decides how important the current observation is in the calculation of the $v$. The higher the value of alpha, the more closely the $v$ racks the original time series.</p></li><li><p>Suppose given a series of data $x_1, x_2, \cdots, x_n$ï¼Œto fit a curve, we use following formula:</p><ul><li><p>$$<br>v_0 = 0\<br>v_1 = \beta \times v_0 + (1 - \beta) \times x_1\<br>v_2 = \beta \times v_1 + (1 - \beta) \times x_2\<br>\cdots\<br>v_t = \beta \times v_{t-1} + (1 - \beta) \times x_t<br>$$</p></li><li><img src="/2021/09/03/Deep-Learning-Optimization-Methods/Screen Shot 2021-09-11 at 11.31.19 AM.png" style="zoom:50%;"><p>$\beta = 0.9$</p></li></ul></li><li><p>$\beta = 0.98$, green line; $\beta = 0.5$, yellow line</p><img src="/2021/09/03/Deep-Learning-Optimization-Methods/Screen Shot 2021-09-11 at 11.35.13 AM.png" style="zoom:50%;"></li></ul><h4 id="2-Momentum"><a href="#2-Momentum" class="headerlink" title="2. Momentum"></a>2. Momentum</h4><ul><li><p>To solve the problem of large oscillating of mini-batch SGD when updating parameters.</p></li><li><p>Make the convergence speed faster.</p></li><li><p>Implementation details:</p><p>On iteration $t$:</p><p>â€‹        Compute $dW, db$ on the current mini-batch</p><p>â€‹        $v_{dW} = \beta v_{dw} + (1 - \beta)dW$</p><p>â€‹        $v_{db} = \beta v_{db} + (1 - \beta)db$</p><p>â€‹        $W = W - \alpha v_{dW}$</p><p>â€‹        $b = b - \alpha v_{db}$</p></li><li><p>Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.</p></li><li><p>You have to tune a momentum hyperparameter $\beta$ and a learning rate $\alpha$.</p></li></ul><h4 id="3-RMSprop"><a href="#3-RMSprop" class="headerlink" title="3. RMSprop"></a>3. RMSprop</h4><ul><li><p>Blue: Momentum; Green: RMSprop</p><img src="/2021/09/03/Deep-Learning-Optimization-Methods/Screen Shot 2021-09-11 at 11.50.06 AM.png" style="zoom:50%;"></li><li><p>Implementation details:</p><p>On iteration $t$:</p><p>â€‹        Compute $dW, db$ on the current mini-batch</p><p>â€‹        $s_{dW} = \beta_2 s_{dw} + (1 - \beta_2)dW^2$</p><p>â€‹        $s_{db} = \beta_2 s_{db} + (1 - \beta_2)db^2$</p><p>â€‹        $W = W - \alpha \frac{dW}{\sqrt{s_{dW}} + \epsilon}$</p><p>â€‹        $b = b - \alpha \frac{db}{\sqrt{s_{db}} + \epsilon}$</p></li><li><p>Generally, $\epsilon = 10^{-8}$ </p></li><li><p>Make the oscillating small</p></li></ul><h4 id="4-Adam"><a href="#4-Adam" class="headerlink" title="4. Adam"></a>4. Adam</h4><ul><li><p>The combination of <strong>Momentum</strong> and <strong>RMSprop</strong></p></li><li><p>Implementation details:</p><p>$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$</p><p>On iteration $t$:</p><p>â€‹        Compute $dW, db$ on the current mini-batch</p><p>â€‹        $v_{dW} = \beta_1 v_{dW} + (1 - \beta_1)dW, v_{db} = \beta_1 v_{db} + (1 - \beta_1)db$</p><p>â€‹        $s_{dW} = \beta_2 s_{dW} + (1 - \beta_2)dW^2, s_{db} = \beta_2 s_{db} + (1 - \beta_2)db^2$</p><p>â€‹        $v_{dW}^{corected} = \frac{v_{dW}}{1 - \beta_1^t}, v_{db}^{corected} = \frac{v_{db}}{1 - \beta_1^t}$</p><p>â€‹        $s_{dW}^{corrected} = \frac{s_{dW}}{1 - \beta_2^t}, s_{db}^{corrected} = \frac{s_{db}}{1 - \beta_2^t}$</p><p>â€‹        $W = W - \alpha \frac{v_{dW}^{corrected}}{\sqrt{s_{dW}^{corrected}} + \epsilon}, b = b - \alpha \frac{v_{db}^{corrected}}{\sqrt{s_{db}^{corrected}} + \epsilon}$</p></li><li><p>Since the moving average at the beginning of iteration will lead to a large difference from the initial value, we need to correct the deviation of the values.</p></li><li><p>Generally, $\beta_1 = 0.9, \beta_2 = 0.999, \epsilon = 10^{-8}$, $\alpha$ need to be tuned.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Optimization Methods </tag>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradient Descent Methods</title>
      <link href="2021/09/01/Gradient-Descent-Methods/"/>
      <url>2021/09/01/Gradient-Descent-Methods/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Batch-Gradient-Descent"><a href="#1-Batch-Gradient-Descent" class="headerlink" title="1. (Batch) Gradient Descent"></a>1. (Batch) Gradient Descent</h4><ul><li><p>All the training examples do gradient descent together</p></li><li><p>Advantages: better performance</p></li><li><p>Disadvantages: if dataset is too big, the training process will be slow</p></li><li><p>Code example:</p><pre class="line-numbers language-python"><code class="language-python">X <span class="token operator">=</span> data_inputY <span class="token operator">=</span> labelsparameters <span class="token operator">=</span> initialize_parameters<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Forward propagation</span>    a<span class="token punctuation">,</span> caches <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Compute cost.</span>    cost <span class="token operator">+=</span> compute_cost<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Backward propagation.</span>    grads <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>a<span class="token punctuation">,</span> caches<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Update parameters.</span>    parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h4 id="2-Stochastic-Gradient-Descent"><a href="#2-Stochastic-Gradient-Descent" class="headerlink" title="2. Stochastic Gradient Descent"></a>2. Stochastic Gradient Descent</h4><ul><li><p>Computing gradients on just one training example at a time, rather than on the whole training set</p></li><li><p>Advantages: speed up convergence</p></li><li><p>Disadvantages: the parameters will â€œoscillateâ€ toward the minimum rather than converge smoothly</p><img src="/2021/09/01/Gradient-Descent-Methods/Screen Shot 2021-09-09 at 2.48.18 PM.png" style="zoom:50%;"></li><li><p>Code example:</p><pre class="line-numbers language-python"><code class="language-python">X <span class="token operator">=</span> data_inputY <span class="token operator">=</span> labelsparameters <span class="token operator">=</span> initialize_parameters<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Forward propagation</span>        a<span class="token punctuation">,</span> caches <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Compute cost</span>        cost <span class="token operator">+=</span> compute_cost<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Backward propagation</span>        grads <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>a<span class="token punctuation">,</span> caches<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Update parameters.</span>        parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h4 id="3-Mini-batch-Gradient-Descent"><a href="#3-Mini-batch-Gradient-Descent" class="headerlink" title="3. Mini-batch Gradient Descent"></a>3. Mini-batch Gradient Descent</h4><ul><li><p>The number of training examples that do gradient descent at a time is $n (1\lt n\lt m)$</p></li><li><p>If $n = 1$, it becomes stochastic gradient descent; if $n=m$, it becomes batch gradient descent</p></li><li><p>Advantages: more smooth than SGD, faster than BGD</p><img src="/2021/09/01/Gradient-Descent-Methods/Screen Shot 2021-09-09 at 3.04.00 PM.png" style="zoom:50%;"></li><li><p>Disadvantages: one more hyper parameter <strong>batch_size</strong> need to be tuned</p></li><li><p>Code example:</p><ul><li><p>First, random mini batches</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># GRADED FUNCTION: random_mini_batches</span><span class="token keyword">def</span> <span class="token function">random_mini_batches</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> mini_batch_size <span class="token operator">=</span> <span class="token number">64</span><span class="token punctuation">,</span> seed <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Creates a list of random minibatches from (X, Y)        Arguments:    X -- input data, of shape (input size, number of examples)    Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)    mini_batch_size -- size of the mini-batches, integer        Returns:    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)    """</span>        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># To make your "random" minibatches the same as ours</span>    m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                  <span class="token comment" spellcheck="true"># number of training examples</span>    mini_batches <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># Step 1: Shuffle (X, Y)</span>    permutation <span class="token operator">=</span> list<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">)</span>    shuffled_X <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> permutation<span class="token punctuation">]</span>    shuffled_Y <span class="token operator">=</span> Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> permutation<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">)</span>        inc <span class="token operator">=</span> mini_batch_size    <span class="token comment" spellcheck="true"># Step 2 - Partition (shuffled_X, shuffled_Y).</span>    <span class="token comment" spellcheck="true"># Cases with a complete mini batch size only i.e each of 64 examples.</span>    num_complete_minibatches <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>m <span class="token operator">/</span> mini_batch_size<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># number of mini batches of size mini_batch_size in your partitionning</span>    <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_complete_minibatches<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># (approx. 2 lines)</span>        <span class="token comment" spellcheck="true"># mini_batch_X =  </span>        <span class="token comment" spellcheck="true"># mini_batch_Y =</span>        <span class="token comment" spellcheck="true"># YOUR CODE STARTS HERE</span>        mini_batch_X <span class="token operator">=</span> shuffled_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k <span class="token operator">*</span> inc <span class="token punctuation">:</span> <span class="token punctuation">(</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> inc<span class="token punctuation">]</span>        mini_batch_Y <span class="token operator">=</span> shuffled_Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k <span class="token operator">*</span> inc <span class="token punctuation">:</span> <span class="token punctuation">(</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> inc<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># YOUR CODE ENDS HERE</span>        mini_batch <span class="token operator">=</span> <span class="token punctuation">(</span>mini_batch_X<span class="token punctuation">,</span> mini_batch_Y<span class="token punctuation">)</span>        mini_batches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mini_batch<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># For handling the end case (last mini-batch &lt; mini_batch_size i.e less than 64)</span>    <span class="token keyword">if</span> m <span class="token operator">%</span> mini_batch_size <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#(approx. 2 lines)</span>        <span class="token comment" spellcheck="true"># mini_batch_X =</span>        <span class="token comment" spellcheck="true"># mini_batch_Y =</span>        <span class="token comment" spellcheck="true"># YOUR CODE STARTS HERE</span>        mini_batch_X <span class="token operator">=</span> shuffled_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> inc <span class="token operator">*</span> num_complete_minibatches <span class="token punctuation">:</span> m<span class="token punctuation">]</span>        mini_batch_Y <span class="token operator">=</span> shuffled_Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> inc <span class="token operator">*</span> num_complete_minibatches <span class="token punctuation">:</span> m<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># YOUR CODE ENDS HERE</span>        mini_batch <span class="token operator">=</span> <span class="token punctuation">(</span>mini_batch_X<span class="token punctuation">,</span> mini_batch_Y<span class="token punctuation">)</span>        mini_batches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mini_batch<span class="token punctuation">)</span>        <span class="token keyword">return</span> mini_batches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Second, gradient descent</p><pre class="line-numbers language-python"><code class="language-python">seed <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch</span>    seed <span class="token operator">=</span> seed <span class="token operator">+</span> <span class="token number">1</span>    minibatches <span class="token operator">=</span> random_mini_batches<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> mini_batch_size<span class="token punctuation">,</span> seed<span class="token punctuation">)</span>    <span class="token keyword">for</span> minibatch <span class="token keyword">in</span> minibatches<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Select a minibatch</span>        <span class="token punctuation">(</span>minibatch_X<span class="token punctuation">,</span> minibatch_Y<span class="token punctuation">)</span> <span class="token operator">=</span> minibatch        <span class="token comment" spellcheck="true"># Forward propagation</span>        AL<span class="token punctuation">,</span> caches <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>minibatch_X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Compute cost</span>        cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>AL<span class="token punctuation">,</span> minibatch_Y<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Backward propagation</span>        grads <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>AL<span class="token punctuation">,</span> minibatch_Y<span class="token punctuation">,</span> caches<span class="token punctuation">)</span>        parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p><strong>batch_size</strong> usually is a power of two, which is more conducive to GPU acceleration</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Optimization Methods </tag>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Neural-Network Implementation</title>
      <link href="2021/08/24/Neural-Network-Implementation/"/>
      <url>2021/08/24/Neural-Network-Implementation/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true">#Initialize parameters for deep neural network</span><span class="token keyword">def</span> <span class="token function">initialize_parameters_deep</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""  Argument:  layer_dims -- python array (list) containing the dimensions of each layer in network    Returns:  parameters -- python dictionary containing parameters "W1", "b1", ..., "WL", "bL":                                  Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])                                  bl -- bias vector of shape (layer_dims[l], 1)  """</span>  parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>  L <span class="token operator">=</span> len<span class="token punctuation">(</span>layer_dims<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># number of layers in the network</span>  <span class="token keyword">for</span> l <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>      parameters<span class="token punctuation">[</span><span class="token string">'W'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layer_dims<span class="token punctuation">[</span>l<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.01</span>      parameters<span class="token punctuation">[</span><span class="token string">'b'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>              <span class="token keyword">assert</span><span class="token punctuation">(</span>parameters<span class="token punctuation">[</span><span class="token string">'W'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layer_dims<span class="token punctuation">[</span>l <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token keyword">assert</span><span class="token punctuation">(</span>parameters<span class="token punctuation">[</span><span class="token string">'b'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> parameters<span class="token comment" spellcheck="true">#Implement the linear part of a layer's forward propagation.</span><span class="token keyword">def</span> <span class="token function">linear_forward</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    A -- activations from previous layer (or input data): (size of previous layer, number of examples)    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)    b -- bias vector, numpy array of shape (size of the current layer, 1)    Returns:    Z -- the input of the activation function, also called pre-activation parameter     cache -- a python tuple containing "A", "W" and "b" ; stored for computing the backward pass efficiently    """</span>    Z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">,</span> A<span class="token punctuation">)</span> <span class="token operator">+</span> b    cache <span class="token operator">=</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>        <span class="token keyword">return</span> Z<span class="token punctuation">,</span> cache<span class="token comment" spellcheck="true">#Implement the forward propagation for the LINEAR->ACTIVATION layer</span><span class="token keyword">def</span> <span class="token function">linear_activation_forward</span><span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)    b -- bias vector, numpy array of shape (size of the current layer, 1)    activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu"    Returns:    A -- the output of the activation function, also called the post-activation value     cache -- a python tuple containing "linear_cache" and "activation_cache";             stored for computing the backward pass efficiently    """</span>        <span class="token keyword">if</span> activation <span class="token operator">==</span> <span class="token string">"sigmoid"</span><span class="token punctuation">:</span>        Z<span class="token punctuation">,</span> linear_cache <span class="token operator">=</span> linear_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>        A<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>    <span class="token keyword">elif</span> activation <span class="token operator">==</span> <span class="token string">"relu"</span><span class="token punctuation">:</span>        Z<span class="token punctuation">,</span> linear_cache <span class="token operator">=</span> linear_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>        A<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>            cache <span class="token operator">=</span> <span class="token punctuation">(</span>linear_cache<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>    <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache  <span class="token comment" spellcheck="true">#Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation</span><span class="token comment" spellcheck="true">#For other computation, we can change the for loop</span><span class="token keyword">def</span> <span class="token function">L_model_forward</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    X -- data, numpy array of shape (input size, number of examples)    parameters -- output of initialize_parameters_deep()        Returns:    AL -- activation value from the output (last) layer    caches -- list of caches containing:                every cache of linear_activation_forward() (there are L of them, indexed from 0 to L-1)    """</span>    caches <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    A <span class="token operator">=</span> X    L <span class="token operator">=</span> len<span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                  <span class="token comment" spellcheck="true"># number of layers in the neural network</span>        <span class="token comment" spellcheck="true"># Implement [LINEAR -> RELU]*(L-1). Add "cache" to the "caches" list.</span>    <span class="token comment" spellcheck="true"># The for loop starts at 1 because layer 0 is the input</span>    <span class="token keyword">for</span> l <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>        A_prev <span class="token operator">=</span> A         A<span class="token punctuation">,</span> cache <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">"W"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">"b"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"relu"</span><span class="token punctuation">)</span>        caches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cache<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Implement LINEAR -> SIGMOID. Add "cache" to the "caches" list.</span>    AL<span class="token punctuation">,</span> cache <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A<span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">"W"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">"b"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>    caches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cache<span class="token punctuation">)</span>              <span class="token keyword">return</span> AL<span class="token punctuation">,</span> caches  <span class="token comment" spellcheck="true">#Implement the cost function</span><span class="token keyword">def</span> <span class="token function">compute_cost</span><span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)    Y -- true "label" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)    Returns:    cost -- cross-entropy cost    """</span>        m <span class="token operator">=</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># Compute loss from aL and y.</span>    cost <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">/</span>m<span class="token operator">*</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>AL<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>AL<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>        cost <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).</span>        <span class="token keyword">return</span> cost  <span class="token comment" spellcheck="true">#Implement the linear portion of backward propagation for a single layer (layer l)</span><span class="token keyword">def</span> <span class="token function">linear_backward</span><span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    dZ -- Gradient of the cost with respect to the linear output (of current layer l)    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer    Returns:    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev    dW -- Gradient of the cost with respect to W (current layer l), same shape as W    db -- Gradient of the cost with respect to b (current layer l), same shape as b    """</span>    A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b <span class="token operator">=</span> cache    m <span class="token operator">=</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    dW <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>m<span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> A_prev<span class="token punctuation">.</span>T<span class="token punctuation">)</span>    db <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>m<span class="token operator">*</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    dA_prev <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ<span class="token punctuation">)</span>        <span class="token keyword">return</span> dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db  <span class="token comment" spellcheck="true">#Implement the backward propagation for the LINEAR->ACTIVATION layer.</span><span class="token keyword">def</span> <span class="token function">linear_activation_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    dA -- post-activation gradient for current layer l     cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently    activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu"        Returns:    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev    dW -- Gradient of the cost with respect to W (current layer l), same shape as W    db -- Gradient of the cost with respect to b (current layer l), same shape as b    """</span>    linear_cache<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> cache        <span class="token keyword">if</span> activation <span class="token operator">==</span> <span class="token string">"relu"</span><span class="token punctuation">:</span>        dZ <span class="token operator">=</span> relu_backward<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>        dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db <span class="token operator">=</span> linear_backward<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> linear_cache<span class="token punctuation">)</span>    <span class="token keyword">elif</span> activation <span class="token operator">==</span> <span class="token string">"sigmoid"</span><span class="token punctuation">:</span>        dZ <span class="token operator">=</span> sigmoid_backward<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>        dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db <span class="token operator">=</span> linear_backward<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> linear_cache<span class="token punctuation">)</span>        <span class="token keyword">return</span> dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db<span class="token comment" spellcheck="true">#Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group</span><span class="token keyword">def</span> <span class="token function">L_model_backward</span><span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> caches<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    AL -- probability vector, output of the forward propagation (L_model_forward())    Y -- true "label" vector (containing 0 if non-cat, 1 if cat)    caches -- list of caches containing:                every cache of linear_activation_forward() with "relu" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)                the cache of linear_activation_forward() with "sigmoid" (it's caches[L-1])        Returns:    grads -- A dictionary with the gradients             grads["dA" + str(l)] = ...              grads["dW" + str(l)] = ...             grads["db" + str(l)] = ...     """</span>    grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    L <span class="token operator">=</span> len<span class="token punctuation">(</span>caches<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># the number of layers</span>    m <span class="token operator">=</span> AL<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>AL<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># after this line, Y is the same shape as AL</span>        <span class="token comment" spellcheck="true"># Initializing the backpropagation</span>    dAL <span class="token operator">=</span> <span class="token operator">-</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> AL<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> AL<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Lth layer (SIGMOID -> LINEAR) gradients. Inputs: "dAL, current_cache". Outputs: "grads["dAL-1"], grads["dWL"], grads["dbL"]</span>    current_cache <span class="token operator">=</span> caches<span class="token punctuation">[</span>L<span class="token number">-1</span><span class="token punctuation">]</span>    dA_prev_temp<span class="token punctuation">,</span> dW_temp<span class="token punctuation">,</span> db_temp <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>dAL<span class="token punctuation">,</span> current_cache<span class="token punctuation">,</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>    grads<span class="token punctuation">[</span><span class="token string">"dA"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>L<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dA_prev_temp    grads<span class="token punctuation">[</span><span class="token string">"dW"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dW_temp    grads<span class="token punctuation">[</span><span class="token string">"db"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> db_temp        <span class="token comment" spellcheck="true"># Loop from l=L-2 to l=0</span>    <span class="token keyword">for</span> l <span class="token keyword">in</span> reversed<span class="token punctuation">(</span>range<span class="token punctuation">(</span>L<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># lth layer: (RELU -> LINEAR) gradients.</span>        <span class="token comment" spellcheck="true"># Inputs: "grads["dA" + str(l + 1)], current_cache". Outputs: "grads["dA" + str(l)] , grads["dW" + str(l + 1)] , grads["db" + str(l + 1)] </span>        current_cache <span class="token operator">=</span> caches<span class="token punctuation">[</span>l<span class="token punctuation">]</span>        dA_prev_temp<span class="token punctuation">,</span> dW_temp<span class="token punctuation">,</span> db_temp <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>dA_prev_temp<span class="token punctuation">,</span> current_cache<span class="token punctuation">,</span> <span class="token string">"relu"</span><span class="token punctuation">)</span>        grads<span class="token punctuation">[</span><span class="token string">"dA"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dA_prev_temp        grads<span class="token punctuation">[</span><span class="token string">"dW"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dW_temp        grads<span class="token punctuation">[</span><span class="token string">"db"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> db_temp    <span class="token keyword">return</span> grads  <span class="token comment" spellcheck="true">#Update parameters using gradient descent</span><span class="token keyword">def</span> <span class="token function">update_parameters</span><span class="token punctuation">(</span>params<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    params -- python dictionary containing your parameters     grads -- python dictionary containing your gradients, output of L_model_backward        Returns:    parameters -- python dictionary containing your updated parameters                   parameters["W" + str(l)] = ...                   parameters["b" + str(l)] = ...    """</span>    parameters <span class="token operator">=</span> params<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>    L <span class="token operator">=</span> len<span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span> <span class="token comment" spellcheck="true"># number of layers in the neural network</span>    <span class="token comment" spellcheck="true"># Update rule for each parameter. Use a for loop.</span>    <span class="token keyword">for</span> l <span class="token keyword">in</span> range<span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">:</span>        parameters<span class="token punctuation">[</span><span class="token string">"W"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">"W"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token string">"dW"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        parameters<span class="token punctuation">[</span><span class="token string">"b"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">"b"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token string">"db"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> parameters<span class="token comment" spellcheck="true">#Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.</span><span class="token keyword">def</span> <span class="token function">L_layer_model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> layers_dims<span class="token punctuation">,</span> learning_rate <span class="token operator">=</span> <span class="token number">0.0075</span><span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">3000</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Arguments:    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)    Y -- true "label" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).    learning_rate -- learning rate of the gradient descent update rule    num_iterations -- number of iterations of the optimization loop    print_cost -- if True, it prints the cost every 100 steps        Returns:    parameters -- parameters learnt by the model. They can then be used to predict.    """</span>    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                         <span class="token comment" spellcheck="true"># keep track of cost</span>        <span class="token comment" spellcheck="true"># Parameters initialization.</span>    parameters <span class="token operator">=</span> initialize_parameters_deep<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Loop (gradient descent)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.</span>        AL<span class="token punctuation">,</span> caches <span class="token operator">=</span> L_model_forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>        cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>        grads <span class="token operator">=</span> L_model_backward<span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> caches<span class="token punctuation">)</span>        parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># Print the cost every 100 iterations</span>        <span class="token keyword">if</span> print_cost <span class="token operator">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> i <span class="token operator">==</span> num_iterations <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Cost after iteration {}: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> i <span class="token operator">==</span> num_iterations<span class="token punctuation">:</span>            costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        <span class="token keyword">return</span> parameters<span class="token punctuation">,</span> costs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Advice for applying machine learning</title>
      <link href="2021/06/29/Advice-for-applying-machine-learning/"/>
      <url>2021/06/29/Advice-for-applying-machine-learning/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Evaluating-a-Learning-Algorithm"><a href="#1-Evaluating-a-Learning-Algorithm" class="headerlink" title="1. Evaluating a Learning Algorithm"></a>1. Evaluating a Learning Algorithm</h4><h5 id="1-1-Evaluating-a-Hypothesis"><a href="#1-1-Evaluating-a-Hypothesis" class="headerlink" title="1.1 Evaluating a Hypothesis"></a>1.1 Evaluating a Hypothesis</h5><ul><li><p>A hypothesis may have a low error for the training examples but still be inaccurate (because of overfitting). Thus, to evaluate a hypothesis, given a dataset of training examples, we can split up the data into two sets: a <strong>training set</strong> and a <strong>test set</strong>. Typically, the training set consists of $70%$ of data and the test set is the remaining $30%$.</p></li><li><p>The new procedure using these two sets is then:</p><ul><li>Learn $\Theta$ and minimize $J_{train}(\Theta)$ using the training set</li><li>Compute the test set error $J_{test}(\Theta)$</li></ul></li><li><p><strong>The test set error</strong></p><ul><li><p>For linear regression: $J_{test}(\Theta) = \frac{1}{2m_{test}}\Sigma_{i=1}^{m_{test}}(h_\Theta(x_{test}^{(i)})-y_{test}^{(i)})^2$</p></li><li><p>For classification ~ Misclassification error (aka $0/1$ misclassification error):<br>$$<br>err(h_\Theta(x), y) = \begin{cases}1\quad \text{if } h_\Theta \ge 0.5 \text{ and } y=0 \text{ or } h_\Theta \lt 0.5 \text{ and } y=1\ 0\quad \text{otherwise}\end{cases}<br>$$</p><p>$$<br>\text{Test Error} = \frac{1}{m_{test}}\Sigma_{i=1}^{m_{test}}err(h_\Theta(x_{test}^{(i)}), y_{test}^{(i)})<br>$$</p></li></ul></li></ul><h5 id="1-2-Model-Selection-and-Train-Validation-Test-Sets"><a href="#1-2-Model-Selection-and-Train-Validation-Test-Sets" class="headerlink" title="1.2 Model Selection and Train/Validation/Test Sets"></a>1.2 Model Selection and Train/Validation/Test Sets</h5><ul><li><p>Just because a learning algorithm fits a training set well, that does not mean it is a good hypothesis. It could overfit and as a result the predication on the test set would be poor. The error of the hypothesis as measured on the dataset with which you trained the parameters will be lower than the error on any other data set.</p></li><li><p>Given many models with different polynomial degrees, we can use a systematic approach to identify the â€˜bestâ€™ function. In order to choose the model of the hypothesis, test each degree of polynomial and look at the error result.</p></li><li><p>One way to break down the dataset into the three sets is:</p><ul><li>Training set: $60%$</li><li>Cross validation set: $20%$</li><li>Test set: $20%$</li></ul></li><li><p>Calculate three separate error values for the three different sets using the following method:</p><ol><li>Optimize the parameters in $\Theta$ using the training set for each polynomial degree.</li><li>Find the polynomial degree $d$ with the least error using the cross validation set.</li><li>Estimate the generalization error using the test set with $J_{test}(\Theta^{(d)})$, (d = theta from polynomial with lower error);</li></ol></li><li><p>This way, the degree of the polynomial $d$ has not been trained using the test set.</p></li></ul><h4 id="2-Bias-vs-Variance"><a href="#2-Bias-vs-Variance" class="headerlink" title="2. Bias vs. Variance"></a>2. Bias vs. Variance</h4><h5 id="2-1-Diagnosing-Bias-vs-Variance"><a href="#2-1-Diagnosing-Bias-vs-Variance" class="headerlink" title="2.1 Diagnosing Bias vs. Variance"></a>2.1 Diagnosing Bias vs. Variance</h5><ul><li><p>Need to distinguish whether <strong>bias</strong> or <strong>variance</strong> is the problem contributing to bad predictions.</p></li><li><p>High bias is underfitting and high variance is overfitting. Ideally, we need to find a golden mean between these two.</p></li><li><p>The training error will tend to <strong>decrease</strong> as we increase the degree $d$ of the polynomial.</p><p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase $d$ up to a point, and then it will <strong>increase</strong> as $d$ is increased, forming a convex curve.</p></li><li><p><strong>High bias (underfitting)</strong>: both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ will be high. Also, $J_{CV}(\Theta) \approx J_{train}(\Theta)$</p></li><li><p><strong>High variance (overfitting)</strong>: $J_{train}(\Theta)$ will be low and $J_{CV}(\Theta)$ will be much greater than $J_{train}(\Theta)$</p></li><li><p>Summurized in the figure below:</p><img src="/2021/06/29/Advice-for-applying-machine-learning/BiasAndVariance.png" style="zoom:50%;"></li></ul><h5 id="2-2-Regularization-and-Bias-Variance"><a href="#2-2-Regularization-and-Bias-Variance" class="headerlink" title="2.2 Regularization and Bias/Variance"></a>2.2 Regularization and Bias/Variance</h5><ul><li><img src="/2021/06/29/Advice-for-applying-machine-learning/RegularizationAndBias:Variance.png" style="zoom:50%;"></li><li><p>In the figure above, as $\lambda$ increases, the fit becomes more rigid. On the other hand, as $\lambda$ approaches $0$, the model tends to overfit the data.</p></li><li><p>In order to choose the model and the regularization term $\lambda$, need to:</p><ol><li>Create a list of lambdas (i.e. $\lambda \in {0, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1.28, 2.56, 5.12, 10.24}$);</li><li>Create a set of models with different degrees or any other variants.</li><li>Iterate through the $\lambda$s and for each $\lambda$ go through all the models to learn some $\Theta$.</li><li>Compute the cross validation error using the learned $\Theta$ (computed with $\lambda$) on the $J_{CV}(\Theta)$ <strong>without</strong> regularization or $\lambda = 0$.</li><li>Select the best combo that produces the lowest error on the cross validation set.</li><li>Using the best combo $\Theta$ and $\lambda$, apply in on $J_{test}(\Theta)$ to see if it has a good generalization of the problem.</li></ol></li></ul><h5 id="2-3-Learning-Curves"><a href="#2-3-Learning-Curves" class="headerlink" title="2.3 Learning Curves"></a>2.3 Learning Curves</h5><ul><li>Training an algorithm on a very few number of data points (such as 1, 2 or 3) will easily have 0 errors because we can always find a quadratic curve that touches exactly those number of points. Hence<ul><li>As the training set gets larger, the error for a quadratic function increases.</li><li>The error value will plateau out after a certain $m$, or training set size.</li></ul></li><li><strong>Experiencing high bias</strong>:<ul><li><strong>Low training set size</strong>: causes $J_{train}(\Theta)$ to be low and $J_{CV}(\Theta)$ to be high.</li><li><strong>Large traning set size</strong>: causes both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ to be high with $J_{train}(\Theta) \approx J_{CV}(\Theta)$.</li><li>If a learning algorithm is suffering from <strong>high bias</strong>, getting more training data will not <strong>(by itself)</strong> help much.</li></ul></li><li><strong>Experiencing high variance</strong>:<ul><li><strong>Low training set size</strong>: $J_{train}(\Theta)$ will be low and $J_{CV}(\Theta)$ will be high.</li><li><strong>Large training set size</strong>: $J_{train}(\Theta)$ increases with training set size and $J_{CV}(\Theta)$ continues to decrease without leveling off. Also, $J_{train}(\Theta) \lt J_{CV}(\Theta)$ but the difference between them remains significant.</li><li>If a learning algorithm is suffering from <strong>high variance</strong>, getting more training data is likely to help.</li></ul></li></ul><h5 id="2-4-Deciding-what-to-do-next-revisited"><a href="#2-4-Deciding-what-to-do-next-revisited" class="headerlink" title="2.4 Deciding what to do next revisited"></a>2.4 Deciding what to do next revisited</h5><ul><li>The decision process can be broken down as follows:<ul><li><strong>Getting more training examples</strong>: Fixes high variance</li><li><strong>Trying smaller sets of features</strong>: Fixes high variance</li><li><strong>Adding features</strong>: Fixes high bias</li><li><strong>Adding polynomial features</strong>: Fixes high bias</li><li><strong>Decreasing $\lambda$</strong>: Fixes high bias</li><li><strong>Increasing $\lambda$</strong>: Fixes high variance</li></ul></li><li><strong>Diagnosing Neural Networks</strong><ul><li>A neural network with fewer parameters is <strong>prone to underfitting</strong>. It is also <strong>Computationally cheaper</strong>.</li><li>A large neural network with more parameters is <strong>prone to overfitting</strong>. It is also <strong>computationally expensive</strong>. In this case, use regularization (increase $\lambda$) to address overfitting.</li><li>Using a single hidden layer is a good starting default. You can train your neural network on a number of hidden layers using cross validation set. Then select the one that performs best.</li></ul></li><li><strong>Model Complexity Effects</strong>:<ul><li>Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.</li><li>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.</li><li>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Support Vector Machine</title>
      <link href="2021/06/22/Support-Vector-Machine/"/>
      <url>2021/06/22/Support-Vector-Machine/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Optimization-Objective"><a href="#1-Optimization-Objective" class="headerlink" title="1. Optimization Objective"></a>1. Optimization Objective</h4><ul><li><p>$$<br>\min_\theta C \sum_{i=1}^m\left[y^{(i)}cost_1(\theta^Tx^{(i)}) + (1-y^{(i)})cost_0(\theta^Tx^{(i)})\right] + \frac{1}{2}\sum_{i=1}^n\theta_J^2<br>$$</p></li><li><p>$z = \theta^Tx$</p></li><li><p><img src="/2021/06/22/Support-Vector-Machine/cost1.png" style="zoom:50%;"> <img src="/2021/06/22/Support-Vector-Machine/cost0.png" style="zoom:50%;"></p></li><li><p>if $y = 1$, $\theta^Tx \ge 1$</p><p>if $y=0$, $\theta^Tx\le -1$</p></li></ul><h4 id="2-Decision-Boundary"><a href="#2-Decision-Boundary" class="headerlink" title="2. Decision Boundary"></a>2. Decision Boundary</h4><ul><li><p>$$<br>\begin{align*}<br>&amp; \min_\theta \frac{1}{2}\sum_{i=1}^n\theta_j^2\<br>&amp; s.t.\quad \theta^Tx^{(i)} \ge 1\quad \text{if}\ y^{(i)} = 1\<br>&amp; \quad \quad\ \ \ \theta^Tx^{(i)} \le -1\quad \text{if}\ y^{(i)} = 0<br>\end{align*}<br>$$</p></li><li><p>Linearly Separable case</p><img src="/2021/06/22/Support-Vector-Machine/LinearSeparable.png" style="zoom:50%;"></li><li><img src="/2021/06/22/Support-Vector-Machine/LinearSeparable1.png" style="zoom:50%;"></li></ul><h4 id="3-Kernel"><a href="#3-Kernel" class="headerlink" title="3. Kernel"></a>3. Kernel</h4><ul><li><p>Given $x$, compute new feature depending on proximity to landmarks $l^{(1)}, l^{(2)}, l^{(3)}, \cdots$</p></li><li><p>$f_1 = similarity(x, l^{(1)}) = \exp\left(-\frac{\Vert x-l^{(1)}\Vert^2}{2\sigma^2}\right)$</p><p>if $x \approx l^{(1)}: f_1 \approx \exp\left(-\frac{0^2}{2\sigma^2}\right) \approx 1$</p><p>If $x$ is far from $l^{(1)}: f_1 = \exp\left(-\frac{(\text{large number})^2}{2\sigma^2}\right) \approx 0$</p></li><li><p><strong>SVM with Kernels</strong></p><ul><li><p>Given $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})$</p></li><li><p>Choose $l^{(1)} = x^{(1)}, l^{(2)} = x^{(2)}, \cdots, l^{(m)} = x^{(m)}$</p></li><li><p>Given example $x$:</p><ul><li>$f_1 = similarity(x, l^{(1)})$</li><li>$f_2 = similarity(x, l^{(2)})$</li><li>$\cdots$</li></ul></li><li><p>For training example $(x^{(i)}, y^{(i)})$</p><ul><li>$x^{(i)}\rightarrow {f_1^{(i)} = sim(x^{(i)}, l^{(1)})\ \vdots \ f_m^{(i)} = sim(x^{(i)}), l^{(m)}}$</li><li>$f^{(i)} = x^{(i)}\f_0^{(i)} = 1$</li></ul></li><li><p>Hypothesis: Given $x$, compute features $f\in R^{m+1}$</p><ul><li><p>Predict â€œ$y=1$â€ if $\theta^Tf \ge 0$</p></li><li><p>Training<br>$$<br>\min_\theta C \sum_{i=1}^m\left[y^{(i)}cost_1(\theta^Tf^{(i)}) + (1-y^{(i)})cost_0(\theta^Tf^{(i)})\right] + \frac{1}{2}\sum_{i=1}^n\theta_J^2<br>$$</p></li></ul></li></ul></li></ul><h4 id="4-SVM-parameters"><a href="#4-SVM-parameters" class="headerlink" title="4. SVM parameters"></a>4. SVM parameters</h4><ul><li>$C(=\frac{1}{\lambda})$<ul><li>Large $C$: Lower bias, high variance.</li><li>Small $C$: Higher bias, low variance.</li></ul></li><li>$\sigma^2$<ul><li>Large $\sigma^2$: Features $f_i$ vary more smoothly. Higher bias, lower variance.</li><li>Small $\sigma^2$: Features $f_i$ vary less smoothly. Lower bias, higher variance.</li></ul></li></ul><h4 id="5-Logistic-regression-vs-SVMs"><a href="#5-Logistic-regression-vs-SVMs" class="headerlink" title="5. Logistic regression vs. SVMs"></a>5. Logistic regression vs. SVMs</h4><p>$n = \text{number of features }(x\in R^{n+1}), m = \text{number of training examples}$</p><ul><li>If $n$ is large (relative to $m$):<ul><li>Use logistic regression, or SVM without a kernel (â€œlinear kernelâ€)</li></ul></li><li>If $n$ is small, $m$ is intermediate:<ul><li>Use SVM with Gaussian kernel</li></ul></li><li>If $n$ is small, $m$ is large:<ul><li>Create/add more features, then use logistic regression or SVM without a kernel</li></ul></li><li>Neural network likely to work well for most of these settings, but may be slower to train.</li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Neural Network</title>
      <link href="2021/06/16/Neural-Network/"/>
      <url>2021/06/16/Neural-Network/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Model-Representation"><a href="#1-Model-Representation" class="headerlink" title="1. Model Representation"></a>1. Model Representation</h4><ul><li><p>Input: features $x_1\cdots x_n$</p></li><li><p>Output: the result of the hypothesis function.</p></li><li><img src="/2021/06/16/Neural-Network/Neural Network Rep1.png" style="zoom:50%;"></li><li><p>$x_0$ input node is called the â€œbias unitâ€. It is always equal to $1$.</p></li><li><p>The same logistic function as in classification, $\frac{1}{1+e^{-\theta^Tx}}$, which is also called sigmoid (logistic) <strong>activation</strong> function.</p></li><li><p>â€œthetaâ€ parameters are called â€œweightsâ€.</p></li><li><p>A simplistic representation:<br>$$<br>[x_0x_1x_2]\rightarrow [\ ]\rightarrow h_\theta(x)<br>$$</p></li><li><p>Inpur nodes (layer 1), known as the â€œinput layerâ€, go into another node (layer 2), which finally outputs the hypothesis function, known as the â€œoutput layerâ€.</p></li><li><p>The intermediate layers of nodes between the input and output layers called the â€œhidden layersâ€.</p></li><li><img src="/2021/06/16/Neural-Network/Neural Network Rep2.png" style="zoom:50%;"></li><li><p>We label these intermediate or â€œhiddenâ€ layer nodes $a_0^2\cdots a_n^2$ and call them â€œactivation unitsâ€.</p></li><li><p>$$<br>\begin{align*}<br>&amp; a_i^{(j)} = \text{activation}\ \text{of unit}\ i\ \text{in layer}\ j\<br>&amp; \Theta^{(j)} = \text{matrix of weights controlling function mapping from layer}\ j \text{ to layer}\ j+1<br>\end{align*}<br>$$</p></li><li><p>$$<br>[x_0x_1x_2x_3]\rightarrow \left[a_1^{(2)}a_2^{(2)}a_3^{(2)}\right]\rightarrow h_\theta(x)<br>$$</p></li><li><p>The values for each of the â€œactivationâ€ nodes is obtained as follows:<br>$$<br>\begin{align*}<br>&amp;&amp; a_1^{(2)} = g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_2 + \Theta_{12}^{(1)}x_1 + \Theta_{13}^{(1)}x_3)\<br>&amp;&amp; a_2^{(2)} = g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_2 + \Theta_{22}^{(1)}x_1 + \Theta_{23}^{(1)}x_3)\<br>&amp;&amp; a_3^{(2)} = g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_2 + \Theta_{32}^{(1)}x_1 + \Theta_{33}^{(1)}x_3)\<br>&amp;&amp; h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)})<br>\end{align*}<br>$$</p></li><li><p>The dimensions of matrices of weights is determined as follows:</p><p><strong>If network has $s_j$ units in layer $j$ and $s_{j+1}$ units in layer $j+1$, then $\Theta^{(j)}$ will be of dimension $s_{j+1}\times (s_j+1)$</strong>.</p><p>The $+1$ comes from the addition in $\Theta^{(j)}$ of the â€œbias nodesâ€, $x_0$ and $\Theta_0^{(j)}$. In other words the output nodes will not include the bias nodes while the inputs will.</p></li></ul><h4 id="2-Vectorized-Representation"><a href="#2-Vectorized-Representation" class="headerlink" title="2. Vectorized Representation"></a>2. Vectorized Representation</h4><ul><li><p>Setting $x = a^{(1)}$</p><p>$z^{(j)} = \Theta^{(j-1)}a^{(j-1)}$</p></li><li><p>Multiply matrix $\Theta^{(j-1)}$ with dimensions $s_j\times (n+1)$ (where $s_j$ is the number of activation nodes) by vector $a^{(j-1)}$ with height $n+1$. This gives vector $z^{(j)}$ with height $s_j$. Now the vector of activation nodes for layer $j$ as follows:<br>$$<br>a^{(j)} = g(z^{(j)})<br>$$<br>where function $g$ can be applied element-wise to vector $z^{(j)}$</p></li><li><p>Add a bias unit (equal to $1$) to layer $j$ after we have computed $a^{(j)}$. This will be element $a_0^{(j)}$ and will be equal to $1$.</p></li><li><p>Final result $h_\Theta(x) = a^{(j+1)} = g(z^{(j+1)}) = g(\Theta^{(j)}a^{(j)})$</p></li></ul><h4 id="3-Cost-Function"><a href="#3-Cost-Function" class="headerlink" title="3. Cost Function"></a>3. Cost Function</h4><ul><li><p>First define a few variables need to use:</p><ul><li>$L = \text{total number of layers in the network}$</li><li>$s_l = \text{number of units (not counting bias unit) in layer } l$</li><li>$K = \text{number of output units/classes}$</li></ul></li><li><p>In neural networks, we may have many output nodes. Denote $h_\theta(x)_k$ as being a hypothesis that results in the $k^{th}$ output.</p></li><li><p>The cost function for neural networks is going to be generalization of the one used for logistic regression.<br>$$<br>J(\Theta) = -\frac{1}{m} \sum_{i=1}^{m} \sum_{k-1}^{K} \left[y_{k}^{(i)} \log((h_\Theta(x^{(i)}))<em>k) + (1-y_k^{(i)})\log(1-(h_\Theta(x^{(i)}))<em>k)\right] + \frac{\lambda}{2m} \sum</em>{l=1}^{L-1} \sum</em>{i=1}^{s_l} \sum_{j=1}^{s_l+1}(\Theta_{j, i}^{(i)})^2<br>$$<br>We have added a few nested summations to account for our multiple output nodes. In the first part of the equation, before the square brackets, we have an additional nested summation that loops through the number of output nodes.</p></li><li><p>In the regularization part, after the square brackets, we must account for multiple theta matrices. The number of columns in our current theta matrix is equal to the number of nodes in our current layer (including the bias unit). The number of rows in our current theta matrix is equal to the number of nodes in the next layer (excluding the bias unit). As before with logistic regression, we square every term.</p></li><li><p>Note:</p><ul><li>the double sum simply adds up the logistic regression costs calculated for each cell in the output layer.</li><li>the triple sum simply adds up the squares of all the individual $\Theta$s in the entire network.</li><li>the $i$ in the triple sum does <strong>not</strong> refer to training example $i$.</li></ul></li></ul><h4 id="4-Backpropagation-Algorithm"><a href="#4-Backpropagation-Algorithm" class="headerlink" title="4. Backpropagation Algorithm"></a>4. Backpropagation Algorithm</h4><ul><li><p>â€œBackpropagationâ€ is neural-network terminology for minimizing the cost function.</p></li><li><p>Compute the partial derivative of $J(\Theta)$:<br>$$<br>\frac{\partial}{\partial \Theta_{i, j}^{(l)}}J(\Theta)<br>$$</p></li><li><p>Procedure:</p><ul><li>Given training examples set ${(x^{(1)}, y^{(1)})\cdots(x^{(m)}, y^{(m)})}$</li><li>Set $\Delta_{ij}^{(l)} = 0$ for all $(l, i, j)$</li><li>For $i = 1$ to $m$:<ul><li>Set $a^{(1)} = x^{(i)}$</li><li>Perform forward propagation to compute $a^{(l)}$ for $l = 2,3,\cdots, L$</li><li>Using $y^{(i)}$, compute $\delta^{(L)} = a^{(L)} - y^{(i)}$</li><li>Compute $\delta^{(L-1)}, \delta^{(L-2)}, \cdots, \delta^{(2)}$ using $\delta^{(l)} = ((\Theta^{(l)})^T\delta^{(l+1)})\ .*\ a^{(l)}\ .*\ (1-a^{(l)})$<ul><li>The delta values of layer $l$ are calculated by multiplying the delta values in the next layer with the theta matrix of layer $l$. We then element-wise multiply that with a function called $g^{\prime}$, or g-prime, which is the derivative of the activation function $g$ evaluated with the input values given by $z^{(l)}$.</li></ul></li><li>$\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + a_j^{(l)}\delta_i^{(l+1)}$</li></ul></li><li>$D_{ij}^{(l)} := \Delta_{ij}^{(l)} + \lambda \Theta_{ij}^{(l)} \text{ if } j \ne 0$</li><li>$D_{ij}^{(l)} := \Delta_{ij}^{(l)} \text{ if } j = 0$</li></ul></li><li><p>Intuitively, $\delta_j^{(l)}$ is the â€œerrorâ€ for $a_j^{(l)}$ (unit $j$ in layer $l$). More formally, the delta values are actually the derivative of the cost function: $\delta_j^{(l)} = \frac{\partial}{\partial z_j^{(l)}}cost(t)$</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Overfitting</title>
      <link href="2021/06/09/Overfitting/"/>
      <url>2021/06/09/Overfitting/</url>
      
        <content type="html"><![CDATA[<h4 id="1-The-Problem-of-Overfitting"><a href="#1-The-Problem-of-Overfitting" class="headerlink" title="1. The Problem of Overfitting"></a>1. The Problem of Overfitting</h4><ul><li><strong>Underfitting</strong>, or high bias, is when the form of our hypothesis function $h$ maps poorly to the trend of the data. It is usually caused by a function that is too simple or uses too few features.</li><li>At the other extreme, <strong>overfitting</strong>, or high variance, is caused by a hypothesis function that fits the available data but does not generalize well to predict new data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.</li><li>Two main options to address the issue of overfitting:<ul><li>Reduce the number of features:<ul><li>Manually select which features to keep.</li><li>Use a model selection algorithm.</li></ul></li><li>Regularization<ul><li>Keep all the features, but reduce the magnitude of parameters $\theta_j$.</li><li>Regularization works well when we have a lot of slightly useful features.</li></ul></li></ul></li></ul><h4 id="2-Cost-Function"><a href="#2-Cost-Function" class="headerlink" title="2. Cost Function"></a>2. Cost Function</h4><ul><li><p>If we have overfitting from our hypothesis function, we can reduce the weight that some of the terms in our function carry by increasing their cost.</p></li><li><p>$$<br>\min_\theta\frac{1}{2m}\Sigma_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \Sigma_{j=1}^n \theta_j^2<br>$$</p></li><li><p>The $\lambda$, or lambda, is the <strong>regularization parameter</strong>. It determines how much the costs of our theta parameters are inflated.</p></li><li><p>Using the above cost function with extra summation, we can smooth the output of our hypothesis function to reduce overfitting.</p></li><li><p>If lambda is chosen to be too large, it may smooth out the function too much and cause underfitting.</p></li></ul><h4 id="3-Regularized-Linear-Regression"><a href="#3-Regularized-Linear-Regression" class="headerlink" title="3. Regularized Linear Regression"></a>3. Regularized Linear Regression</h4><ul><li><p><strong>Gradient Descent</strong><br>$$<br>\begin{align*}<br>&amp; Repeat\ {\<br>&amp; \quad\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\<br>&amp; \quad\theta_j := \theta_j - \alpha\left[ \left( \frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\right) + \frac{\lambda}{m}\theta_j\right] \quad\quad j\in{1, 2\cdots n}\<br>&amp; }<br>\end{align*}<br>$$</p></li><li><p>The term $\frac{\lambda}{m}\theta_j$ performs regularization. With some manipulation, the update rule can also be represented as:<br>$$<br>\theta_j := \theta_j(1-\alpha\frac{\lambda}{m}) - \alpha\frac{1}{m}\Sigma_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}<br>$$<br>The first term in the above equation, $1 - \alpha\frac{\lambda}{m}$ will always be less than $1$. Intuitively reduce the value of $\theta_j$ by some amount on every update.</p></li><li><p><strong>Normal Equation</strong><br>$$<br>\theta = (X^TX+\lambda L)^{-1}X^Ty\quad<br>where\ L = \begin{bmatrix} 0 \ \ &amp; 1 \ \ &amp;\ &amp; 1 \ \ &amp; \ &amp; \ &amp; \ddots \ \ &amp; \ &amp; \ &amp;\ &amp; 1\end{bmatrix}<br>$$<br>$L$ is a matrix with $0$ at the top left and $1$â€™s down the diagonal, with $0$â€™s everywhere else. It should have dimension $(n+1)\times (n+1)$. Intuitively, this is the identity matrix (though we are not including $x_0$), multiplied with a single real number $\lambda$.</p></li><li><p>When we add the term $\lambda L$, then $X^TX + \lambda L$ becomes invertible.</p></li></ul><h4 id="4-Regularized-Logistic-Regression"><a href="#4-Regularized-Logistic-Regression" class="headerlink" title="4. Regularized Logistic Regression"></a>4. Regularized Logistic Regression</h4><ul><li><p>Cost function<br>$$<br>J(\theta) = -\frac{1}{m}\Sigma_{i=1}^m[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\theta(x^{(i )}))] + \frac{\lambda}{m}\Sigma_{j=1}^n\theta_j^2<br>$$<br>The second sum, $\Sigma_{j=1}^n\theta_j^2$ <strong>means to explicitly exclude</strong> the bias term $\theta_0$.</p></li><li><p><strong>Gradient Descent</strong><br>$$<br>\begin{align*}<br>&amp; Repeat\ {\<br>&amp; \quad\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\<br>&amp; \quad\theta_j := \theta_j - \alpha\left[ \left( \frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\right) + \frac{\lambda}{m}\theta_j\right] \quad\quad j\in{1, 2\cdots n}\<br>&amp; }<br>\end{align*}<br>$$</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logistic Regression -- Classification</title>
      <link href="2021/06/08/Logistic-Regression-Classification/"/>
      <url>2021/06/08/Logistic-Regression-Classification/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Classification"><a href="#1-Classification" class="headerlink" title="1. Classification"></a>1. Classification</h4><ul><li>The classification problem is just like the regression problem, except that the values we now want to predict take on only a small number of discrete values.</li><li><strong>Binary classification problem</strong><ul><li>$y$ can take on only two values, $0$ and $1$. (Multi-class later)</li><li>$0$ is called the negative class, and $1$ the positive class, and they are sometimes also denoted by the symbols â€œ-â€œ and â€œ+â€.</li><li>Given $x^{(i)}$, the corresponding $y^{(i)}$ is also called the <strong>label</strong> for the training example.</li></ul></li></ul><h4 id="2-Hypothesis-Representation"><a href="#2-Hypothesis-Representation" class="headerlink" title="2. Hypothesis Representation"></a>2. Hypothesis Representation</h4><ul><li><p>By using the â€œSigmoid Functionâ€, also called the â€œLogistic Functionâ€:<br>$$<br>\begin{align*}<br>&amp; h_{\theta}(x) = g(\theta^Tx)\<br>&amp; z = \theta^Tx\<br>&amp; g(z) = \frac{1}{1+e^{-z}}<br>\end{align*}<br>$$</p></li><li><p>The function $g(z)$, maps any real number to the $(0,1)$ interval, making it useful for transforming an arbitrary-valued function into a function suited for classification.</p></li><li><p>$h_{\theta}(x)$ will give us the <strong>probability</strong> that our output is $1$. The probability that the prediction is $0$ is just the complement of the probability that it is $1$.<br>$$<br>\begin{align*}<br>&amp; h_{\theta}(x) = P(y=1\mid x;\theta) = 1 - P(y=0\mid x;\theta)\<br>&amp; P(y=0\mid x;\theta) + P(y=1\mid x;\theta) = 1<br>\end{align*}<br>$$</p></li></ul><h4 id="3-Decision-Boundary"><a href="#3-Decision-Boundary" class="headerlink" title="3. Decision Boundary"></a>3. Decision Boundary</h4><ul><li><p>$$<br>\theta^Tx\ge 0 \Rightarrow y=1\<br>\theta^Tx\lt 0 \Rightarrow y=0<br>$$</p></li><li><p>The <strong>decision boundary</strong> is the line that separates the area where $y = 1$ and where $y = 0$. It is created by the hypothesis function.</p></li><li><p>The input to the sigmoid function $g(z)$ (e.g. $\theta^TX$) doesnâ€™t need to be linear, and could be a function that describes a circle or any shape to fit our data.</p></li></ul><h4 id="4-Cost-Function"><a href="#4-Cost-Function" class="headerlink" title="4. Cost Function"></a>4. Cost Function</h4><ul><li><p>We cannot use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function.</p></li><li><p>Instead, our cost function for logistic regression looks like:<br>$$<br>\begin{align*}<br>&amp; J(\theta) = \frac{1}{m}\sum^m_{i=1}Cost(h_\theta(x^{(i)}), y^{(i)})\<br>&amp; Cost(h_\theta(x), y) = -\log(h_\theta(x))\quad\quad if\ y = 1\<br>&amp; Cost(h_\theta(x), y) = -\log(1-h_\theta(x))\ if\ y = 0<br>\end{align*}<br>$$</p></li><li><p>$$<br>\begin{align*}<br>&amp; Cost(h_{\theta}(x), y) = 0\ if\ h_\theta(x) = y\<br>&amp; Cost(h_\theta(x), y) \rightarrow \infin\ if\ y = 0\ and\ h_\theta(x)\rightarrow 1\<br>&amp; Cost(h_\theta(x), y) \rightarrow \infin\ if\ y = 1\ and\ h_\theta(x) \rightarrow 0<br>\end{align*}<br>$$</p></li><li><p>If the correct answer â€˜$y$â€™ is $0$, then the cost function will be $0$ if our hypothesis function also ouputs $0$. If the hypothesis approaches $1$, then the cost function will approach infinity. If the correct answer â€˜$y$â€™ is $1$, the case is reverse.</p></li><li><p>Not that writing the cost function in this way guarantees that $J(\theta)$ is convex for logistic regression.</p></li></ul><h4 id="5-Simplified-Cost-Function"><a href="#5-Simplified-Cost-Function" class="headerlink" title="5. Simplified Cost Function"></a>5. Simplified Cost Function</h4><ul><li><p>Compress the cost functionâ€™s two conditional cses into one case:<br>$$<br>Cost(h_\theta(x), y) = -y\log(h_\theta(x)) - (1-y)\log(1-h_\theta(x))<br>$$</p></li><li><p>Cost function<br>$$<br>J(\theta) = -\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1 - h_\theta(x^{(i)}))]<br>$$</p></li><li><p>A vectorized implementation:<br>$$<br>h = g(X\theta)\<br>J(\theta) = \frac{1}{m}(-y^T\log(h) - (1-y)^T\log(1-h))<br>$$</p></li></ul><h4 id="6-Gradient-Descent"><a href="#6-Gradient-Descent" class="headerlink" title="6. Gradient Descent"></a>6. Gradient Descent</h4><ul><li><p>$$<br>\begin{align*}<br>&amp; Repeat\ { \<br>&amp; \theta_j := \theta_j - \frac{\alpha}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\<br>&amp; }<br>\end{align*}<br>$$</p></li><li><p>A vectorized implementation:<br>$$<br>\theta := \theta - \frac{\alpha}{m}X^T(g(X\theta) - \vec{y})<br>$$</p></li></ul><h4 id="7-Advanced-Optimization"><a href="#7-Advanced-Optimization" class="headerlink" title="7. Advanced Optimization"></a>7. Advanced Optimization</h4><ul><li>â€œConjugate gradientâ€, â€œBFGSâ€, and â€œL-BFGSâ€ are more sophisticated, faster ways to optimize $\theta$ that can be used instead of gradient descent.</li></ul><h4 id="8-Multiclass-Classification-One-vs-all"><a href="#8-Multiclass-Classification-One-vs-all" class="headerlink" title="8. Multiclass Classification: One-vs-all"></a>8. Multiclass Classification: One-vs-all</h4><ul><li><p>Instead of $y = {0, 1}$, we will expand the definition so that $y = {0, 1\cdots n}$.</p></li><li><p>Since $y = {0, 1\cdots n}$, we divide the problem into $n+1$ binary classification problems; in each one, predict the probability that â€˜$y$â€™ is a member of one of our classes.</p></li><li><p>$$<br>\begin{align*}<br>&amp; y\in {0, 1\cdots n}\<br>&amp; h_\theta^{(0)}(x) = P(y = 0\mid x;\theta)\<br>&amp; h_\theta^{(1)}(x) = P(y = 1\mid x;\theta)\<br>&amp; \cdots\<br>&amp; h_\theta^{(n)}(x) = P(y = n\mid x;\theta)\<br>&amp; prediction = \max_{i}(h_\theta^{(i)}(x))<br>\end{align*}<br>$$</p></li><li><p>We are basically choosing one class and then lumping all the others into a single second class. Do this repeatedly, applying binary logistic regression to each case, and then use the hypothesis that returned the highest value as our prediction.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Priority Queue</title>
      <link href="2021/06/02/Priority-Queue/"/>
      <url>2021/06/02/Priority-Queue/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Definition"><a href="#1-Definition" class="headerlink" title="1. Definition"></a>1. Definition</h4><ul><li>A priority queue is an abstract data type for storing a collection of prioritized elements that supports<ul><li>arbitrary element insertion,</li><li>removal of elements in order of priority (the element with the first priority can be removed at any time)</li></ul></li></ul><h4 id="2-Priority-Queue-ADT"><a href="#2-Priority-Queue-ADT" class="headerlink" title="2. Priority Queue ADT"></a>2. Priority Queue ADT</h4><ul><li>A priority queue stores a collection of entries</li><li>Each entry is a pair (key, value)</li><li><strong>Entry ADT</strong><ul><li>An <em>entry</em> in a priority queue is simply a key-value pair</li><li>Priority queues store entries to allow for efficient insertion and removal based on keys</li></ul></li></ul><h4 id="3-Sequence-based-Priority-Queue"><a href="#3-Sequence-based-Priority-Queue" class="headerlink" title="3. Sequence-based Priority Queue"></a>3. Sequence-based Priority Queue</h4><ul><li>Implementation with an unsorted list<ul><li><em>insert</em> takes $O(1)$ time since we can insert the item at the beginning or end of the sequence</li><li><em>removeMin</em> and <em>min</em> take $O(n)$ time since we have to traverse the entire sequence to find the smallest key</li></ul></li><li>Implementation with a sorted list<ul><li><em>insert</em> takes $O(n)$ time since we have to find the place where to insert the item</li><li><em>removeMin</em> and <em>min</em> take $O(1)$ time, since the smallest key is at the beginning</li></ul></li></ul><h4 id="4-Priority-Queue-Sorting"><a href="#4-Priority-Queue-Sorting" class="headerlink" title="4. Priority Queue Sorting"></a>4. Priority Queue Sorting</h4><ul><li>Use a priority queue to sort a list of comparable elements<ul><li>Insert the elements one by one with a series of <em>insert</em> operations</li><li>Remove the elements in sorted order with a series of <em>removeMin</em> operations</li></ul></li><li>Selection-Sort<ul><li>Selection-sort is the variation of PQ-sort where the prioroty queue is implemented with an unsorted sequence</li><li>Running time of Selection-sort:<ul><li>Inserting the elements into the priority queue with $n$ insert operations takes $O(n)$ time</li><li>Removing the elements in sorted order from the priority queue with $n$ <em>removeMin</em> operations takes time proportional to $1+2+\cdots + n$</li></ul></li><li>Selection-sort runs in $O(n^2)$ time</li></ul></li><li>Insertion-Sort<ul><li>Insertion-sort is the variation of PQ-sort where the priority queue is implemented with a sorted sequence</li><li>Running time of Insertion-sort:<ul><li>Inserting the elements into the priority queue with $n$ <em>insert</em> operations takes time proportional to $1+2+\cdots +n$</li><li>Removing the elements in sorted order from the priority queue with a series of $n$ <em>removeMin</em> operations takes $O(n)$ time</li></ul></li><li>Insertion-sort runs in $O(n^2)$ time</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linear Regression</title>
      <link href="2021/06/01/Linear-Regression/"/>
      <url>2021/06/01/Linear-Regression/</url>
      
        <content type="html"><![CDATA[<h5 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h5><ul><li>$x^{(i)}$ to denote the â€œinputâ€ variables, also called input features.</li><li>$y^{(i)}$ to denote the â€œoutputâ€ or target variable that we are trying to predict.</li><li>A pair $(x^{(i)}, y^{(i)})$ is called a training example.</li><li>The dataset that weâ€™ll be using to learn - a list of $m$ training examples $(x^{(i)}, y^{(i)}); i = 1, \cdots, m$ - is called a training set.</li><li>Note that the superscript â€œ$(i)$â€ in the notation is simply an index into the training set, and has nothing to do with exponentiation.</li><li>$X$ to denote the space of input values.</li><li>$Y$ to denote the space of output values.</li></ul><h4 id="1-Model-Representation"><a href="#1-Model-Representation" class="headerlink" title="1. Model Representation"></a>1. Model Representation</h4><ul><li>Given a training set, to learn a function $h: X\rightarrow Y$ so that $h(x)$ is a â€œgoodâ€ predictor for the corresponding value of $y$. $h$ is called a hypothesis.</li><li>When the target variable that weâ€™re trying to predict is continuous, we call the learning problem a regression problem.</li></ul><h4 id="2-Cost-Function-Loss-Function"><a href="#2-Cost-Function-Loss-Function" class="headerlink" title="2. Cost Function (Loss Function)"></a>2. Cost Function (Loss Function)</h4><ul><li><p>This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from $x$â€™s and the actual output $y$â€™s.</p></li><li><p>$$<br>J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^{m}(\hat{y_i} - y_i)^2 = \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x_i) - y_i)^2<br>$$</p></li><li><p>This function is otherwise called the â€œSquared error functionâ€, or â€œMean squared errorâ€. The mean is halved $(\frac{1}{2})$ as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the $\frac{1}{2}$ term.</p></li><li><p>As a goal, we should try to minimize the cost function.</p></li></ul><h4 id="3-Gradient-Descent"><a href="#3-Gradient-Descent" class="headerlink" title="3. Gradient Descent"></a>3. Gradient Descent</h4><ul><li><p>The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is determined by the parameter $\alpha$, which is called the learning rate.</p></li><li><p>A smaller $\alpha$ would result in a smaller step and a larger $\alpha$ results in a larger step. The direction in which the step is taken is determined by the partial derivative of $J(\theta_0, \theta_1)$.</p></li><li><p>The gradient descent algorithm is:</p><ul><li><p>repeat until convergence:<br>$$<br>\theta_j := \theta_j - \alpha\frac{\partial}{\partial \theta_j}J(\theta_0, \theta_1)<br>$$<br>where</p><p>$j = 0, 1$ represents the feature index number.</p></li></ul></li><li><p>At each iterarion $j$, one should simultaneously update the parameters $\theta_1, \theta_2, \cdots, \theta_n$. Updating a specific parameter prior to calculating another one on the $j^{(th)}$ iteration would yield to a wrong implementation.</p></li><li><p>We should adjust our parameter $\alpha$ to ensure that the gradient descent algorithm converges in a reasonable time. Failure to converge or too much time to obtain the minimum value imply that our step size is wrong.</p></li><li><p>Gradient descent can converge to a local minimum, even with the learning rate $\alpha$ fixed. As we approach a local optimum, gradient descent will automatically take smaller steps. So, no need to decrese $\alpha$ over time.</p></li></ul><h4 id="4-Multiple-Features"><a href="#4-Multiple-Features" class="headerlink" title="4. Multiple Features"></a>4. Multiple Features</h4><ul><li><p>Linear regression with multiple variables is also known as <strong>â€œmultivariate linear regressionâ€</strong>.</p></li><li><p>$x^{(i)}_j = $ value of feature $j$ in the $i^{th}$ training example</p></li><li><p>$x^{(i)} = $ the input (features) of the $i^{th}$ training example</p></li><li><p>$m = $ the number of training examples</p></li><li><p>$n = $ the number of features</p></li><li><p>The multivariable form of the hypothesis function accommodating these multiple features is as follows:<br>$$<br>h_{\theta}(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 + \cdots + \theta_nx_n<br>$$</p></li><li><p>Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as:<br>$$<br>h_{\theta}(x) = \begin{bmatrix}\theta_0 &amp; \theta_1 &amp; \cdots &amp; \theta_n\end{bmatrix} \begin{bmatrix}x_0\x_1\ \vdots\ x_n\end{bmatrix} = \theta^Tx<br>$$</p></li></ul><h4 id="5-Gradient-Descent-for-Multiple-Variables"><a href="#5-Gradient-Descent-for-Multiple-Variables" class="headerlink" title="5. Gradient Descent for Multiple Variables"></a>5. Gradient Descent for Multiple Variables</h4><ul><li>repeat until convergence:<br>$$<br>\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})\times x_j^{(i)}\quad for\ j := 0\cdots n<br>$$</li></ul><h4 id="6-Gradient-Descent-in-Practice-Feature-Scaling"><a href="#6-Gradient-Descent-in-Practice-Feature-Scaling" class="headerlink" title="6. Gradient Descent in Practice - Feature Scaling"></a>6. Gradient Descent in Practice - Feature Scaling</h4><ul><li><p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because $\theta$ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p></li><li><p>The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally: $-1 \le x_{(i)} \le 1$ or $-0.5 \le x_{(i)} \le 0.5$. These arenâ€™t exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.</p></li><li><p>Two techniques to help with this are <strong>feature scaling</strong> and <strong>mean normalization</strong>. Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. Mean normalization involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. To implement both of these techniques, adjust your input values as shown this formula:<br>$$<br>x_i := \frac{x_i - \mu_i}{s_i}<br>$$<br>Where $\mu_i$ is the <strong>average</strong> of all the values for feature $(i)$ and $s_i$ is the range of values (max - min), or $s_i$ is the standard deviation.</p></li></ul><h4 id="7-Gradient-Descent-in-Practice-Learning-Rate"><a href="#7-Gradient-Descent-in-Practice-Learning-Rate" class="headerlink" title="7. Gradient Descent in Practice - Learning Rate"></a>7. Gradient Descent in Practice - Learning Rate</h4><ul><li><strong>Debugging gradient descent.</strong> Make a plot with <em>number of iterations</em> on the x-axis. Now plot the cost function, $J(\theta)$ over the number of iterations of gradient descent. If $J(\theta)$ ever increases, then you probably need to decrease $\alpha$.</li><li><strong>Automatic convergence test.</strong> Declare convergence if $J(\theta)$ decreases by less than $E$ in one iteration, where $E$ is some small value such as $10^{-3}$. However in practice itâ€™s difficult to choose this threshold value.</li><li>It has been proven that if learning rate $\alpha$ is sufficiently small, then $J(\theta)$ will decrease on every iteration.</li><li>To summarize:<ul><li>If $\alpha$ is too small: slow convergence.</li><li>If $\alpha$ is too large: may not decrease on every iteration and thus may not converge.</li></ul></li></ul><h4 id="8-Features-and-Polynomial-Regression"><a href="#8-Features-and-Polynomial-Regression" class="headerlink" title="8. Features and Polynomial Regression"></a>8. Features and Polynomial Regression</h4><ul><li>We can improve our features and the form of our hypothesis function in a couple different ways.</li><li>We can <strong>combine</strong> multiple features into one.</li><li><strong>Polynomial Regression</strong><ul><li>Our hypothesis function need not be linear (a straight line) if that does not fit the data well.</li><li>We can <strong>change the behavior or curve</strong> of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).</li><li>For example, if our hypothesis function is $h_{\theta}(x) = \theta_0 + \theta_1 x_1$ then we can create additional features based on $x_1$, to get the quadratic function $h_{\theta}(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_1^2$.</li><li>One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important.</li></ul></li></ul><h4 id="9-Normal-Equation"><a href="#9-Normal-Equation" class="headerlink" title="9. Normal Equation"></a>9. Normal Equation</h4><ul><li><p>A second way of minimizing $J$.</p></li><li><p>In the â€œNormal Equationâ€ method, we will minimize $J$ by explicitly taking its derivatives with respect to the $\theta_j$â€™s, and setting them to zero. This allows us to find the optimum theta without iteration. The normal equation formula is given below:<br>$$<br>\theta = (X^TX)^{-1}X^Ty<br>$$</p></li><li><p>There is <strong>no need</strong> to do feature scaling with the normal equation.</p></li><li><p>The comparison of gradient descent and the normal equation:</p><img src="/2021/06/01/Linear-Regression/Screen Shot 2021-06-04 at 10.02.03 PM.png" style="zoom:50%;"></li><li><p>With the normal equation, computing the inversion has complexity $O(n^3)$. So if we have a very large number of features, the normal equation will be slow. In practice, when $n$ exceeds $10,000$ it might be a good time to go from a normal solution to an iterative process.</p></li><li><p><strong>Noninvertibility</strong></p><ul><li>If $X^TX$ is <strong>noninvertible</strong>, the common causes might be having:<ul><li>Redundant features, where two features are very closely related (i.e. they are linearly dependent)</li><li>Too many features (e.g. $m\le n$). In this case, delete some features or use â€œregularizationâ€.</li></ul></li><li>Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> self-study notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Red-Black Tree</title>
      <link href="2021/05/26/Red-Black-Tree/"/>
      <url>2021/05/26/Red-Black-Tree/</url>
      
        <content type="html"><![CDATA[<h2 align="center">Red-Black Trees</h2><h4 id="1-Definition"><a href="#1-Definition" class="headerlink" title="1. Definition"></a>1. Definition</h4><ul><li>A red-black tree is a binary search tree that satisfies the following properties:<ul><li><strong>Root Property</strong>: the root is black</li><li><strong>External Property</strong>: every leaf is black</li><li><strong>Internal/Red Property</strong>: the children of a red node are black</li><li><strong>Depth Property</strong>: all the leaves have the same <em>black depth</em>, defined as the number of proper ancestors that are black</li></ul></li></ul><h4 id="2-From-Red-Black-to-2-4-Trees"><a href="#2-From-Red-Black-to-2-4-Trees" class="headerlink" title="2. From Red-Black to $(2,4)$ Trees"></a>2. From Red-Black to $(2,4)$ Trees</h4><ul><li>Given a red-black tree, we can construct a corresponding $(2,4)$ tree:<ul><li>merge every red node $w$ into its parent, storing the entry from $w$ at its parent</li><li>the children of $w$ become ordered children of the parent</li></ul></li><li>Depth Property:<ul><li>$(2,4)$ Tree: all the external nodes have the same depth</li><li>Red-Black Tree: all the leaves have the same <em>black depth</em></li></ul></li><li>A red-black tree is a representation of a $(2,4)$ tree by means of a binary tree whose nodes are colored red or black</li><li>In comparison with its associated $(2,4)$ tree, a red-black tree has<ul><li>same logarithmic time performance</li><li>simpler implementation with a single node type</li></ul></li></ul><h4 id="3-Height-of-a-Red-Black-Tree"><a href="#3-Height-of-a-Red-Black-Tree" class="headerlink" title="3. Height of a Red-Black Tree"></a>3. Height of a Red-Black Tree</h4><ul><li>Theorem: A red-black tree storing $n$ items has height $O(\log n)$<ul><li>Proof:<ul><li>The height of a red-black tree is at most twice the height of its associated $(2,4)$ tree, which is $O(\log n)$</li></ul></li></ul></li></ul><h4 id="4-Search"><a href="#4-Search" class="headerlink" title="4. Search"></a>4. Search</h4><ul><li>The search algorithm for a red-black tree is the same as that for a binary search tree</li><li>Searching in a red-black tree takes $O(\log n)$ time</li></ul><h4 id="5-Insertion"><a href="#5-Insertion" class="headerlink" title="5. Insertion"></a>5. Insertion</h4><ul><li><p>To insert $(k, o)$, we execute the insertion algorithm for binary search trees and color <strong>red</strong> the newly inserted node $z$ <em>unless it is the root</em></p><ul><li>We preserve the root, external, and depth properties</li><li>If the parent $v$ of $z$ is black, we also preserve the internal property and we are done</li><li>Else ($v$ is red) we have a <strong>double red</strong> (i.e., a violation of the internal property), which requires a reorganization of the tree</li></ul></li><li><p><strong>Remedying a Double Red</strong></p><ul><li>Consider a double red with child $z$ and parent $v$, and let $w$ be the sibling of $v$</li><li>Case1: $w$ is black<ul><li>The double red is an incorrect replacement of a 4-node</li><li><strong>Restructuring</strong>: we change the 4-node replacement</li></ul></li><li>Case2: $w$ is red<ul><li>The double red corresponds to an overflow</li><li><strong>Recoloring</strong>: we perform the equivalent of a <strong>split</strong></li></ul></li></ul></li><li><p><strong>Restructuring</strong></p><ul><li><p>A restructuring remedies a child-parent double red when the parent red node has a black sibling</p></li><li><p>It is equivalent to restoring the <em>correct replacement</em> of a 4-node</p></li><li><p>The internal property is restored and the other properties are preserved</p></li><li><p>There are four restructuring configrations depending on whether the double red nodes are left or right children</p><img src="/2021/05/26/Red-Black-Tree/Screen Shot 2021-05-10 at 7.22.25 PM.png" style="zoom:50%;"></li></ul></li><li><p><strong>Recoloring</strong></p><ul><li>A recoloring remedies a child-parent double red when the parent red node has a red sibling</li><li>The parent $v$ and its sibling $w$ become black and the grandparent $u$ becomes red, unless it is the root</li><li>It is equivalent to performing a split on a 5-node</li><li><em>The double red violation may propagate to the grangparent $u$</em></li></ul></li><li><p>Analysis of Insertion</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Algorithm insert(k, o)1. We search for key k to locate the insertion node z2. We add the new entry (k, o) at node z and color z red3. while doubleRed(z)        if isBlack(sibling(parent(z)))            z <- restructure(z)            return        else sibling(parent(z)) is red            z <- recolor(z)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Recall that a red-black tree has $O(\log n)$ height</p></li><li><p>Step 1 takes $O(\log n)$ time because we visit $O(\log n)$ nodes</p></li><li><p>Step 2 takes $O(1)$ time</p></li><li><p>Step 3 takes $O(\log n)$ time because we perform</p><ul><li>$O(\log n)$ recoloring, each taking $O(1)$ time, and</li><li>at most one restructuring taking $O(1)$ time</li></ul></li><li><p>Thus, an insertion in a red-black tree takes $O(\log n)$ time</p></li></ul></li></ul><h4 id="6-Deletion"><a href="#6-Deletion" class="headerlink" title="6. Deletion"></a>6. Deletion</h4><ul><li>To perform operation $remove(k)$, we first execute the deletion algorithm for binary search trees</li><li>Let $v$ be the internal node removed, $w$ the external node removed, and $r$ the sibling of $w$<ul><li>If $v$ was red, the resulting tree remains a valid red-black tree</li><li>If $v$ was black and $r$ was red, we color $r$ black and we are done</li><li>Else ($v$ and $r$ were both black) we color $r$ <em><strong>double black</strong></em>, to preserve the depth property</li></ul></li><li><strong>Remedying a Double Black</strong><ul><li>The algorithm for remedying a double black node $r$ with sibling $y$ considers three cases</li><li>Case1: $y$ is black and has a red child<ul><li>We perform a <strong>restructuring</strong>, equivalent to a <strong>transfer</strong>, and we are done.</li></ul></li><li>Case2: sibling $y$ of $r$ is black and its children are both black<ul><li>We perform a <strong>recoloring</strong>, equivalent to a <strong>fusion</strong>, which may propagate up the double black violation</li></ul></li><li>Case3: $y$ is red<ul><li>We perform an <strong>adjustment</strong>, equivalent to choosing a different representation of a 3-node, after which either Case 1 or Case 2 applies</li></ul></li></ul></li><li>Deletion in a red-black tree takes $O(\log n)$ time</li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Formal Languages</title>
      <link href="2021/05/15/Formal-Languages/"/>
      <url>2021/05/15/Formal-Languages/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Basic-Concepts"><a href="#1-Basic-Concepts" class="headerlink" title="1. Basic Concepts"></a>1. Basic Concepts</h4><ul><li><p><strong>Alphabet</strong>: a finite, nonempty set $\Sigma$ of symbols.</p></li><li><p><strong>String</strong>: a finite sequence of symbols from $\Sigma$</p></li><li><p>substring, prefix and suffix</p></li><li><p>The empty string has length 0 and is written as $\lambda$</p><ul><li>It is a prefix, substring and suffix of any given string</li><li>Operations (suppose <strong>v = aba</strong> and <strong>w = abaaa</strong>):<ul><li>Concatenation: <strong>vw = abaabaaa</strong></li><li>Reverse: <strong>w<sup>R</sup> = aaaba</strong></li><li>Repetition: <strong>v<sup>2</sup> = abaaba</strong> and <strong>v<sup>0</sup> = $\lambda$</strong></li></ul></li></ul></li><li><p>If $\Sigma$ is an alphabet, then we use $\Sigma^*$ to denote the set of strings obtained by concatenating zero or more symbols from $\Sigma$. The set $\Sigma^*$ always contains $\lambda$.</p><ul><li>$\Sigma^*$ = the set of <strong>all strings</strong> formed by concatenating zero or more symbols in $\Sigma$</li><li>$\Sigma^+$ = the set of all <strong>non-empty</strong> strings formed by concatenating symbols in $\Sigma$</li><li>$\Sigma^+ = \Sigma^* - {\lambda}$</li></ul></li><li><p>A <strong>formal language L</strong> is any subset of $\Sigma^*$</p><ul><li>The <strong>complement</strong> of <strong>L</strong> is: $\overline{L} = \Sigma^* - L$</li><li>Reverse: $L^R = {w^R, w\in L}$</li><li>Concatenation: $L_1L_2 = {xy: x\in L_1, y \in L_2}$</li><li>$L^n$ as $L$ concatenated with itself $n$ times<ul><li>$L^0 = {\lambda}$</li><li>$L^1 = L$</li></ul></li><li><strong>Star-closure</strong>: $L^* = L^0\bigcup L^1\bigcup L^2\cdots$</li><li><strong>Positive-closure</strong>: $L^+ = L^1\bigcup L^2\cdots$</li><li>ç©ºé›†å’Œ${\lambda}$éƒ½æ˜¯ä¸€ç§è¯­è¨€</li></ul></li><li><p>A grammar G is defined as a quadruple $G = (V, T, S, P)$ (the sets $V$ and $T$ are non-empty and disjoint):</p><ul><li>$V$: a finite set of objects called <strong>variables</strong> or non-terminal symbols</li><li>$T$: a finite set of objects called <strong>terminal symbols</strong></li><li>$S\in V$: a special symbol called the <strong>start</strong> symbol</li><li>$P$: a finite set of <strong>productions</strong></li><li>Production rules are of the form: $x\rightarrow y$, where $x$ is an element of $(V\cup T)^+$ and $y$ is in $(V\cup T)^*$</li></ul></li><li><p>For a given grammar G, the language generated by G, L(G), is the set of all strings derived from the start  symbol.</p><ul><li>$L(G) = {w\in T^*: S \stackrel*\Rightarrow w}$</li><li>If $w\in L(G)$, then the sequence $S\Rightarrow w_1 \Rightarrow w_2 \Rightarrow \cdots \Rightarrow w_n \Rightarrow w$ is a <strong>derivation</strong> of the sentence $w$. The strings $S, w_1, w_2, \cdots, w_n$, which contain variables as well as terminals, are called <strong>sentential forms</strong> of the derivation</li></ul></li><li><p>Automata</p><ul><li>An automaton is an abstract model of a digital computer</li><li>An automaton consists of<ul><li>An input mechanism</li><li>A control unit</li><li>Possibly, a storage mechanism</li><li>Possibly, an output mechanism</li></ul></li></ul></li></ul><h4 id="2-Finite-Automata"><a href="#2-Finite-Automata" class="headerlink" title="2. Finite Automata"></a>2. Finite Automata</h4><h5 id="2-1-Deterministic-Finite-Acceptors"><a href="#2-1-Deterministic-Finite-Acceptors" class="headerlink" title="2.1 Deterministic Finite Acceptors"></a>2.1 Deterministic Finite Acceptors</h5><ul><li><p>A <strong>deterministic finite acceptor</strong> or <strong>dfa</strong> is defined by the quintuple<br>$$<br>M = (Q, \Sigma, \delta, q_0, F)<br>$$<br>where</p><p>â€‹        $Q$ is a finite set of <strong>internal states</strong>,</p><p>â€‹        $\Sigma$ is a finite set of symbols called the <strong>input alphabet</strong>,</p><p>â€‹        $\delta : Q\times \Sigma \rightarrow Q$ is a total function called the <strong>transition function</strong>,</p><p>â€‹        $q_0 \in Q$ is the <strong>initial state</strong>,</p><p>â€‹        $F\subseteq Q$ is a set of <strong>finite states</strong>.</p></li><li><p>Extended Transition Function: $\delta^*$<br>$$<br>\delta^*: Q \times \Sigma^* \rightarrow Q<br>$$<br>For any given $q \in Q, w \in \Sigma^*, a \in \Sigma$:</p><p>â€‹    $\delta^*(q,\lambda) = q$</p><p>â€‹    $\delta^*(q, wa) = \delta(\delta^*(q, w), a)$</p></li><li><p>The language accepted by a DFA $M = (Q, \Sigma, \delta, q_0, F)$ is the set of all strings on $\Sigma$ accepted by $M$, i.e. the set of all strings $w$ such that $\delta^*(q_0, w)$ results in a final state:<br>$$<br>L(M) = {w \in \Sigma^* : \delta^*(q_0, w) \in F}<br>$$</p></li><li><p><strong>Theorem 2.1</strong></p><ul><li>Let $M = (Q, \Sigma, \delta, q_0, F)$ be a deterministic finite accepter, and let $G_M$ be its associated transition graph. Then for every $q_i, q_j \in Q$, and $w \in \Sigma^+$, $\delta^*(q_i, w) = q_j$ if and only if there is in $G_M$ a walk with label $w$ from $q_i$ to $q_j$</li></ul></li><li><p>Notes</p><ul><li>Finite accepters are characterized by having no temporary storage</li><li>Since an input file cannot be rewritten, a finite automaton is severely limited in its capacity to â€œrememberâ€ things during the computation</li><li>A finite amount of information can be retained in the control unit by placing the unit into a specific state</li><li>But since the number of such states is finite, a finite automaton can only deal with situations in which the information to be stored at any time is strictly bounded</li></ul></li><li><p>Regular Languages</p><ul><li>A language $L$ is <strong>regular</strong> if and only if there is a DFA that accepts $L$</li></ul></li></ul><h5 id="2-2-Nondeterministic-Finite-Accepter-NFA"><a href="#2-2-Nondeterministic-Finite-Accepter-NFA" class="headerlink" title="2.2 Nondeterministic Finite Accepter (NFA)"></a>2.2 Nondeterministic Finite Accepter (NFA)</h5><ul><li><p>A <strong>nondeterministic finite accepter</strong> or <strong>nfa</strong> is defined by the quintuple<br>$$<br>M = (Q, \Sigma, \delta, q_0, F)<br>$$<br>where $Q, \Sigma, q_0, F$ are defined as for deterministic finite accepter, but<br>$$<br>\delta : Q \times (\Sigma \cup {\lambda}) \rightarrow 2^Q<br>$$<br>where $2^Q$ is the set of all subsets of $Q$ (i.e., the power set of $Q$)</p></li><li><p>The basic differences between deterministic and nondeterministic finite automata are:</p><ul><li>In an NFA, a (state, symbol) combination may lead to several states <u>simultaneously</u></li><li>An NFA may have <u>undefined transitions</u></li><li>If a transition is labeled with the empty string as its input symbol, the NFA may change states <u>without consuming input</u></li></ul></li><li><p>The language $L$ accepted by an nfa $M = (Q, \Sigma, \delta, q_0, F)$ is defined as the set of all strings accepted in the above sense. Formally,<br>$$<br>L(M) = {w \in \Sigma^* : \delta^*(q_0, w) \cap F \neq \emptyset}<br>$$</p></li></ul><h5 id="2-3-Equivalence-of-Deterministic-and-Nondeterministic-Finite-Accepters"><a href="#2-3-Equivalence-of-Deterministic-and-Nondeterministic-Finite-Accepters" class="headerlink" title="2.3 Equivalence of Deterministic and Nondeterministic Finite Accepters"></a>2.3 Equivalence of Deterministic and Nondeterministic Finite Accepters</h5><ul><li><strong>Theorem 2.2</strong><ul><li>Let $L$ be the language accepted by a nondeterministic finite accepter $M_N = (Q_N, \Sigma, \delta_N, q_0, F_N)$. Then there exists a deterministic finite accepter $M_D = (Q_D, \Sigma, \delta_N, {q_0}, F_D)$ such that $L = L(M_D)$</li><li>For <u>any</u> nondeterministic finite accepter, there is an equivalent deterministic finite accepter.</li><li>Therefore, <em>every language accepted by a nondeterministic finite accepter is also regular.</em></li></ul></li><li>Procedure: NFA-to-DFA Conversion<ol><li>Beginning with the start state, define input transitions for the DFA as follows:<ul><li>If the NFA input transition leads to a single state, replicate for the DFA.</li><li>If the NFA input transition leads to more than one state, create a new state in the DFA labeled ${q_i, \cdots, q_j}$, where $q_i, \cdots, q_j$ are all the states the NFA transition can lead to.</li><li>If the NFA input transition is not defined, the corresponding DFA transition should lead to a trap state.</li></ul></li><li>Repeat step 1 for all newly created DFA states, until no new states are created.</li><li>Any DFA state containing an NFA final state in its label should be labeled as final.</li><li>If the NFA accepts the empty string, label the start DFA state a final state.</li></ol></li></ul><h4 id="3-Regular-Languages-and-Regular-Grammars"><a href="#3-Regular-Languages-and-Regular-Grammars" class="headerlink" title="3. Regular Languages and Regular Grammars"></a>3. Regular Languages and Regular Grammars</h4><h5 id="3-1-Regular-Expressions"><a href="#3-1-Regular-Expressions" class="headerlink" title="3.1 Regular Expressions"></a>3.1 Regular Expressions</h5><ul><li><p>Regular Expressions are defined recursively. For any alphabet $\Sigma$:</p><ol><li>Primitive regular expressions:<ul><li>the empty set $\emptyset$</li><li>the empty string $\lambda$</li><li>any symbol of the alphabet $a \in \Sigma$</li></ul></li><li>If $r_1$ and $r_2$ are regular expressions, then so are:<ul><li>the union $r_1 + r_2$</li><li>concatenation $r_1 \cdot r_2$ or $r_1r_2$</li><li>star closure $r_1^*$</li></ul></li><li>Any string resulting from a <em>finite</em> number of these operations on primitive regular expressions is also a regular expression.</li></ol></li><li><p>Languages Associated with Regular Expressions</p><ul><li>A regular expressions $r$ denotes a language $L(r)$</li><li>Assuming that $r_1$ and $r_2$ are regular expressions:<ol><li>The regular expression $\emptyset$ denotes the empty set</li><li>The regular expression $\lambda$ denotes the set ${\lambda}$</li><li>For any $a$ in the alphabet $\Sigma$, the regular expression $a$ denotes the set ${a}$</li><li>The regular expression $r_1 + r_2$ denotes $L(r_1) \cup L(r_2)$</li><li>The regular expression $r_1 \cdot r_2$ denotes $L(r_1)L(r_2)$</li><li>The regular expression $(r_1)$ denotes $L(r_1)$</li><li>The regular expression $r_1^*$ denotes $(L(r_1))^*$</li></ol></li></ul></li></ul><h5 id="3-2-Regular-Expressions-and-Regular-Languages"><a href="#3-2-Regular-Expressions-and-Regular-Languages" class="headerlink" title="3.2 Regular Expressions and Regular Languages"></a>3.2 Regular Expressions and Regular Languages</h5><ul><li><p><strong>Theorem 3.1</strong></p><ul><li>For any regular expression $r$, there is a nondeterministic finite automaton that accepts the language denoted by $r$.</li></ul></li><li><p>Since nondeterministic and deterministic accepters are equivalent, for any regular expression $r$, the language $L(r)$ is also regular.</p></li><li><p><strong>Primitive regular expressions</strong></p><ul><li>We can construct simple automata that accept the languages associated with:<ul><li>the empty set</li><li>the empty string</li><li>any individual symbol $a \in \Sigma$</li></ul></li></ul><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-03-23 at 11.56.19 AM.png" style="zoom:50%;"><ul><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-03-23 at 12.03.27 PM.png" style="zoom:50%;"></li><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-03-23 at 12.04.22 PM.png" style="zoom:50%;"></li><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-03-23 at 12.04.52 PM.png" style="zoom:50%;"></li><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-03-23 at 12.05.25 PM.png" style="zoom:50%;"></li></ul></li><li><p>Regular Expressions for Regular Languages</p><ul><li><strong>Theorem 3.2</strong><ul><li>For every regular language $L$, it is possible to construct a corresponding regular expression $r$ satisfying $L = L(r)$</li></ul></li></ul></li></ul><h5 id="3-3-Regular-grammars"><a href="#3-3-Regular-grammars" class="headerlink" title="3.3 Regular grammars"></a>3.3 Regular grammars</h5><ul><li><p>A grammar $G = (V, T, S, P)$ is said to be <strong>right-linear</strong> if all productions are of the form<br>$$<br>A \rightarrow xB,\<br>A \rightarrow x,<br>$$<br>where $A, B \in V$, and $x \in T^*$. A grammar is said to be <strong>left-linear</strong> if all productions are of the form<br>$$<br>A \rightarrow Bx,\<br>A \rightarrow x.<br>$$</p></li><li><p>In a <em><u>right-linear grammar</u></em>, at most one variable symbol appears on the right side of any production. If it occurs, it is the <em><strong>rightmost</strong></em> symbol.</p></li><li><p>In a <em><u>left-linear grammar</u></em>, at most one variable symbol appears on the right side of any production. If it occurs, it is the <em><strong>leftmost</strong></em> symbol.</p></li><li><p>A <strong>regular grammar</strong> is one that is either right-linear or left-linear.</p></li><li><p>Right-Linear grammars Generate Regular Languages</p><ul><li><strong>Theorem 3.3</strong><ul><li>For any given right-linear grammar $G$, the language $L(G)$ is regular</li></ul></li><li>The algorithm for constructing an NFA to accept the language generated by a given right-linear grammar $G$:<ul><li>Label the NFA start state with $S$ and a final state $V_f$</li><li>For every variable symbol $V_i$ in $G$, create an NFA state and label it $V_i$</li><li>For each production of the form $A \rightarrow aB$, label a transition from state $A$ to $B$ with symbol $a$</li><li>For each production of the form $A \rightarrow a$, label a transition from state $A$ to $V_f$ with symbol a:<ul><li>You need to add intermediate states for productions with more than one terminal on the right hand side.</li></ul></li></ul></li></ul></li><li><p>Right-Linear grammars for Regular Languages</p><ul><li><strong>Theorem 3.4</strong><ul><li>If $L$ is a regular language on the alphabet $\Sigma$, then there exists a right-linear grammar $G = (V, \Sigma, S, P)$ such that $L = L(G)$</li></ul></li><li>There is an algorithm that, given any DFA $M$ accepting a regular language $L$, constructs a right-linear grammar $G$ which generates the same language:<ul><li>Each state in the DFA corresponds to a variable symbol in $G$</li><li>For each DFA transition from state $A$ to state $B$ labeled with symbol $a$, there is a production of the form $A \rightarrow aB$ in $G$</li><li>For each final state $F_i $ in the DFA, there is a corresponding production $F_i \rightarrow \lambda$ in $G$</li></ul></li></ul></li><li><p>Equivalence of Regular Languages and Regular grammars</p><ul><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-03-27 at 12.46.52 PM.png" style="zoom:50%;"></li></ul></li></ul><h4 id="4-Properties-of-Regular-Languages"><a href="#4-Properties-of-Regular-Languages" class="headerlink" title="4. Properties of Regular Languages"></a>4. Properties of Regular Languages</h4><ul><li><p>Closure Properties</p><ul><li><strong>Theorem 4.1</strong><ul><li>If $L_1$ and $L_2$ are regular languages, so are the languages that result from the following operations:<ul><li>$L_1 \cup L_2$</li><li>$L_1 \cap L_2$</li><li>$L_1L_2$</li><li>$\overline{L_1}$</li><li>$L_1^*$</li></ul></li><li>In other words, the family of regular language is <strong>closed</strong> under union, intersection, concatenation, complementation, and star-closure.</li></ul></li></ul></li><li><p>Closure under Reversal</p><ul><li><strong>Theorem 4.2</strong><ul><li>If $L$ is a regular language, so is $L^R$</li></ul></li></ul></li><li><p>A Membership Algorithm for Regular Languages</p><ul><li>We say that a regular language is given in a <strong>standard representation</strong> if and only if it is described by one of the following:<ul><li>a finite automaton,</li><li>a regular expression,</li><li>or a regular grammar</li></ul></li><li><strong>Theorem 4.5</strong> confirms the existence of a <strong>membership</strong> algorithm for reguklar languages</li><li>To determine if an arbitrary string $w$ is in a regular language $L$, we assume we are given a standard representation of $L$m which we then convert to a DFA that accepts $L$</li><li>Simulate the operation of the DFA while processing $w$ as the input string</li><li>If the machine halts in a final state after processing $w$, then $w\in L$, otherwise, $w\notin L$.</li></ul></li><li><p>Determining whether a regular language is empty, finite or infinite</p><ul><li><strong>Theorem 4.6</strong> confirms the existence of an <em><strong>algorithm</strong></em> to determine if a regular language is <em><strong>empty, finite, or infinite</strong></em></li><li>Given the <em><strong>transition graph</strong></em> of a DFA that accepts $L$,<ul><li>If there is a simple path from the start state to any final state, $L$ is not empty (since it contains, at least, the corresponding string)</li><li>If a path form the start state to a final state includes a vertex which is the base of some cycle, $L$ is infinite (otherwise, $L$ is finite)</li></ul></li></ul></li><li><p>Determining whether two regular languages are equal</p><ul><li><p><strong>Theorem 4.7</strong> confirms the existence of an algorithm to determine if two regular languages $L_1$ and $L_2$ are equal:</p><ul><li><p>Define the language $L = (L_1 \cap \overline{L_2}) \cup (\overline{L_1} \cap L_2)$</p></li><li><p>By closure properties, $L$ is regular</p></li><li><p>So we can construct a DFA $M$ to accept it, and by Theorem 4.6, we can determine whether $L$ is emoty or not.</p></li><li><p>$L_1$ and $L_2$ are equal if and only if $L$ is empty</p></li></ul></li></ul></li><li><p>Identifying Non-regular Languages</p><ul><li><p><strong>Pigeonhole Principle:</strong> If we put $n$ objects into $m$ boxes (pigeonholes), and if $n &gt; m$, then at least one box must have more than one item in it.</p></li><li><p>This simple principle is the basis of most of the methods for proving non-regularity of languages.</p></li><li><p><strong>Basic observation:</strong> Although regular languages can be <em>infinite</em>, their associated automata have <em>finite</em> memory.</p></li></ul></li><li><p>The Pumping Lemma</p><ul><li>Suppose that $M = (Q, \Sigma, \delta, q_0, F)$ is a DFA with $n$ states that accepts a language $L$:<ul><li>If it accepts a string $x$ such that $|x| \ge n$, then by the time $n$ symbols have been read, $M$ must have entered some state more than once;</li><li>In other words, there must be two different prefixes $u$ and $uv$ such that $\delta^*(q_0, u) = \delta^*(q_0, uv)$</li><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-05-03 at 4.16.49 PM.png" style="zoom:50%;"></li></ul></li><li>This implies that there are many more strings in $L$, because we can traverse the loop $v$ any number of times (including leaving it out altogether).</li><li>In other words, all of the string $uv^iw$ for $i \ge 0$ are in $L$</li><li>This fact is known as the <em><strong>Pumping Lemma for Regular Languages</strong></em>.</li><li><strong>Theorem (<em>pumping property</em>):</strong> Suppose that $L$ is a language over $\Sigma$. If $L$ is accepted by the DFA $M = (Q, \Sigma, \delta, q_0, F)$, then there is an integer $n$ so that for every $x$ in $L$ satisfying $|x| \ge n$, there are three strings $u, v$, and $w$ such that $x = uvw$ and:<ul><li>$|uv| \le n$;</li><li>$v &gt; 0 (i.e. v \ne \lambda) $</li><li>For every $i \ge 0$, the string $uv^iw$ belongs to $L$</li></ul></li><li>The way we found $n$ was to take the number of states in an FA accepting $L$.</li><li>In many applications we donâ€™t need to know this, only that there is such an $n$.</li><li>The statement of the Pumping lemma is as follows:<ul><li>If $L$ is regular $\Rightarrow$ the pumping property holds</li></ul></li><li>In practice, we use the contrapositive:<ul><li>If the pumping property does not hold $\Rightarrow$ the language $L$ is not regular</li></ul></li><li>Thus, the most common application of the pumping lemma is to show that a language is not regular</li><li>The proof is by contradiction. We suppose that the language can be accepted by an FA, and we let $n$ be the integer in the pumping lemma</li><li>Then we choose a string $x$ with $|x| \ge n$ to which we can apply the lemma so as to get a contradiction.</li><li>Note that the Pumping lemma only provides a <em><strong>necessary</strong></em> condition, but not a sufficient one.<ul><li>If $L$ is regular $\Rightarrow$ the pumping property holds</li></ul></li><li>In other words, it does not say anything about the pumping property when L is not regular</li><li>In fact, <em><strong>there are languages that do satisfy the pumping lemma, but are not regular</strong></em>, e.g.:<ul><li>$L = {a^ib^jc^j\mid i\ge 1\ and\ j \ge 0}\cup{b^jc^k\mid j\ge 0\ and\ k\ge 0}$</li></ul></li></ul></li></ul><h4 id="5-Context-Free-Languages"><a href="#5-Context-Free-Languages" class="headerlink" title="5. Context Free Languages"></a>5. Context Free Languages</h4><h5 id="5-1-Context-Free-Grammars"><a href="#5-1-Context-Free-Grammars" class="headerlink" title="5.1 Context-Free Grammars"></a>5.1 Context-Free Grammars</h5><ul><li><p>Definition:</p><ul><li><p>We call $G = (V, \Sigma, S, P)$ a <strong><em>context-free grammar</em> (CFG)</strong> if all productions in $P$ have the form:</p><ul><li>$A\rightarrow x$</li></ul><p>in which $A\in V$, and $x\in (V\cup\Sigma)^*$.</p></li><li><p>We say that $L$ is a <strong><em>context-free language</em> (CFG)</strong> if and only if there is a context-free grammar $G$ such that $L = L(G)$</p><ul><li>In other words, a language is context-free if it is generated by a context-free grammar.</li></ul></li></ul></li><li><p>No Restriction on the Right Side</p><ul><li>A context-free grammar has <em>no restrictions</em> on the right side of its productions.</li><li>Therefore, the class of CFLs includes the class of regular languages as a proper subset.</li></ul></li><li><p>Restriction on the Left Side</p><ul><li>Note that, a context-free grammar does impose a restriction on the <em>left side</em> of productions:<ul><li><strong>the left side must be a single variable</strong></li></ul></li></ul></li></ul><h5 id="5-2-Leftmost-and-Rightmost-Derivations"><a href="#5-2-Leftmost-and-Rightmost-Derivations" class="headerlink" title="5.2 Leftmost and Rightmost Derivations"></a>5.2 Leftmost and Rightmost Derivations</h5><ul><li>In a <em>leftmost derivation</em> (LMD), at each step, the leftmost variable in a sentential form is replaced.</li><li>In a <em>rightmost derivation</em> (RMD), at each step, the rightmost variable in a sentential form is replaced.</li></ul><h5 id="5-3-Derivation-Trees"><a href="#5-3-Derivation-Trees" class="headerlink" title="5.3 Derivation Trees"></a>5.3 Derivation Trees</h5><ul><li>In a <em>derivation tree</em> or <em>parse tree</em>,<ul><li>the root is labeled $S$</li><li>internal nodes are labeled with a variable occurring on the left side of a production</li><li>the children of a node contain the symbols on the corresponding right side of a production</li></ul></li><li>In a full derivation tree, the root node represents the start variable $S$.</li><li>Any interior node and its children represent a production $A\rightarrow x$ used in the derivation;<ul><li>the node represents $A$, and the children, from left to right, represent the symbols in $x$.</li></ul></li><li>Each leaf node represents a symbol or $\lambda$.</li><li>The string derived is read off from left to right, ignoring $\lambdaâ€™$s.<ul><li>The <em><strong>yield</strong></em> of a derivation tree is the string of terminals produced by a leftmost depth-first traversal of the tree.</li></ul></li></ul><h5 id="5-4-Sentential-Forms-and-Derivation-Trees"><a href="#5-4-Sentential-Forms-and-Derivation-Trees" class="headerlink" title="5.4 Sentential Forms and Derivation Trees"></a>5.4 Sentential Forms and Derivation Trees</h5><ul><li><strong>Theorem 5.1</strong> states that:<ul><li>Given a context-free grammar $G$, for every string $w\in L(G)$, there exists a derivation tree whose yield is $w$.</li><li>The converse is also true: the yield of any derivation tree formed with productions from $G$ is in $L(G)$</li><li><strong>Note:</strong> Derivation trees show which productions are used in obtaining a sentence, but <em>do not give the order of their application</em>.</li></ul></li></ul><h5 id="5-5-Parsing-and-Membership"><a href="#5-5-Parsing-and-Membership" class="headerlink" title="5.5 Parsing and Membership"></a>5.5 Parsing and Membership</h5><ul><li><strong>The <em>parsing</em> problem</strong>: given a grammar $G$ and a string $w$, find a sequence of derivations using the productions in $G$ to produce $w$</li><li>To ensure that the problem may ne solved (regardless of efficiency) we need to require grammars to be given in a suitable shape</li><li>Exhausive parsing is guaranteed to yield all strings eventually, but many fail to stop for strings not in $L(G)$, unless we restrict the productions in the grammar.</li><li>Questions about the strings generated by a CFg are sometimes easier to answer if the productions have a retricted form:<ul><li>For example, if we know that a grammar has:<ul><li>no $\lambda$-productions ($A\rightarrow \lambda$),</li><li>and no unit productions ($A\rightarrow B$),</li></ul></li><li>we can deduce that no derivation of a string $x$ can take more than $2\vert x\vert - 1$.</li><li>We could then, in principle, determine whether $x$ can be derived by considering derivations no longer than $2\vert x\vert - 1$.</li></ul></li><li>There exists an algorithm which, for every CFG $G = (V, \Sigma, S, P)$, produces a CFG $G_1 = (V, \Sigma, S, P_1)$ which has no $\lambda$-productions, no unit productions of the form $A\rightarrow B$, and for which:<ul><li>$L(G_1) = L(G)-{\lambda}$</li></ul></li><li>With this conversion, the parsing problem may be solved in an exhaustive, top-down, but not very efficient fashion:</li><li><strong><u>Theorem 5.2</u></strong>: Exhaustive parsing is guaranteed to yield all strings eventually, but may fail to stop for strings not in $L(G)$, <em>unless if the grammar has no $\lambda$-productions or unit productions</em>.</li></ul><h5 id="5-6-Parsing-and-Ambiguity"><a href="#5-6-Parsing-and-Ambiguity" class="headerlink" title="5.6 Parsing and Ambiguity"></a>5.6 Parsing and Ambiguity</h5><ul><li>If $G$ is a CFG, then for any $x\in L(G)$ these three statements are equivalent:<ul><li>$x$ has more than one derivation tree.</li><li>$x$ has more than one LMD.</li><li>$x$ has more than one RMD.</li></ul></li><li>Thus, a CFG $G$ is <em><strong>ambiguous</strong></em> if and only if, for at least one $x\in L(G)$, $x$ has more than one LMD (or RMD).</li></ul><h5 id="5-7-Derivation-Trees-and-Ambiguity"><a href="#5-7-Derivation-Trees-and-Ambiguity" class="headerlink" title="5.7 Derivation Trees and Ambiguity"></a>5.7 Derivation Trees and Ambiguity</h5><ul><li><p>A classic example of ambiguity is <strong>the dangling <em>else</em></strong>.</p></li><li><p>In C, an if-statement can be defined by:</p><ul><li>$S\rightarrow if\ (E)\ S\ \mid\ if\ (E)\ S\ else\ S\ \mid\ OS$  (Where $OS$ stands for â€œother statementâ€).</li></ul></li><li><p>Consider the statement</p><p>$if\ (e1)\ if\ (e2)\ f();\ else\ g();$</p><ul><li>In C, the <em>else</em> should belong to the second $if$, but this grammar does not rule out interpreting the statement with $else$ belonging to the first $if$.</li></ul></li><li><p>Clearly the grammar given is ambiguous, <em>but there are equivalent grammars that allow only the correct interpretation</em>. For example:</p><p>$S\rightarrow S_1\ \mid\ S_2$</p><p>$S_1\rightarrow \ if\ (E)\ S_1\ else\ S_1\ \mid\ OS$</p><p>$S_2\rightarrow\ if\ (E)\ S\ \mid\ if\ (E)\ S_1\ else\ S_2$</p></li><li><p>These rules generate the same strings as the original ones and are unambiguous.</p></li></ul><h5 id="5-8-Ambiguous-Languages"><a href="#5-8-Ambiguous-Languages" class="headerlink" title="5.8 Ambiguous Languages"></a>5.8 Ambiguous Languages</h5><ul><li>For some languages, it is always possible to find an unambiguous grammar.</li><li>However, there are <em><strong>inherently ambiguous</strong></em> languages, for which every possible grammar is ambiguous.</li></ul><h5 id="5-9-Pumping-lemma-for-CFGs"><a href="#5-9-Pumping-lemma-for-CFGs" class="headerlink" title="5.9 Pumping lemma for CFGs"></a>5.9 Pumping lemma for CFGs</h5><ul><li>For every CFL $L$ there exists a natural number $n$ such that for any string $u\in L$ with $|u|\ge n$, there are $v, w, x, y, z$ such that $u = vwxyz$ and:<ol><li>$|wxy|\le n$</li><li>$|wy|\gt 0$</li><li>$\forall i\in N : vw^ixy^iz\in L$</li></ol></li></ul><h4 id="6-Pushdown-Automata"><a href="#6-Pushdown-Automata" class="headerlink" title="6. Pushdown Automata"></a>6. Pushdown Automata</h4><h5 id="6-1-Introduction"><a href="#6-1-Introduction" class="headerlink" title="6.1 Introduction"></a>6.1 Introduction</h5><ul><li><p>CFLs do not have anything similar to regular expressions.</p></li><li><p>But they do have a machine model, i.e., pushdown automata.</p></li><li><p>A pushdown automaton is essentially a finite automaton with a <em><strong>stack</strong></em> added as storage.</p></li><li><p>As there is no limit on the size of the stack, pushdown automata do not have bounded memory limitation of finite automata.</p></li><li><p>Pushdown automata are equivalent to CFGs, as long as we allow them to be nondeterministic.</p></li><li><p>The language family associated with deterministic pushdown automata is a proper subset of the context-free languages.</p></li><li><p>There are CFLs (such as $A^nB^n$) that cannot be recognized by finite automata</p></li><li><p>This is because the memory of a finite automata is restricted to a finite set of states, whereas the recognition of a CFL may require storing an unbounded amount of information.</p></li><li><p>Consider the following languages:</p><ul><li>$A^nB^m = {a^nb^m\mid n, m \ge 0}$, which is regular;</li><li>$A^nB^n = {a^nb^n\mid n\ge 0}$, which is not regular.</li></ul></li><li><p>To recognize strings in $A^nB^m$, all we need to do is to check that $a$â€™s appear before $b$â€™s, a task which can be done by a DFA.</p></li><li><p>In constrast, for $A^nB^n$, we must not only check that all $a$â€™s precede the first $b$, we must also <em><strong>count</strong></em> the number of $a$â€™s.</p></li><li><p>Since $n$ is unbounded, this counting cannot be done with a finite memory.</p></li><li><p>As the example of $A^nB^n$ shows, for the machine model of CFLs, we need a machine that can <em><strong>count without limit</strong></em>.</p></li><li><p>But, that is not enough. For instance, consider $WW^R = {ww^R\mid w\in {a, b}^*$, which is a CFL.</p></li><li><p>$WW^R$ shows that we need more than unlimited counting ability:</p><ul><li>We need the ability to store and match a sequence of symbols in <em><strong>reverse</strong></em> order.</li></ul></li><li><p>This suggests that we might try a <em><strong>stack</strong></em> as a storage mechanism, allowing unbounded storage that is restricted to operating like a stack.</p></li><li><p>This gives us a class of machines called pushdown automata (PDA), which we use as a model of computation to process context-free languages.</p></li></ul><h5 id="6-2-Nondeterministic-Pushdown-Automata"><a href="#6-2-Nondeterministic-Pushdown-Automata" class="headerlink" title="6.2 Nondeterministic Pushdown Automata"></a>6.2 Nondeterministic Pushdown Automata</h5><ul><li><p>Each move of the control unit:</p><ul><li>reads a symbol from the input file;</li><li>changes the contents of the stack (<em>through the usual stack operations</em>).</li></ul></li><li><p>Each move of the control unit is determined by:</p><ul><li>the current input symbol</li><li>and the symbol currently on top of the stack.</li></ul></li><li><p>The result of the move is a new state of the control unit and a change in the top of the stack.</p></li><li><p>A <em>nondeterministic pushdown accepter</em> (NPDA) $M = (Q, \Sigma, \Gamma, \delta, q_0, z, F)$ is defined by:</p><ul><li><p>$Q$: the finite set of internal states of the control unit</p></li><li><p>$\Sigma$: the finite set of input alphabet</p></li><li><p>$\Gamma$: the finite set of stack alphabet</p></li><li><p>$\delta$: the transition function with the type signature:<br>$$<br>\delta: Q\times (\Sigma \cup {\lambda})\times \Gamma\rightarrow P_f(Q\times \Gamma^*)<br>$$<br>$P_f(Q\times \Gamma^*)$ is the set of <em>finite</em> subsets of $(Q\times \Gamma^*)$</p></li><li><p>$q_0\in Q$: the initial state of the control unit</p></li><li><p>$z\in \Gamma$: the stack start symbol</p></li><li><p>$F\subseteq Q$: the set of final states</p></li><li><p>The arguments of $\delta$ are:</p><ul><li>the current state of the control unit</li><li>the current input symbol</li><li>and the current symbol on <em>top</em> of the stack</li></ul></li><li><p>The result is a finite set of pairs $(q, x)$, where:</p><ul><li>$q$ is the next state of the control unit</li><li>and $x$ is a <em><strong>string</strong></em> that is put on top of the stack <em><strong>in place of the single symbol</strong></em> there before.</li></ul></li><li><p>$\lambda$-transition: When the second argument of $\delta$ is $\lambda$, i.e., a move that does not consume an input symbol.</p></li><li><p>$\delta$ Always needs a stack symbol; i.e., no move is possible if the stack is empty.</p></li><li><p>Finally, the requirement that the elements of the range of $\delta$ be a <em><strong>finite</strong></em> subset is necessary because:</p><ul><li>$Q\times \Gamma^*$ is an infinite set and therefore has infinite subsets.</li><li>While an NPDA may have several choices for its moves, <em>this choice must be restricted to a finite set of possibilities</em>.</li></ul></li><li><p><strong>Note</strong>: If a particular transition is not defined, the corresponding (state, symbol, stack top) configuration represents a <em>dead</em> state.</p></li></ul></li><li><p>Transition Graphs</p><ul><li>Label the edges of the graph with three things:<ul><li>the current input symbol</li><li>the symbol at the top of the stack</li><li>and the string that replaces the top of the stack</li></ul></li></ul></li><li><p>Instantaneous Descriptions</p><ul><li><p>While transition graphs are convenient for <em>describing</em> NPDAs, they are not so suitable for formal reasoning.</p></li><li><p>To trace the operation of an NPDA, we must keep track of:</p><ul><li>the current state of the control unit,</li><li>the unread part of the input string,</li><li>and the stack contents.</li></ul></li><li><p><strong><u>Instantaneous Description</u></strong>: The triplet $(q, w, u)$ in which:</p><ul><li>$q$ is the state of the control unit,</li><li>$w$ is the unread part of the input string,</li><li>and $u$ is the stack contents:<ul><li>with the leftmost symbol indicating the top of the stack</li></ul></li></ul><p>is called an instantaneous description of a pushdown automaton.</p></li><li><p>A move from one instantaneous description to another will be denoted by the symbol $\vdash$</p></li><li><p>Thus $(q_1, aw, bx)\vdash (q_2, w, yx)$ is possible if and only if:<br>$$<br>(q_2, y)\in \delta (q_1, a, b)<br>$$</p></li><li><p>Moves involving an arbitrary number of steps will be denoted by $\vdash^*$.</p></li></ul></li></ul><h5 id="6-3-The-Language-Accepted-by-an-NPDA"><a href="#6-3-The-Language-Accepted-by-an-NPDA" class="headerlink" title="6.3 The Language Accepted by an NPDA"></a>6.3 The Language Accepted by an NPDA</h5><ul><li><p>The language accepted by an NPDA is the set of all strings that cause the NPDA to halt in a final state, after starting in $q_0$ with only the stack symbol $z$ on the stack.</p></li><li><p><em>The final contents of the stack are irrelevant</em>.</p></li><li><p>As was the case with nondeterministic finite automata, the string is accepted if <em>at least one</em> of the computations cause the NPDA to halt in a final state.</p></li><li><p>In other words, it does not require all the possible traces to end up in a final state.</p></li><li><p><strong><u>Definition 7.2</u></strong>: Let $M = (Q, \Sigma, \Gamma, \delta, q_0, z, F)$ be an NPDA. The language accepted by $M$ is the set:<br>$$<br>L(M) = \lbrace w\in \Sigma^<em>\mid (q_0, w, z) \vdash^</em> (p, \lambda, u), p\in F, u \in \Gamma^*\rbrace<br>$$</p></li></ul><h5 id="6-4-NPDAs-and-CFLs"><a href="#6-4-NPDAs-and-CFLs" class="headerlink" title="6.4 NPDAs and CFLs"></a>6.4 NPDAs and CFLs</h5><ul><li><p>A context-free grammar is in <em>Greibach Normal Form</em> if, in all of its productions, the right side consists of a single terminal follows by any number of variables</p></li><li><p><strong><u>Definition 6.5</u></strong>: A context-free grammar $G = (V, T, S, P)$ is said to be in <em><strong>Greibach normal form</strong></em> if all productions have the form<br>$$<br>A\rightarrow ax<br>$$<br>where $a\in T$ and $x\in V^*$.</p></li><li><p><strong><u>Theorem 6.7</u></strong>: For every context-free grammar $G$ there exists a grammar $\hat{G}$ in Greibach normal form satisfying:<br>$$<br>L(\hat{G}) = L(G) - {\lambda}<br>$$</p></li></ul><h5 id="6-5-NPDAs-for-CFLs"><a href="#6-5-NPDAs-for-CFLs" class="headerlink" title="6.5 NPDAs for CFLs"></a>6.5 NPDAs for CFLs</h5><ul><li><p><strong><u>Theorem 7.1</u></strong> For any given $\lambda$-free context-free language $L$, there exists an NPDA $M$ such that<br>$$<br>L(M) = L<br>$$</p></li><li><p>The constructive proof of Theorem 7.1 provides an algorithm that can be used to build the corresponding NPDA, for any language specified by a grammar $G$ in Greibach normal form.</p></li><li><p>The resulting NPDA simulates grammar derivations by:</p><ul><li>keeping variables on the stack</li><li>while making sure that the input symbol matches the terminal on the right side of the production.</li></ul></li></ul><h5 id="6-6-Construction-of-an-NPDA-from-a-Grammar-in-Greibach-Normal-Form"><a href="#6-6-Construction-of-an-NPDA-from-a-Grammar-in-Greibach-Normal-Form" class="headerlink" title="6.6 Construction of an NPDA from a Grammar in Greibach Normal Form"></a>6.6 Construction of an NPDA from a Grammar in Greibach Normal Form</h5><ul><li>The NPDA $M = ({q_0, q_1, q_f}, T, V\cup{z}, \delta, q_0,z {q_f})$ has:<ul><li>three states $Q = {q_0, q_1, q_f}$, with $q_0$ as the initial state, and $q_f$ as the only final state</li><li>input alphabet equal to the grammar terminal symbols $T$,</li><li>and stack alphabet equal to the grammar variable $V$, plus $z$, with the assumption that $z\notin V$</li></ul></li><li>The transition function contains the following:<ul><li>A rule that pushes $S$ on the stack and switches control to $q_1$ without consuming input:<ul><li>$\delta (q_0, \lambda, z) = {(q_1, Sz)}$</li></ul></li><li>For every production of the form $A\rightarrow au$, we have<ul><li>$(q_1, u)\in \delta (q_1, a, A)$</li></ul></li><li>A rule that switches the control unit to the final state $q_f$ when there is no more input, and the stack is empty:<ul><li>$\delta(q_1, \lambda, z) = {(q_f, z)}$</li></ul></li><li>If $\lambda \in L$, we add the transition $\delta(q_0, \lambda, z) = {(q_f, z)}$</li></ul></li></ul><h5 id="6-7-CFGs-for-PDAs"><a href="#6-7-CFGs-for-PDAs" class="headerlink" title="6.7 CFGs for PDAs"></a>6.7 CFGs for PDAs</h5><ul><li><strong><u>Theorem 7.2</u></strong>: If $L = L(M)$ for some NPDA $M$, then there exists a context-free grammar $G$ such that $L(G) = L(M)$. In other words, $L$ is a context-free language.</li><li>Proof: The basic idea behind the proof is to reverse the process in the proof of Theorem 7.1</li><li>The aim is to construct a grammar that simulates the moves of the NPDA $M$.</li><li>In particular:<ul><li>the content of the stack should be reflected in the variable part of sentential forms in derivations,</li><li>while the processed input is the terminal prefix of the sentential forms.</li></ul></li><li>Theorem 7.1 and 7.2 show that the following are equivalent, in the sense that they generate the same class of languages, i.e., context-free languages:<ul><li>Context-free grammars</li><li>NPDAs</li></ul></li><li>Which specification one chooses depends on the purpose:<ul><li>For specifying programming language constructs, grammars are more appropriate, as they are easier to understand by human beings.</li><li>For conputational purposes (e.g., compilation of a program) the machine model, i.e., NPDA, is more appropriate.</li></ul></li></ul><h5 id="6-8-Deterministic-Pushdown-Automata-DPDA"><a href="#6-8-Deterministic-Pushdown-Automata-DPDA" class="headerlink" title="6.8 Deterministic Pushdown Automata (DPDA)"></a>6.8 Deterministic Pushdown Automata (DPDA)</h5><p>A <em>deterministic pushdown accepter</em> (DPDA) never has more than one choice in its moves.</p><ul><li>For every $q\in Q, a\in \Sigma \cup {\lambda}$ and $b\in \Gamma$:<ul><li>$\delta (q, a, b)$ contains at most one element;</li><li>If $\delta(q, \lambda, b)$ is not empty, then $\delta(q, c, b)$ must be empty for every input symbol $c\in \Sigma$.<ul><li>when a $\lambda$-move is possible for some configuration, no input-consuming alternative is available.</li></ul></li></ul></li><li>Unlike the case for finite automata, a $\lambda$-transition does not necessarily mean the automaton is nondeterministic:<ul><li>Since the top of the stack plays a role in determining the next move, the presence of $\lambda$-transitions does not automatically imply nondeterminism.</li></ul></li><li>Also, some transitions of a DPDA may be to the empty set, that is, undefined, so there may be dead configurations.</li><li>This does not affect the definition either:<ul><li>The only criterion for determinism is that, at all times, <em>at most</em> one possible move exists.</li></ul></li></ul><h5 id="6-9-Deterministic-Context-Free-Languages-DCFLs"><a href="#6-9-Deterministic-Context-Free-Languages-DCFLs" class="headerlink" title="6.9 Deterministic Context-Free Languages (DCFLs)"></a>6.9 Deterministic Context-Free Languages (DCFLs)</h5><ul><li><p>A context-free language $L$ is <em>deterministic</em> if there is a DPDA $M$ such that:<br>$$<br>L = L(M)<br>$$</p></li><li><p>There are, however, languages which are context-free, but not DCFL.</p><ul><li>This shows that, <em><strong>deterministic and nondeterministic pushdown automata are not equivalent.</strong></em></li></ul></li></ul><h5 id="6-10-Importance-of-DCFLs"><a href="#6-10-Importance-of-DCFLs" class="headerlink" title="6.10 Importance of DCFLs"></a>6.10 Importance of DCFLs</h5><ul><li>The importance of deterministic context-free languages lies in the fact that they can be <em><strong>parsed efficiently</strong></em>.</li><li>Think of the pushdown automaton as a parsing device:<ul><li>Since there is no backtracking involved, we can easily write a computer program for it, and we may expect that it will work efficiently.</li><li>Since there may be $\lambda$-transitions involved, we cannot immediately claim that this will yield a linear-time parser, but it puts us on the right track, nevertheless.</li></ul></li></ul><h4 id="7-Turing-Machines"><a href="#7-Turing-Machines" class="headerlink" title="7. Turing Machines"></a>7. Turing Machines</h4><h5 id="7-1-The-Standard-Turing-Machine"><a href="#7-1-The-Standard-Turing-Machine" class="headerlink" title="7.1 The Standard Turing Machine"></a>7.1 The Standard Turing Machine</h5><ul><li>A standard Turing machine has unlimited storage in the form of a tape:<ul><li>The tape consists of an infinite number of cells,</li><li>with each cell capable of storing one symbol.</li></ul></li><li>The read-write head can travel in <em><strong>both</strong></em> directions on the tape, processing one symbol per move.</li><li>In a standard Turing machine, the tape acts as the:<ul><li>input,</li><li>output,</li><li>and storage medium.</li></ul></li><li>A control function causes the machine to change states and possibly overwrite the tape contents:<ul><li>Deterministic and non-deterministic Turing machines turn out to be as powerful as each other.</li></ul></li><li>The input string is surrounded by blanks, so the input alphabet is considered a proper subset of the tape alphabet.</li></ul><h5 id="7-2-Definition-of-a-Turing-Machine"><a href="#7-2-Definition-of-a-Turing-Machine" class="headerlink" title="7.2 Definition of a Turing Machine"></a>7.2 Definition of a Turing Machine</h5><ul><li><strong><u>Definition 9.1</u></strong>: A <em>Turing Machine</em> $M = (Q, \Sigma, \Gamma, \delta, q_0, \Box, F)$ is defined by:<ul><li>$Q$: a finite set of internal states</li><li>$\Sigma$: the input alphabet</li><li>$\Gamma$: the tape alphabet</li><li>$\delta$: $Q\times \Gamma\rightarrow Q\times \Gamma \times {L, R}$: the transition function</li><li>$\Box \in \Gamma$: a special symbol called the blank</li><li>$q_0 \in Q$: the initial state</li><li>$F \subseteq Q$: the set of final states</li></ul></li><li>In the definition of a Turing machine, we assume that: $\Sigma \subseteq \Gamma - {\Box}$.</li><li>In other words, the input alphabet is a subset of the tape alphabet, and the blank symbol is not in the input alphabet.</li><li>Transition Function $\delta$<ul><li>$\delta: Q\times \Gamma \rightarrow Q \times \Gamma \times {L, R}$</li><li>Input to the transition function $\delta$ consists of:<ul><li>the current state of the control unit</li><li>and the current tape symbol</li></ul></li><li>Output of $\delta$ consists of:<ul><li>a new state,</li><li>a new tape symbol,</li><li>and location of the next symbol to be read (left or right)</li></ul></li><li>In general, $\delta$ is a partial function, so that some (state, symbol) input combinations may be undefined.</li></ul></li></ul><h5 id="7-3-Transition-Graphs-for-Turing-Machines"><a href="#7-3-Transition-Graphs-for-Turing-Machines" class="headerlink" title="7.3 Transition Graphs for Turing Machines"></a>7.3 Transition Graphs for Turing Machines</h5><ul><li>Label the edges of the graph with three items:<ul><li>the current tape symbol,</li><li>the symbol that replaces it,</li><li>and the direction in which the read-write head is to move.</li></ul></li></ul><h5 id="7-4-A-Turing-machine-that-Never-Halts"><a href="#7-4-A-Turing-machine-that-Never-Halts" class="headerlink" title="7.4 A Turing machine that Never Halts"></a>7.4 A Turing machine that Never Halts</h5><ul><li>It is possible for a Turing machine to never halt on certain inputs.</li><li>The machine runs forever with the read-write head moving alternately right and left but making no modifications to the tape.</li><li>In fact, it should be clear that this particular machine will run forever, <em>regardless of the initial information on its tape</em>, with the read-write head moving alternately right then left but making no modifications to the tape.</li><li>In the analogy with programming terminology, we say that the Turing machine is in an <em><strong>infinite loop</strong></em>.</li></ul><h5 id="7-5-Instantaneous-Description"><a href="#7-5-Instantaneous-Description" class="headerlink" title="7.5 Instantaneous Description"></a>7.5 Instantaneous Description</h5><ul><li><p>The most convenient way to exhibit a sequence of configurations of a Turing machine uses the idea of an <em>instantaneous description</em>.</p></li><li><p>Any configuration is completely determined by:</p><ul><li>the current state of the control unit,</li><li>the contents of the tape,</li><li>and the position of the read-write head.</li></ul></li><li><p>Use the notation in which $x_1qx_2$ or $a_1a_2\cdots a_{k-1}qa_ka_{k+1}\cdots a_n$ is the instantaneous description of a machine in state $q$ with the tape depicted in the figure below.</p><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-05-06 at 5.25.49 PM.png" style="zoom:50%;"></li><li><p>This convention is chosen so that the position of the read-write head is over the cell containing the symbol immediately following $q$.</p></li><li><p>The instantaneous description gives only a finite amount of information to the right and left of the read-write head.</p></li><li><p>The unspecified part of the tape is assumed to contain all blanks.</p></li><li><p>Normally, such blanks are irrelevant and are not shown explicitly in the instantaneous description.</p></li><li><p>If the position of blanks is relevant to the discussion, however, the blank symbol may appear in the instantaneous description.</p></li></ul><h5 id="7-6-The-Language-Accepted-by-a-Turing-Machine"><a href="#7-6-The-Language-Accepted-by-a-Turing-Machine" class="headerlink" title="7.6 The Language Accepted by a Turing Machine"></a>7.6 The Language Accepted by a Turing Machine</h5><ul><li><p><strong><u>Definition 9.3</u></strong>: Let $M = (Q, \Sigma, \Gamma, \delta, q_0, \Box, F)$ be a Turing machine. Then the language accepted by $M$ is:<br>$$<br>L(M) = {w\in \Sigma^+\mid q_0w\vdash^* x_1q_fx_2,\ for\ some\ q_f\in F, x_1, x_2\in \Gamma^*}<br>$$</p></li><li><p>The language accepted by a Turing machine is the set of all strings which cause the machine to halt in a final state, when started in its standard initial configuration.</p></li><li><p>A string is rejected if</p><ul><li>The machine halts in a nonfinal state, or</li><li><em><strong>The machine never halts</strong></em></li></ul></li><li><p>$M$ is said to halt starting from some initial configuration $x_1q_ix_2$ if<br>$$<br>x_1q_ix_2\vdash^* y_1q_jay_2<br>$$<br>for any $q_j$ and $a$, for which $\delta(q_j, a)$ is undefined.</p></li><li><p>Turing machines are more powerful than the previous classes of automata that we have studied (i.e., FAs, and PDAs).</p></li></ul><h5 id="7-7-Turing-Machines-as-Transducers"><a href="#7-7-Turing-Machines-as-Transducers" class="headerlink" title="7.7 Turing Machines as Transducers"></a>7.7 Turing Machines as Transducers</h5><ul><li><p>Turing machines provide an abstract model for digital computers, acting as a transducer that transforms input into output.</p></li><li><p>A <em>Turing machine transducer</em> implements a function that treats the original contents of the tape as its input and the final contents of the tape as its output.</p></li><li><p>A function is <em>Turing-computable</em> if it can be carried out by a Turing machine capable of processing all values in the function domain.</p></li><li><p><strong><u>Definition 9.4</u></strong>: A function $f$ with domain $D$ is said to be Turing-computable if there exists some Turing machine $M = (Q, \Sigma, \Gamma, \delta, q_0, \Box, F)$ such that, for all $w \in D$:<br>$$<br>q_0w\vdash^*q_ff(w)<br>$$<br>for some final state $q_f\in F$, <em><strong>and for any input $w\notin D$, the machine $M$ does not halt in a final state.</strong></em></p></li><li><p>Turing machines are the most powerful model of computation as transducers as well.</p></li><li><p>In fact, all the common mathematical functions are Turing-computable, e.g.:</p><ul><li>Arithmetic operators, Exponentiation, Integer logarithm;</li><li>Comparison;</li><li>String manipulation;</li><li>Etc.</li></ul></li></ul><h5 id="7-8-Combining-Turing-Machines"><a href="#7-8-Combining-Turing-Machines" class="headerlink" title="7.8 Combining Turing Machines"></a>7.8 Combining Turing Machines</h5><ul><li>By combining Turing Machines that perform simple tasks, complex algorithms can be implemented.</li></ul><h5 id="7-9-Universal-Turing-Machines"><a href="#7-9-Universal-Turing-Machines" class="headerlink" title="7.9 Universal Turing Machines"></a>7.9 Universal Turing Machines</h5><ul><li>The TMs we have studied so far have been special-purpose computers capable of executing a single algorithm.</li><li>We can consider a â€œuniversalâ€ Turing machine, which can execute a program stored in its memory:<ul><li>It receives an input string that specifies both:<ul><li>the algorithm it is to execute</li><li>and the input that is to be provided to the algorithm</li></ul></li></ul></li></ul><h5 id="7-10-The-Church-Turing-Thesis"><a href="#7-10-The-Church-Turing-Thesis" class="headerlink" title="7.10 The Church-Turing Thesis"></a>7.10 The Church-Turing Thesis</h5><ul><li>To say that the TM is a general model of computation implies that:<ul><li><em>â€œany algorithmic procedure that can be carried out at all, by a human computer or a team of humans or an electronic computer, can be carried out by a TMâ€</em>.</li></ul></li><li>An acceptance of the Church-Turing Thesis leads to a <em><strong>definition of an algorithm</strong></em>:<ul><li>An <em>algorithm</em> for a function $f: D\rightarrow R$ is a Turing machine $M$, which given any $d\in D$ on its tape, eventually halts with the correct answer $f(d)\in R$ on its tape.</li></ul></li><li>The nature of the model makes it seems that a TM can execute any algorithm a human can.</li><li>Apparent enhancements to the TM have been shown not to increase its power.</li><li>Other models of computation proposed have either been less powerful or equivalent to Turing machines.</li><li>No one has ever suggested any kind of <em><strong>effective</strong></em> computation that cannot be implemented on a TM</li><li>From now on, we will consider that, by definition, <em><strong>an â€œalgorithmic procedureâ€ is what a Turing machine can do</strong></em>.</li></ul><h5 id="7-11-The-Chomsky-Hierarchy"><a href="#7-11-The-Chomsky-Hierarchy" class="headerlink" title="7.11 The Chomsky Hierarchy"></a>7.11 The Chomsky Hierarchy</h5><ul><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-05-14 at 12.41.00 PM.png" style="zoom:50%;"></li><li><img src="/2021/05/15/Formal-Languages/Screen Shot 2021-05-14 at 12.41.10 PM.png" style="zoom:50%;"></li></ul><h4 id="8-Easy-wrong-topic"><a href="#8-Easy-wrong-topic" class="headerlink" title="8. Easy wrong topic"></a>8. Easy wrong topic</h4><ul><li><p>Is every formal language regular? No. $L = {a^nb^n : n \ge 0}$ is not regular.</p></li><li><p>$L = \emptyset$ is regular language.</p></li><li><p>$G = (V, T, S, P)$, $S \rightarrow aSb \mid S$, $L(G)$ is regular, because the production cannot halt, the language is empty.</p></li><li><p>Every finite language is regular. Therefore, every non-regular language is infinite.</p></li><li><p>Context Free contains regular languages, regular languages contain finite language</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Language and Computation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pattern Matching</title>
      <link href="2021/04/15/Pattern-Matching/"/>
      <url>2021/04/15/Pattern-Matching/</url>
      
        <content type="html"><![CDATA[<h4 id="1-What-is-pattern-matching"><a href="#1-What-is-pattern-matching" class="headerlink" title="1. What is pattern matching?"></a>1. What is pattern matching?</h4><ul><li>Given:<ul><li>A text string of length $n$</li><li>A pattern string of length $m\lt n$</li></ul></li><li>Determine:<ul><li>Whether the pattern is a <em><strong>substring</strong></em> of the text;</li><li>Find all indices at which the pattern begins.</li></ul></li></ul><h4 id="2-Brute-force-algorithm"><a href="#2-Brute-force-algorithm" class="headerlink" title="2. Brute-force algorithm"></a>2. Brute-force algorithm</h4><ul><li>Compare the pattern $P$ with the text $T$ for each possible shift of $P$ relative to $T$, until either<ul><li>A match is found, or</li><li>All placements of the pattern have been tried.</li></ul></li><li>Brute-force pattern matching runs in time $O(nm)$ in worst case.</li></ul><h4 id="3-Boyer-Moore-algorithm"><a href="#3-Boyer-Moore-algorithm" class="headerlink" title="3. Boyer-Moore algorithm"></a>3. Boyer-Moore algorithm</h4><ul><li><p>Boyer-Moore heuristics</p><ul><li><em><strong>Looking-glass heuristic</strong></em>: Compare $P$ with a subsequence of $T$ from  <em><strong>right to left</strong></em>.</li><li><em><strong>Character-jump heuristic</strong></em>: When a mismatch occurs at $T[i] = c$<ul><li>If $P$ contains $c$, shift $P$ to align the <em><strong>last (right-most)</strong></em> occurrence of $c$ in $P$ with $T[i]$</li><li>Else, shift $P$ to align $P[0]$ with $T[i+1]$</li></ul></li></ul></li><li><p>Last-occurrence function</p><ul><li>Objective: speed up the search by <em><strong>look-up table</strong></em>.</li><li>BM algorithm <em><strong>preprocesses the pattern $P$</strong></em> and the alphabet $S$ to build the last-occurrence function $L$ mapping $S$ to integers, where $L(c)$ is defined as<ul><li>The largest index $i$ such that $P[i] = c$ or</li><li>$-1$ if no such index exists.</li></ul></li></ul></li><li><p>The Boyer-Moore algorithm</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Algorithm BoyerMooreMatch(T, P, Alphabet)    L = lastOccurenceFunction(P, Alphabet)    i = m - 1    j = m - 1    repeat        if T[i] == P[j] // matching            if j == 0                return i // match at i            else                i = i - 1                j = j - 1        else // character-jump            l = L[T[i]]            i = i + m - min(j, 1 + l)            j = m - 1 //rightmost    until i > n - 1    return -1 // no match<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>Analysis</p><ul><li>Boyer-Mooreâ€™s algorithm runs in time $O(nm)$ in worst case</li><li>The worst case may occur in images and DNA sequences but unlikely in English text.</li><li>Boyer-Mooreâ€™s algorithm is <em><strong>significantly faster</strong></em> than the brute-force algorithm on English text.</li></ul></li><li><p>Key innovations of BM algorithm</p><ul><li><em><strong>Pre-indexing mismatched Text characters in Pattern.</strong></em></li></ul></li></ul><h4 id="4-KMP-algorithm"><a href="#4-KMP-algorithm" class="headerlink" title="4. KMP algorithm"></a>4. KMP algorithm</h4><ul><li><p>Key idea of KMP algorithm: precompute <em><strong>self-overlaps</strong></em> between portion of the pattern, so when a mismatch occurs, we know the maximum amount to shift the pattern.</p></li><li><p>Failure function</p><ul><li><p>Indicate the shift of the pattern upon a failed comparison.</p><ul><li>$f(k)$: the length of <em><strong>the longest prefix</strong></em> of the pattern that is a suffix of the substring pattern$[1,2,\cdots,k]$. pattern$[0]$ is excluded as we shift at least one character.</li><li>Mismatch at pattern$[k+1]$, $f(k)$ tells how many preceding characters can be reused to restart the pattern.</li></ul></li><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Algorithm failureFunction(P)    F[0] = 0    i = 1    j = 0    while i < m        if P[i] == P[j]            F[i] = j + 1            i = i + 1            j = j + 1        else if j > 0 then            j = F[j-1]        else            F[i] = 0 //no match            i = i + 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>Time complexity</p><ul><li>$O(|P|+|T|)$.</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hash Table</title>
      <link href="2021/04/11/Hash-Table/"/>
      <url>2021/04/11/Hash-Table/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Definition"><a href="#1-Definition" class="headerlink" title="1. Definition"></a>1. Definition</h4><ul><li><strong>Hash tables</strong> are a concrete data structure which is suitable for implementing maps.</li><li>Basic idea: convert each key into an index.</li><li>Look-up of keys, insertion and deletion in a hash table usually runs in $O(1)$ time.</li></ul><h4 id="2-Hash-Tables-and-Hash-Functions"><a href="#2-Hash-Tables-and-Hash-Functions" class="headerlink" title="2. Hash Tables and Hash Functions"></a>2. Hash Tables and Hash Functions</h4><ul><li>A <strong>hash table</strong> for a given key type consists of<ul><li>Array $A$ (called table) of size $N$</li><li>Hash function $h$</li></ul></li><li>A <strong>hash function</strong> $h$ maps keys of a given type to integers in a fixed interval $[0, N-1]$</li><li>When implementing a map with a hash table, the goal is to store item $(k, o)$ at index $i = h(k)$ in the array $A$</li></ul><h4 id="3-Hash-Functions"><a href="#3-Hash-Functions" class="headerlink" title="3. Hash Functions"></a>3. Hash Functions</h4><ul><li>A hash function is usually specified as the <em>composition</em> of two function:<ul><li><strong>Hash code</strong>: $h_1: keys \rightarrow integers$</li><li><strong>Compression function</strong>: $h_2: integers \rightarrow [0, N - 1]$</li></ul></li><li>The hash code is applied first, and the compression function is applied next on the result, i.e., $h(x) = h_2(h_1(x))$</li><li>The goal of the hash function is to <strong>â€œdisperseâ€</strong> the keys in an apparently <strong>random</strong> way</li></ul><h4 id="4-Collision-Handling"><a href="#4-Collision-Handling" class="headerlink" title="4. Collision Handling"></a>4. Collision Handling</h4><ul><li>Collisions occur when different elements are mapped to the same cell.</li><li><strong>Separate Chaining</strong>: let each cell in the table point to a list of entries  that map there<ul><li>Separate chaining is simple, but requires additional mempry outside the table</li></ul></li><li><strong>Linear Probing</strong><ul><li><strong>Open addressing</strong>: the colliding item is placed in a different cell of the table</li><li><strong>Linear probing</strong>: handles collisions by placing the colliding item in the next (circularly) available table cell</li><li>Accessing a cell of the array is referred to as a â€œprobeâ€</li><li>Disadvantage: Colliding items lump together, causing future collisions to cause a longer sequence of probes</li></ul></li><li>Updates with Linear Probing<ul><li>To handle insertions and deletions, we introduce a special object, called <em><strong>DEFUNCT</strong></em>, which replaces deleted elements</li></ul></li></ul><h4 id="5-Double-Hashing"><a href="#5-Double-Hashing" class="headerlink" title="5. Double Hashing"></a>5. Double Hashing</h4><ul><li><p>Double hashing uses a secondary hash function $d(k)$ and handles collisions by placing an item in the first available cell of the series<br>$$<br>(h(k) + jd(k))\mod N<br>$$<br>for $j = 0, 1, \cdots, N-1$</p></li><li><p>The secondary hash function $d(k)$ cannot have zero values</p></li><li><p>Linear probing is a special case where $d(k) = 1$</p></li><li><p>The table size $N$ must be a <em>prime</em> to allow probing of all the cells</p></li><li><p>Common choice of compression function for the secondary hash function:<br>$$<br>d(k) = q - (k\mod q)<br>$$<br>where</p><ul><li>$q &lt; N$</li><li>$q$ is a <em>prime</em></li></ul></li><li><p>The possible values for $d(k)$ are $1, 2, \cdots, q$</p></li></ul><h4 id="6-Performance-of-Hashing"><a href="#6-Performance-of-Hashing" class="headerlink" title="6. Performance of Hashing"></a>6. Performance of Hashing</h4><ul><li>In the worst case, searches, insertions and removals on a hash table take $O(n)$ time</li><li>The worst case occurs when all the keys inserted into the map collide</li><li>The load factor $\alpha = n/N$ affects the performance of a hash table</li><li>The expected running time of all the map ADT operations in a hash table is $O(1)$</li></ul><h4 id="7-Summary"><a href="#7-Summary" class="headerlink" title="7. Summary"></a>7. Summary</h4><ul><li><p>Let $n$ denote the number of entries in the map, and we assume that the bucket array supporting the hash table is maintained such that its capacity is proportional to the number of entries in the map.</p></li><li><style type="text/css">.tg  {border-collapse:collapse;border-spacing:0;}.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;  overflow:hidden;padding:10px 5px;word-break:normal;}.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}.tg .tg-7btt{border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}</style><table class="tg"><thead align="center">  <tr>    <th class="tg-7btt" rowspan="2">Method</th>    <th class="tg-7btt" rowspan="2">Unsorted<br>List</th>    <th class="tg-7btt" colspan="2">Hash Table</th>  </tr>  <tr>    <td class="tg-c3ow">expected</td>    <td class="tg-c3ow">worst case</td>  </tr></thead><tbody align="center">  <tr>    <td class="tg-c3ow">get</td>    <td class="tg-c3ow">O(n)</td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(1)</span></td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(n)</span></td>  </tr>  <tr>    <td class="tg-c3ow">put</td>    <td class="tg-c3ow">O(n)</td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(1)</span></td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(n)</span></td>  </tr>  <tr>    <td class="tg-c3ow">remove</td>    <td class="tg-c3ow">O(n)</td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(1)</span></td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(n)</span></td>  </tr>  <tr>    <td class="tg-c3ow">size, isEmpty</td>    <td class="tg-c3ow">O(1)</td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(1)</span></td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(1)</span></td>  </tr>  <tr>    <td class="tg-c3ow">entrySet, keySet, values</td>    <td class="tg-c3ow">O(n)</td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(n)</span></td>    <td class="tg-c3ow"><span style="font-weight:normal;font-style:normal;text-decoration:none">O(n)</span></td>  </tr></tbody></table></li><li><p>Why disperse?</p><ul><li>To reduce numbers of collisions</li></ul></li><li><p>Why random?</p><ul><li>Random means no pattern</li><li>If there is an obvious pattern, then the incoming data may have a matching pattern that leads to many collisions.</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph</title>
      <link href="2021/04/10/Graph/"/>
      <url>2021/04/10/Graph/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Definition-Graph"><a href="#1-Definition-Graph" class="headerlink" title="1. Definition: Graph"></a>1. Definition: Graph</h4><ul><li>$G$ is an ordered triple $G = (V, E, f)$<ul><li>$V$ is a set of nodes, points, or vertices.</li><li>$E$ is a set, whose elements are known as edges or lines.</li><li>$f$ is a function maps each element of $E$ to an unordered pair of vertices in $V$</li></ul></li></ul><h4 id="2-Definition-vertex-amp-edge"><a href="#2-Definition-vertex-amp-edge" class="headerlink" title="2. Definition: vertex &amp; edge"></a>2. Definition: vertex &amp; edge</h4><ul><li><p>Vertex</p><ul><li>Basic element</li><li>Drawn as a <em><strong>node</strong></em> or a dot</li><li>Vertex set of $G$ is usually denoted by $V(G)$, or $V$</li></ul></li><li><p>Edge</p><ul><li>A set of two elements</li><li>Drawn as a <em><strong>line</strong></em> connecting two vertices, called end vertices, or endpoints</li><li>The <em><strong>edge</strong></em> set of $G$ is usually denoted by $E(G)$, or $E$</li></ul></li></ul><h4 id="3-Simple-graphs"><a href="#3-Simple-graphs" class="headerlink" title="3. Simple graphs"></a>3. Simple graphs</h4><ul><li><em>Simple graphs</em> are graphs without <em><strong>multiple edges</strong></em> or <em><strong>self-loops</strong></em>.</li></ul><h4 id="4-Directed-and-undirected-graphs"><a href="#4-Directed-and-undirected-graphs" class="headerlink" title="4. Directed and undirected graphs"></a>4. Directed and undirected graphs</h4><ul><li>Graphs can be<ul><li>Undirected (edges donâ€™t have direction),</li><li>Directed (edges have direction).</li></ul></li><li>Undirected graphs can be represented as directed graphs where for each edge $(X, Y)$ there is a corresponding edge $(Y, X)$</li><li>Directed edge $(A, B)$.</li><li>Undirected edge ${A, B}$.</li></ul><h4 id="5-Weighted-and-unweighted-graphs"><a href="#5-Weighted-and-unweighted-graphs" class="headerlink" title="5. Weighted and unweighted graphs"></a>5. Weighted and unweighted graphs</h4><ul><li>Graphs can also be<ul><li>unweighted</li><li>weighted (edges have weights)</li></ul></li></ul><h4 id="6-Adjacency-path-amp-reachability"><a href="#6-Adjacency-path-amp-reachability" class="headerlink" title="6. Adjacency, path &amp; reachability"></a>6. Adjacency, path &amp; reachability</h4><ul><li>$A\longrightarrow B \longrightarrow C \longrightarrow D$</li><li>Node $B$ is <em><strong>adjacent</strong></em> to $A$ is there is an edge from $A$ to $B$.</li><li>A <em><strong>path</strong></em> from $A$ to $D$: a sequence of vertices, such that there is an edge from $A$ to $B$, $B$ to $C$, $\cdots$, from $C$ to $D$.</li><li>Vertex $B$ is <em><strong>reachable</strong></em> from $A$ is there is a path from $A$ to $B$.</li></ul><h4 id="7-Cycle-acyclic-amp-connected"><a href="#7-Cycle-acyclic-amp-connected" class="headerlink" title="7. Cycle, acyclic &amp; connected"></a>7. Cycle, acyclic &amp; connected</h4><ul><li><em><strong>Cycle</strong></em>: A path from a vertex to itself.</li><li>Graph is <em><strong>acyclic</strong></em> if it does not have cycles.</li><li>Graph is <em><strong>connected</strong></em> if there is a path between every pair of vertices.</li><li>Graph is <em><strong>strongly connected</strong></em> if there is a path in <em><strong>both directions</strong></em> between every pair of vertices</li></ul><h4 id="8-Degree"><a href="#8-Degree" class="headerlink" title="8. Degree"></a>8. Degree</h4><ul><li>Number of edges incident on a node.</li></ul><h4 id="9-Degree-directed-graphs"><a href="#9-Degree-directed-graphs" class="headerlink" title="9. Degree (directed graphs)"></a>9. Degree (directed graphs)</h4><ul><li>In-degree: Number of edges entering,</li><li>Out-degree: Number of edges leaving,</li><li>Degree = indeg + outdeg.</li></ul><h4 id="10-Degree-simple-facts"><a href="#10-Degree-simple-facts" class="headerlink" title="10. Degree: simple facts"></a>10. Degree: simple facts</h4><ul><li>If $G$ is a graph with $m$ edges, $\Sigma deg(v) = 2m = 2|E|$</li><li>If $G$ is a digraph, $\Sigma indeg(v) = \Sigma outdeg(v) = |E|$</li><li>The number of <em><strong>odd-degree nodes</strong></em> is even</li><li>Let $G$ be a simple graph with $n$ vertices and $m$ edges<ul><li>If $G$ is undirected, $m\le n(n-1)/2, C_n^{2}$</li><li>If $G$ is directed, $m\le n(n-1)$</li></ul></li><li>Let $G$ be an undirected graph with $n$ vertices and $m$ edges<ul><li>If $G$ is connected, $m\ge n-1$</li><li>If $G$ is a tree, $m = n-1$</li></ul></li></ul><h4 id="11-Data-structures-for-graphs"><a href="#11-Data-structures-for-graphs" class="headerlink" title="11. Data structures for graphs"></a>11. Data structures for graphs</h4><ul><li><p>Static implementation: adjacency matrix</p><ul><li><p>Store node in the array: each node is associated with an integer (array index).</p></li><li><p>Represent information about the edges using a two-dimensional array, where<br>$$<br>array[i][j] = 1<br>$$<br>iff there is an edge from node with index $i$ to the node with index $j$.</p></li><li><p>Disadvantages of adjacency matrices</p><ul><li><em><strong>Sparse graohs</strong></em><ul><li>Very few edges for a large number of vertices.</li><li>Result in many zero entries in adjacency matrix.</li><li>Waste space and makes many algorithms less efficient.</li></ul></li><li>Matrix representation is <em><strong>inflexible</strong></em>, if the number of nodes in the graph may change, (especially if we donâ€™t know the maximal size of the graph).</li></ul></li></ul></li><li><p>Adjacency list</p><ul><li>For every vertex, keep a list of adjacent vertices.</li><li>Keep a list of vertices, or keep vertices in a Map as keys and lists of adjacent vertices as values.</li></ul></li><li><p>Edge list</p><ul><li>Represent the graph as a list of edges.</li></ul></li></ul><h4 id="12-Graph-traversals"><a href="#12-Graph-traversals" class="headerlink" title="12. Graph traversals"></a>12. Graph traversals</h4><ul><li><p>Graph traversal: visit all vertices and edges in a graph in a systematic way.</p><ul><li>Breadth-first search.</li><li>Depth-first search.</li></ul></li><li><p>What is it used for?</p><ul><li>Search for a certain <em><strong>node</strong></em> in a graph.</li><li>Search for a certain <em><strong>edge</strong></em> in a graph.</li><li>Search for a <em><strong>path</strong></em> between two nodes.</li><li>Check if a graph is <em><strong>connected</strong></em>.</li><li>Check if a graph contains <em><strong>loops</strong></em>.</li></ul></li><li><p>Breadth-first search</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">BFS starting from vertex v,Create a queue Q,Mark v as visited and put v into Q,While Q is non-empty,  Remove the head u of Q,  Mark and enqueue all (unvisited) neighbours of u.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>The BFS order is that those closet to the start point $A$ occur earliest.</p></li><li><p>The BFS search tends to â€œgo broad (wide, flat)â€.</p></li></ul></li><li><p>Depth-first search</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">DFS starting from vertex v.Create a stack S.Mark v as visited and push v onto S.While S is non-empty,    Peek at the top u of S,    If u has an (unvisited) neighbour w,        mark w and push it onto S,    else        pop S.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>The DFS search tends to â€œgo deepâ€.</p></li></ul></li><li><p>Detect cycles in a directed graph</p></li><li><ul><li><p>Idea: If we encounter a vertex which is already on the <em>stack</em>, we find a loop</p><ul><li>Stack contains vertices on a path, and if we see the same vertex again, the path must contain a cycle.</li></ul></li><li><p>Instead of visited and unvisited, use three colors:</p><ul><li>White = unvisited</li><li>Grey = on the stack</li><li>Black = finished</li></ul></li><li><p>Modified DFS for cycle detection</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Modified DFS starting from v.All vertices coloured white.Create a stack S.Colour v grey and push v onto S.While S is non-empty    peek at the top u of S    if u has a grey neighbour,        a cycle is detected,    else if u has a white neighbour w,        colour w grey and push it onto S,    else        colour u black and pop S.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li></ul></li><li><p>$firstUnmarkedAdj()$</p><ul><li><p>Adjacency list implementation.</p></li><li><p>Assume that we have a method which returns the first unmarked vertex adjacent to a given one:</p><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">GraphNode firstUnmarkedAdj(GraphNode v)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>Implementation</p><ul><li>Keep <em><strong>a pointer into the adjacency list</strong></em> of each vertex<ul><li>Do not start to traverse the list of adjacent vertices from the beginning each time.</li></ul></li><li>Or use the same iterator for this list, so when we call $next()$ it returns the next element in the list.<ul><li>Again does not start from the beginning.</li></ul></li></ul></li></ul></li><li><p>Pseudocode for breadth-first search</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Starting from vertex ss.marked = true; // marked is a field in GraphNodeQueue Q = new Queue(); //FIFOQ.enqueue(s); // add s into queuewhile (!Q.isempty()) {    v = Q.dequeue(); //remove the first element    u = firstUnmarkedAdj(v);    while (u != null) {        u.marked = true;        Q.enqueue(u);        u = firstUnmarkedAdj(v);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Complexity of BFS</p><ul><li>Assume an adjacency list representation, $|V|$ is the number of vertices, $|E|$ is the number of edges.<ul><li><em><strong>Each vertex</strong></em> is enqueued and dequeued at most once.</li><li>Scanning for all <em><strong>adjacent vertices</strong></em> takes $O(|E|)$ time, since sum of lengths of adjacency lists is $|E|$.</li><li>Gice a $O(|V|+|E|)$ time complexity.</li></ul></li></ul></li></ul></li><li><p>Pseudocode for DFS</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">s.marked = true;Stack S = new Stack(); //FILOS.push(s); //push s into stackwhile (!S.isempty()) {    v = S.peek(); //topest element in stack    u = firstUnmarkedAdj(v);    if (u == null) {        S.pop(); //no element, remove    }else {        u.marked = true;        S.push(u); //push u into stack    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Complexity of DFS</p><ul><li><em><strong>Each vertex</strong></em> is pushed on the stack and popped at most once.</li><li>For every vertec we check what the next unvisited neighbour is.</li><li>In our implementation, we traverse the <em><strong>adjacency list</strong></em> only once. This gives $O(|V| + |E|)$ again.</li></ul></li></ul></li><li><p>BFS vs. DFS</p><ul><li><table><thead><tr><th align="center"></th><th align="center">BFS</th><th align="center">DFS</th></tr></thead><tbody><tr><td align="center">Implementation</td><td align="center">Queue, size $</td><td align="center">V</td></tr><tr><td align="center">Space complexity</td><td align="center">$O(</td><td align="center">V</td></tr><tr><td align="center">Time complexity</td><td align="center">$O(</td><td align="center">V</td></tr><tr><td align="center">Application</td><td align="center">Shortest path</td><td align="center">Cycle detection</td></tr></tbody></table></li></ul></li></ul><h4 id="13-Dijkstraâ€™s-algorithm"><a href="#13-Dijkstraâ€™s-algorithm" class="headerlink" title="13. Dijkstraâ€™s algorithm"></a>13. Dijkstraâ€™s algorithm</h4><ul><li><p>An algorithm for solving the single-source shortest path problem.</p><ul><li><em><strong>Greedy</strong></em> algorithm</li><li>Compute <em><strong>distances</strong></em> from a source vertex to all others</li></ul></li><li><p>Assumptions:</p><ul><li>The graph is <em><strong>connected</strong></em>.</li><li>The edges are <em><strong>undirected</strong></em>.</li><li>The edge weights are <em><strong>nonnegative</strong></em>.</li></ul></li><li><p>Grow a â€œcloudâ€ of vertices, beginning with $s$.</p></li><li><p>Store $d(v)$ representing the distance of $v$ from $s$.</p></li><li><p>At each step</p><ul><li>Add to the cloud the vertex $u$ outside the cloud with the <em>shortest distance</em> $d(u)$.</li><li><em>Update</em> the distances of the vertices <em>adjacent to $u$</em>.</li></ul></li><li><p>Edge relaxation</p><ul><li><p>Consider an edge $e = (u, z)$ such that</p><ul><li>$u$ is the vertex most recently added to the cloud</li><li>$z$ is not in the cloud</li></ul></li><li><p>The relaxation of edge $e$ updates distance $d(z)$ as follows:</p><p>$d(z)\leftarrow \min{d(z), d(u) + weight(e)}$</p></li></ul></li><li><p>Implementation</p><p>To find the shortest paths from the start vertex $s$:</p><ul><li>Priority queue PQ: vertices to be processed.</li><li>An array: Shortest distances from $s$ to every vertex.<ul><li>Initially set to be infinity for all but $s$, and $0$ for $s$.</li></ul></li><li>Order the queue by its distance. (shortest in front).</li><li>Loop while there are vertices in the queue PQ:<ul><li>Dequeue a vertex $u$.</li><li>Update the distances by Edge Relaxation.</li><li>Re-order the queue.</li></ul></li></ul></li><li><p>Modified Dijkstraâ€™s algorithm</p><ul><li><p>To make Dijkstraâ€™s algorithm to <strong>return the path itself</strong>, not just the distance:</p><ul><li><p>In addition to distances, <em><strong>maintain a path</strong></em> (list of vertices) for every vertex.</p></li><li><p>In the beginning, paths are empty.</p></li><li><p>When assigning $dist(s, v) = dist(s, u) + weight(u, v)$ also assign $path(v) = path(u)$.</p></li><li><p>When dequeuing a vertex, add in to its path.</p></li></ul></li></ul></li><li><p>Complexity</p><ul><li><p>Assume that the priority queue is implemented as a heap.</p></li><li><p>At each step (dequeuing a vertex $u$ and recomputing distances) we do $O(|E_u|\times \log (|V|))$ work, where $E_u$ is the set of edges with source $u$. (Up-heap, find the min).</p></li><li><p>We do this for every vertex, so total complexity is $O((|V|+|E|)\times \log(|V|))$.</p></li><li><p>Really similar to BFS and DFS, but instead of choosing some successor, we <em><strong>reorder</strong></em> a priority queue at each step, hence the $\log(|V|)$ factor.</p></li><li><p>Adaptable priority queue using unsorted sequence</p><ul><li>Complexity: $O(|V|^2+|E|)$</li></ul></li><li><p>Fibonacci heap</p><ul><li>Complexity: $O(|V|\times \log(|V|) + |E|)$.</li></ul></li></ul></li></ul><h4 id="14-Directed-acyclic-graphs-æœ‰å‘æ— ç¯å›¾"><a href="#14-Directed-acyclic-graphs-æœ‰å‘æ— ç¯å›¾" class="headerlink" title="14. Directed acyclic graphs (æœ‰å‘æ— ç¯å›¾)"></a>14. Directed acyclic graphs (æœ‰å‘æ— ç¯å›¾)</h4><ul><li>Informal definition: directed graph without directed cycles.</li></ul><h4 id="15-Topological-ordering"><a href="#15-Topological-ordering" class="headerlink" title="15. Topological ordering"></a>15. Topological ordering</h4><ul><li>Definition: A topological ordering of graph $G$ is an ordering of its $n$ vertices such that for every edge $(v_i, v_j)$ of $G$, it is the case that $i\lt j$.<ul><li>Any directed path in $G$ traverses vertices in increasing order.</li><li>May be more than $1$ ordering.</li></ul></li><li>$G$ has a topological ordering iff it is acyclic.</li></ul><h4 id="16-Topological-sort"><a href="#16-Topological-sort" class="headerlink" title="16. Topological sort"></a>16. Topological sort</h4><ul><li><p>Objective: sort vertices in order so that every edge folloes such an order.</p></li><li><p>Input: directed acyclic graph.</p></li><li><p>Output: a <em><strong>linear sequence of vertices</strong></em> such that for any two vertices $u$ and $v$, if there is an edge from $u$ to $v$, then $u$ is before $v$ in the sequence.</p></li><li><p>Algorithm</p><ul><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Create an empty array to store the ordering.While the graph is not emoty, repeat:    Find a vertex with no incoming edges.    Put this vertex in the array.    Delete the vertex from the graph.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Note that this destructively updates a graph</p><ul><li>Make a copy of the graph first and do topological sort on the copy.</li></ul></li></ul></li></ul><h4 id="17-Cycle-detection-with-topological-sort"><a href="#17-Cycle-detection-with-topological-sort" class="headerlink" title="17. Cycle detection with topological sort"></a>17. Cycle detection with topological sort</h4><ul><li>What happens if we run topological sort on a <em><strong>cyclic</strong></em> graph?</li><li>There will be either no vertex with $0$ prerequisites to begin with, or at some point in the iteration.</li><li>If we run a topological sort on a graph and there are vertices left undeleted, the graph contains a cycle.</li><li>Why does topological sort work?<ul><li>A vertex cannot be removed before all its prerequisites have been removed. (No incomming edges)</li><li>It cannot be inserted in the array before its prerequisite. (So the array is arranged in topological order).</li><li>Cycle detection: in a cycle, a vertex is its own prerequisite. So it can never be removed.</li></ul></li></ul><h4 id="18-Minimal-spanning-tree"><a href="#18-Minimal-spanning-tree" class="headerlink" title="18. Minimal spanning tree"></a>18. Minimal spanning tree</h4><ul><li><p>Input: <em><strong>connected, undirected, weighted</strong></em> graph</p></li><li><p>Output: a tree which connects all vertices in the graph using only the edges present in the graph and is minimal in the sense that <em><strong>the sum of weights of the edges is the smallest</strong></em> possible.</p></li><li><p><em><strong>Spanning tree</strong></em>: a tree contains all vertices of a connected graph.</p></li><li><p><em><strong>Minimal spanning tree</strong></em>: The spanning tree with the smallest total weight.</p></li><li><p>Primâ€™s algorithm</p><ul><li><p>A <em><strong>greedy</strong></em> algorithm to construct an MST:</p></li><li><pre class="line-numbers language-pseudocode"><code class="language-pseudocode">Pick any vertex M.Choose the shortest edge from M to any other vertex N.Add edge (M, N) to the MST.Continue to add at every step the shortest edge from a vertex in MST to a vertex outside, until all vertices are in MST.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li></ul><h4 id="19-Euler-path"><a href="#19-Euler-path" class="headerlink" title="19. Euler path"></a>19. Euler path</h4><ul><li>A path that uses every <strong>edge</strong> of a graph exactly once.<ul><li>Start and end at <strong>different</strong> vertices.</li></ul></li><li>The Criterion for Euler Paths<ul><li>The two endpoints of $P$ must be <strong>odd</strong> vertices.</li><li>All vertices other than the two endpoints of $P$ must be <strong>even</strong> vertices.</li></ul></li><li>Explanation Using Degree of Graph<ul><li>A graph has Eular paths iff it has two <strong>odd-degree</strong> nodes, and all other nodes are <strong>even-degree</strong> nodes.</li></ul></li></ul><h4 id="20-Euler-Circuit"><a href="#20-Euler-Circuit" class="headerlink" title="20. Euler Circuit"></a>20. Euler Circuit</h4><ul><li>An Euler circuit is a <strong>circuit</strong> that uses every edge of a graph exactly once.</li><li>An Euler circuit starts and ends at the <strong>same</strong> vertex.</li><li>Explanation Using Degree of Graph<ul><li>A connected graph has Euler circuits iff all nodes are <strong>even-degree</strong> node.</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Binary Search Tree</title>
      <link href="2021/03/11/Binary-Search-Tree/"/>
      <url>2021/03/11/Binary-Search-Tree/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Ordered-Maps"><a href="#1-Ordered-Maps" class="headerlink" title="1. Ordered Maps"></a>1. Ordered Maps</h4><ul><li>Keys are assumed to come from a total order</li><li>Items are stored in order by their keys</li><li>This allows us to support <strong>nearest neighbor queries</strong>:<ul><li>Item with largest key less than or equal to $k$</li><li>Item with smallest key greater than or equal to $k$</li></ul></li></ul><h4 id="2-Sorted-Search-Tables"><a href="#2-Sorted-Search-Tables" class="headerlink" title="2. Sorted Search Tables"></a>2. Sorted Search Tables</h4><ul><li><p>Store the mapâ€™s entries in an array list $A$ so that they are in increasing order of their keys.</p></li><li><p>We refer to this implementation as a <em><strong>sorted search table</strong></em>.</p></li><li><p>A search table is an ordered map implemented by means of a sorted sequence</p><ul><li>We store the items in an array-based sequence, sorted by key</li><li>We use an external comparator for the keys</li></ul></li><li><p>Performance:</p><ul><li>Searches take $O(\log n)$ time, using binary search</li><li>Inserting a new item takes $O(n)$ time, since in the worst case we have to shift $n$ items to make room for the new item</li><li>Removing an item takes $O(n)$ time, since in the worst case we have to shift $n$ items to compact the items after the removal</li></ul></li><li><p>The lookup table is efficient only for ordered maps of small size or for maps on which searches are the most common operations, while insertions and removals are rarely performed</p></li><li><p>Performance of a sorted map (implemented using a sorted search table)</p><ul><li><table><thead><tr><th align="center">Method</th><th align="center">Running Time</th></tr></thead><tbody><tr><td align="center">size</td><td align="center">$O(1)$</td></tr><tr><td align="center">get</td><td align="center">$O(\log n)$</td></tr><tr><td align="center">put</td><td align="center">$O(n)$; $O(\log n)$ if map has entry<br>with given key</td></tr><tr><td align="center">remove</td><td align="center">$O(n)$</td></tr><tr><td align="center">firstEntry, lastEntry</td><td align="center">$O(1)$</td></tr><tr><td align="center">ceilingEntry, floorEntry<br>lowerEntry, higherEntry</td><td align="center">$O(\log n)$</td></tr><tr><td align="center">subMap</td><td align="center">$O(s+\log n)$ where $s$ items are<br>reported</td></tr><tr><td align="center">entrySet, keySet, values</td><td align="center">$O(n)$</td></tr></tbody></table></li></ul></li><li><p>Motivation</p><ul><li>Binary search on ordered arrays is efficient: $O(\log_2 n)$</li><li>However insertion or removal os an item in an ordered array is slow: $O(n)$</li><li>Ordered arrays are best suited for static searching, where search space does not change</li><li>Binary search trees can be used for efficient dynamic searching</li></ul></li></ul><h4 id="3-Binary-Search-Trees"><a href="#3-Binary-Search-Trees" class="headerlink" title="3. Binary Search Trees"></a>3. Binary Search Trees</h4><ul><li>A binary search tree is a <em>proper</em> binary tree storing keys (or key-value entries) at its <em>internal nodes</em> and satisfying the following properties:<ul><li>Let $u, v$, and $w$ be three nodes such that $u$ is in the left <em>subtree</em> of $v$ and $w$ is in the right <em>subtree</em> of $v$. We have $key(u)\le key(v)\le key(w)$</li><li>Assuming there are no duplicate keys, we have $key(u)\lt key(v)\lt key(w)$</li></ul></li><li>External nodes do not store items<ul><li>and likely are not actually implemented, but are just null links from the parent</li></ul></li><li>Search<ul><li>To search for a key $k$, we trace a downward path starting at the root</li><li>The next node visited depends on the comparison of $k$ with the key of the current node</li><li>If we reach a leaf, the key is not found</li></ul></li><li>Insertion<ul><li>Have to insert $k$ where a $get(k)$ would find it</li><li>So natural that $put(k, o)$ starts with $get(k)$</li><li>Search for key $k$ (using TreeSearch)</li><li>Assume $k$ is already in the tree then just replace the value</li><li>Otherwise, let $w$ be the leaf reached by the search, we insert $k$ at node $w$ and expand $w$ into an internal node</li></ul></li><li>Deletion<ul><li>To perform operation $remove(k)$, we search for $k$</li><li>Assume key $k$ is in the tree, and let $v$ be the node storing $k$</li><li>If node $v$ has a leaf child $w$, we remove $v$ and $w$ from the tree with operation $removeExternal(w)$, which removes $w$ and its parent</li><li>We consider the case where the key $k$ to be removed is stored at a node $v$ whose children are both internal<ul><li>we find the internal node $w$ that follows $v$ in an <strong>inorder traversal</strong></li><li>we copy $key(w)$ into node $v$</li><li>we remove node $w$ and its left child $z$ (which must be a leaf) by means of operation $removeExternal(z)$</li></ul></li></ul></li><li>Performance<ul><li>Consider an ordered map with $n$ items implemented by means of a binary search tree of height $h$<ul><li>the space used is $O(n)$</li><li>methods <em>get</em>, <em>put</em> and <em>remove</em> take $O(h)$ time</li></ul></li><li>The height $h$ is $n$ in the worst case and $\log n$ in the best case</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Heap</title>
      <link href="2020/11/22/Heap/"/>
      <url>2020/11/22/Heap/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Definition"><a href="#1-Definition" class="headerlink" title="1. Definition"></a>1. Definition</h4><ul><li>A heap is a binary tree storing keys at its nodes and satisfying the following properties:<ul><li><strong>Heap-Order</strong>: for every internal node $v$ other than the root, $key(v) \ge key(parent(v))$</li><li><strong>Complete Binary Tree</strong>: let $h$ be the height of the heap<ul><li>levels $i = 0, \cdots, h-1$ have the maximal number of nodes, i.e. there are $2^i$ nodes at depth $i$.</li><li>The remaining nodes at level/depth $h$ reside in the leftmost possible positions at that level/depth.</li></ul></li><li>The <strong>last node</strong> of a heap is the rightmost node of maximum depth</li></ul></li></ul><h4 id="2-Insertion-into-a-Heap"><a href="#2-Insertion-into-a-Heap" class="headerlink" title="2. Insertion into a Heap"></a>2. Insertion into a Heap</h4><ul><li><p>Method insertItem of the priority queue ADT corresponds to the insertion of a key $k$ to the heap</p></li><li><p>The insertion algorithm consists os three steps</p><ul><li>Find the insertion node $z$ (the new last node)</li><li>Store $k$ at $z$</li><li>Restore the heap-order property</li></ul></li><li><p><strong>Upheap</strong></p><ul><li><p>After the insertion of a new key $k$, the heap-order property may be violated</p></li><li><p>Algorithm up heap restores the heap-order property by swapping $k$ along an upward path from the insertion node</p></li><li><p>Upheap terminates when the key $k$ reaches the root or a node whose parent has a key smaller than or equal to $k$</p></li><li><p>Since a heap has height $O(\log n)$, up heap runs in $O(\log n)$ time</p></li></ul></li></ul><h4 id="3-Removal-from-a-Heap"><a href="#3-Removal-from-a-Heap" class="headerlink" title="3. Removal from a Heap"></a>3. Removal from a Heap</h4><ul><li>Method removeMin of the priority queue ADT corresponds to the removal of the root key from the heap</li><li>The removal algorithm consists of three steps<ul><li>Replace the root key with the key of the last node $w$</li><li>Remove $w$</li><li>Restore the heap-order property</li></ul></li><li><strong>Downheap</strong><ul><li>After replacing the root key with the key $k$ of the last node, the heap-order property may be violated</li><li>Algorithm downheap restores the heap-order property by swapping key $k$ along a downward path from the root (always swap with the smallest child)</li><li>Downheap terminates when key $k$ reaches a leaf or a node whose children have keys greater than or equal to $k$</li><li>Since a heap has height $O(\log n)$, downheap runs in $O(\log n)$ time</li></ul></li></ul><h4 id="4-Array-besed-Heap-Implementation"><a href="#4-Array-besed-Heap-Implementation" class="headerlink" title="4. Array-besed Heap Implementation"></a>4. Array-besed Heap Implementation</h4><ul><li>We can represent a heap with $n$ keys by means of a vector or ArrayList of length $n+1$</li><li>The cell of at index $0$ is not used</li><li>Links between nodes are not explicitly stored</li><li>For the node at index $i$<ul><li>the left child is at index $2i$</li><li>the right child is at index $2i+1$</li></ul></li><li>Operation insert corresponds to inserting at index $n+1$</li><li>Operation removeMin corresponds to moving index $n$ to index $1$</li></ul><h4 id="5-Implementing-Priority-Queue-with-a-Heap"><a href="#5-Implementing-Priority-Queue-with-a-Heap" class="headerlink" title="5. Implementing Priority Queue with a Heap"></a>5. Implementing Priority Queue with a Heap</h4><ul><li>To create a priority queue, initialise a heap</li><li>To insert in the priority queue, insert in the heap</li><li>To get the value with the minimal key, ask for the value of the root of the heap</li><li>To dequeue the highest priority item, remove the root and return the value stored there.</li></ul><h4 id="6-Heap-Sort"><a href="#6-Heap-Sort" class="headerlink" title="6. Heap-Sort"></a>6. Heap-Sort</h4><ul><li>Using a heap-based priority queue, we can sort a sequence of $n$ elements in $O(n\log n)$ time</li><li>The resulting algorithm is called heap-sort</li><li>Heap-sort is much faster than quadratic sorting algorithms, such as insertion-sort and selection-sort</li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memory Management</title>
      <link href="2020/11/10/Memory-Management/"/>
      <url>2020/11/10/Memory-Management/</url>
      
        <content type="html"><![CDATA[<h4 id="1-å†…å­˜å±‚æ¬¡-Memory-Hierarchies"><a href="#1-å†…å­˜å±‚æ¬¡-Memory-Hierarchies" class="headerlink" title="1. å†…å­˜å±‚æ¬¡(Memory Hierarchies)"></a>1. å†…å­˜å±‚æ¬¡(Memory Hierarchies)</h4><ol><li>Computers typically have memory hierarchies: <ul><li>Registers, L1/L2/L3 cache (volatile)</li><li>Main memory (volatile)</li><li>Disks (nonvolatile)</li><li><img src="/2020/11/10/Memory-Management/Memory%20Hierarchies.png?lastModify=1630990878" alt="img"></li></ul></li><li><strong>Higher memory</strong> is faster, more expensive and volatile, <strong>lower memory</strong> is slower, cheaper and non-volatile.</li><li>Memory can be seen as one <strong>linear array</strong> of bytes/words.<ul><li><img src="/2020/11/10/Memory-Management/Memory%20Structure.png?lastModify=1630990878" alt="img"></li></ul></li><li><strong>OS responsibilities:</strong><ul><li><strong>Allocate/Deallocate</strong> memory when requested by processes, <strong>keep track of</strong> <strong>used/unused</strong> memory.</li><li><strong>Transparently</strong> move data from <strong>memory</strong> to <strong>disk</strong> and vice versa.</li><li><strong>Distribute memory</strong> between processes and simulate an <strong>â€œinfinitely largeâ€</strong> memory space.</li><li><strong>Control access</strong> when multiprogramming is applied.</li></ul></li></ol><h4 id="2-æ“ä½œç³»ç»Ÿçš„å†…å­˜ç®¡ç†æ–¹å¼"><a href="#2-æ“ä½œç³»ç»Ÿçš„å†…å­˜ç®¡ç†æ–¹å¼" class="headerlink" title="2. æ“ä½œç³»ç»Ÿçš„å†…å­˜ç®¡ç†æ–¹å¼"></a>2. æ“ä½œç³»ç»Ÿçš„å†…å­˜ç®¡ç†æ–¹å¼</h4><ol><li>æ“ä½œç³»ç»Ÿä¸­é‡‡ç”¨çš„å†…å­˜ç®¡ç†æ–¹å¼<ul><li>é‡å®šä½(relocation)</li><li>åˆ†æ®µ(segmentation)</li><li>åˆ†é¡µ(paging)</li><li>è™šæ‹Ÿå­˜å‚¨(virtual memory)</li></ul></li><li>å®ç°é«˜åº¦ä¾èµ–ç¡¬ä»¶<ul><li>ä¸è®¡ç®—æœºå­˜å‚¨æ¶æ„ç´§è€¦åˆ</li><li>MMU(å†…å­˜ç®¡ç†å•å…ƒ): å¤„ç†CPUå­˜å‚¨è®¿é—®è¯·æ±‚çš„ç¡¬ä»¶</li></ul></li></ol><h4 id="3-åœ°å€ç©ºé—´å’Œåœ°å€ç”Ÿæˆ"><a href="#3-åœ°å€ç©ºé—´å’Œåœ°å€ç”Ÿæˆ" class="headerlink" title="3. åœ°å€ç©ºé—´å’Œåœ°å€ç”Ÿæˆ"></a>3. åœ°å€ç©ºé—´å’Œåœ°å€ç”Ÿæˆ</h4><ol><li>åœ°å€ç©ºé—´å®šä¹‰:<ul><li>ç‰©ç†åœ°å€ç©ºé—´â€”â€”ç¡¬ä»¶æ”¯æŒçš„åœ°å€ç©ºé—´<ul><li>èµ·å§‹åœ°å€ä¸º0ï¼Œç›´åˆ°MAXsys</li></ul></li><li>é€»è¾‘åœ°å€ç©ºé—´â€”â€”åœ¨CPUè¿è¡Œçš„è¿›ç¨‹çœ‹åˆ°çš„åœ°å€<ul><li>èµ·å§‹åœ°å€ä¸º0ï¼Œç›´åˆ°MAXprog</li></ul></li></ul></li><li>é€»è¾‘åœ°å€ç”Ÿæˆ<ul><li><img src="/2020/11/10/Memory-Management/Screen%20Shot%202020-12-09%20at%203.54.27%20PM.png?lastModify=1630990878" alt="img"></li></ul></li><li>åœ°å€ç”Ÿæˆæ—¶æœºå’Œé™åˆ¶<ul><li>ç¼–è¯‘æ—¶<ul><li>å‡è®¾èµ·å§‹åœ°å€å·²çŸ¥</li><li>å¦‚æœèµ·å§‹åœ°å€æ”¹å˜ï¼Œå¿…é¡»é‡æ–°ç¼–è¯‘</li></ul></li><li>åŠ è½½æ—¶<ul><li>å¦‚ç¼–è¯‘æ—¶èµ·å§‹ä½ç½®æœªçŸ¥ï¼Œç¼–è¯‘å™¨éœ€ç”Ÿæˆå¯é‡å®šä½çš„ä»£ç (relocatable code)</li><li>åŠ è½½æ—¶ï¼Œç”Ÿæˆç»å¯¹åœ°å€</li></ul></li><li>æ‰§è¡Œæ—¶<ul><li>æ‰§è¡Œæ—¶ä»£ç å¯ç§»åŠ¨</li><li>éœ€åœ°å€è½¬æ¢(æ˜ å°„)ç¡¬ä»¶æ”¯æŒ</li></ul></li></ul></li><li>åœ°å€ç”Ÿæˆè¿‡ç¨‹<ul><li>CPU<ul><li>ALU: éœ€è¦é€»è¾‘åœ°å€çš„å†…å­˜å†…å®¹</li><li>MMU: è¿›è¡Œé€»è¾‘åœ°å€å’Œç‰©ç†åœ°å€çš„è½¬æ¢</li><li>CPUæ§åˆ¶é€»è¾‘: ç»™æ€»çº¿å‘é€ç‰©ç†åœ°å€è¯·æ±‚</li></ul></li><li>å†…å­˜<ul><li>å‘é€ç‰©ç†åœ°å€çš„å†…å®¹ç»™CPU</li><li>æˆ–æ¥æ”¶CPUæ•°æ®åˆ°ç‰©ç†åœ°å€</li></ul></li><li>æ“ä½œç³»ç»Ÿ<ul><li>å»ºç«‹é€»è¾‘åœ°å€LAå’Œç‰©ç†åœ°å€PAçš„æ˜ å°„</li></ul></li></ul></li><li>åœ°å€æ£€æŸ¥<ul><li><img src="/2020/11/10/Memory-Management/Screen%20Shot%202020-12-09%20at%204.34.03%20PM.png?lastModify=1630990878" alt="img"></li></ul></li></ol><h4 id="4-Contiguous-Memory-è¿ç»­å†…å­˜"><a href="#4-Contiguous-Memory-è¿ç»­å†…å­˜" class="headerlink" title="4. Contiguous Memory (è¿ç»­å†…å­˜)"></a>4. Contiguous Memory (è¿ç»­å†…å­˜)</h4><ol><li><p>Mono-programming(å•é“ç¨‹åº)</p><ul><li>Only <strong>one single user process</strong> is in memory/executed at any point in time (no multi-programming)</li><li>A fixed region of memory is allocated to the <strong>OS/kernel</strong>, the remaining memory is reserved for a <strong>single process</strong> (MS-DOS worked this way) </li><li>This process has <strong>direct access</strong> to <strong>physical memory</strong> (i.e. no address translation takes place) </li><li>Every process is allocated <strong>contiguous block of memory</strong>, i.e. it contains no â€œholesâ€ or â€œgapsâ€ (â‡” <strong>non-contiguous allocation</strong>)</li><li><strong>One process</strong> is allocated the <strong>entire memory space</strong>, and the process is <strong>always located in the same address space</strong></li><li><strong>No protection</strong> between different user processes required (one process)</li><li><strong>Overlays</strong> enable the programmer to use more memory than available (burden on programmer)</li><li><strong>Shortcomings</strong> of Mono-programming:<ul><li>Since a process has <strong>direct access to the physical memory</strong>, it may have <strong>access to OS</strong> memory</li><li>The operating system can be seen as a process - so we have <strong>two processes</strong> anyway</li><li><strong>Low</strong> <strong>utilisation</strong> of hardware resources (CPU, I/O devices, etc.)</li><li>Mono-programming is unacceptable as <strong>multiprogramming is expected</strong> on modern machines</li></ul></li><li>Direct memory access and mono-programming is common in basic <strong>embedded systems</strong> and <strong>modern consumer electronics</strong>, e.g. washing machines, microwaves, etc.</li></ul></li><li><p>Multi-programming(å¤šé“ç¨‹åº): <strong>A Probabilistic Model</strong>(æ¦‚ç‡æ¨¡å‹)</p><ul><li>There are <strong>n independent processes in memory</strong></li><li>A process spends <strong>p percent</strong> of its time <strong>waiting for I/O</strong></li><li><strong>CPU</strong> <strong>Utilisation</strong> is calculated as 1 minus the time that <strong>all processes are waiting for I/O:</strong> e.g., p = 0.9 then CPU utilisation = 1 - 0.9 â‡’ 0.1 =&gt; (1âˆ’p)</li><li>The <strong>probability</strong> that all n processes are waiting for I/O (i.e., the CPU is idle) is pn , i.e. p Ã—p Ã—p . . . </li><li>The <strong>CPU</strong> <strong>utilisation</strong> is given by 1âˆ’pn</li><li>CPU <strong>utilisation goes up</strong> with <strong>the number of processes</strong> and down for <strong>increasing levels of I/O ratio</strong></li><li>Muiti-programming does able to improve resource utilisation</li></ul></li><li><p>Fixed partitions (å›ºå®šåˆ†åŒº)</p><ul><li><p>Divide memory into <strong>static, contiguous and equal sized partitions</strong> that have a <strong>fixed size</strong> and <strong>fixed location</strong> (é™æ€å¤§å°ç›¸ç­‰åˆ†åŒº)</p><ul><li>Any process can take up <strong>any</strong> (large enough) <strong>partition</strong></li><li>Allocation of <strong>fixed equal sized partitions</strong> to processes is <strong>trivial</strong></li><li>Very <strong>little overhead</strong> and <strong>simple implementation</strong></li><li>The operating system keeps a track of which partitions are being <strong>used</strong> and which are <strong>free</strong></li></ul></li><li><p><strong>Disadvantages</strong> of static equal-sized partitions</p><ul><li><strong>Low memory utilisation</strong> and <strong>internal fragmentation</strong>: partition may be unnecessarily large</li><li><strong>Overlays</strong> must be used if a program does not fit into a partition (burden on programmer)</li></ul></li><li><p>Divide memory into <strong>static</strong> and <strong>non-equal sized partitions</strong> that have a <strong>fixed size</strong> and <strong>fixed location</strong> (é™æ€å¤§å°ä¸ç­‰åˆ†åŒº)</p><ul><li><strong>Reduces internal fragmentation</strong></li><li>The <strong>allocation</strong> of processes to partitions must be <strong>carefully considered</strong></li></ul></li><li><p>Allocation Methods</p><ol><li><strong>One private queue per partition</strong></li></ol><ul><li>Assigns each process to the <strong>smallest partition</strong> that it would fit in</li><li><strong>Reduces internal fragmentation</strong></li><li>Can <strong>reduce memory utilisation</strong> (e.g., lots of small jobs result in unused large partitions) and result in <strong>starvation</strong></li></ul><ol><li><strong>A single shared queue</strong> for all partitions can allocate small processes to <strong>large partitions</strong> but results in <strong>increased internal fragmentation</strong></li></ol></li><li><p><strong>Cons</strong> of fixed partitioning</p><ul><li>Limits the number of <strong>active processes (overlays)</strong></li><li>Small job not <strong>utilize partition space efficiently</strong> (internal fragmentation)</li><li>Processesâ€™ memory requirement need to be <strong>known beforehand</strong>.</li></ul></li></ul></li><li><p>Dynamic partitioning (åŠ¨æ€åˆ†åŒº)</p><ul><li><strong>Fixed partitioning</strong> results in <strong>internal fragmentation</strong>:<ul><li>An <strong>exact match</strong> between the requirements of the process and the available partitions <strong>may not exist</strong></li><li>The partition <strong>may not be used entirely</strong></li></ul></li><li>Dynamic partitioning<ul><li>A <strong>variable number of partitions</strong> of which the <strong>size</strong> and <strong>starting address</strong> <strong>can change</strong> over time</li><li>A process is allocated the <strong>exact amount of contiguous memory</strong> it requires, thereby <strong>preventing internal fragmentation</strong></li></ul></li></ul></li></ol><ul><li>Swapping<ul><li><strong>Swapping</strong> holds some of the <strong>processes on the hard disk</strong> and <strong>shuttles processes</strong> between the hard disk and main memory as necessary</li></ul></li><li><strong>Reasons</strong> for swapping:<ul><li>Some <strong>processes</strong> only <strong>run occasionally</strong></li><li>We have <strong>more processes</strong> than <strong>partitions</strong> (assuming fixed partitions)</li><li>A processâ€™s <strong>memory requirements</strong> have <strong>changed</strong>, e.g. increased</li><li>The <strong>total amount of memory that is required</strong> for the processes <strong>exceeds the available memory</strong></li></ul></li><li>Allocation structure: Bitmaps<ul><li>The simplest data structure to <strong>keep track of free memory</strong> is a form of <strong>bitmap</strong></li><li><strong>Memory</strong> is <strong>split into blocks</strong> of say 4 kilobyte size<ul><li>A bit map is set up so that <strong>each bit</strong> is <strong>0</strong> if the <strong>memory block is free</strong> and <strong>1</strong> if the <strong>memory block is used</strong>, e.g.<ul><li>32MB memory = 32 * 220 bytes / 4K blocks =&gt; 8192 bitmap entries</li><li>8192 bits occupy 8192 / 8 = 1K bytes of storage</li></ul></li><li>The size of this bitmap will depend on the <strong>size of the memory</strong> and the <strong>size of the allocation unit</strong></li></ul></li><li>A <strong>trade-off exists</strong> between the <strong>size of the bitmap</strong> and the <strong>size of blocks</strong><ul><li>The <strong>size of bitmaps</strong> can become prohibitive for small blocks and may <strong>make searching</strong> the bitmap <strong>slower</strong></li><li>Larger blocks may increase <strong>internal fragmentation</strong></li></ul></li><li><strong>Bitmaps</strong> are <strong>rarely used</strong> for this reason</li></ul></li><li>Allocation structure: Linked List<ul><li>A more <strong>sophisticated data structure</strong> is required to deal with <strong>a variable number</strong> of <strong>free and used partitions</strong></li><li><strong>A linked list</strong> is one such possible data structure<ul><li>A linked list consists of a <strong>number of entries</strong> (â€œlinksâ€)</li><li>Each link <strong>contains data items</strong>, e.g. <strong>start of memory block</strong>, <strong>size</strong>, free/allocated <strong>flag</strong></li><li>Each link also contains a <strong>pointer to the next</strong> in the chain</li></ul></li><li><img src="/2020/11/10/Memory-Management/Picture1.png?lastModify=1630990878" alt="img"></li></ul></li></ul><ol><li>The operating system is responsible for:<ul><li>Applying strategies to (quickly) <strong>allocate processes</strong> to available memory (â€œholesâ€)</li><li>Managing <strong>free space</strong></li></ul></li><li>Allocating Available Memory: Algorithms<ul><li><strong>First fit</strong> starts scanning <strong>from the start</strong> of the linked list until a link is found which represents <strong>free space of sufficient size</strong><ul><li>If requested space is <strong>the exact same size</strong> as the â€œholeâ€, all the space is allocated (i.e. no <strong>internal</strong> fragmentation)</li><li>Else, the free link is <strong>split into two</strong>:<ul><li>The first entry is set to the <strong>size requested</strong> and marked <strong>â€œusedâ€</strong></li><li>The second entry is set to <strong>remaining size</strong> and marked <strong>â€œfreeâ€</strong></li></ul></li></ul></li><li>The <strong>next fit algorithm</strong> maintains a record of where it got to:<ul><li>It <strong>starts its search</strong> from <strong>where it stopped last time</strong></li><li>It gives an <strong>even chance to all memory to get allocated</strong> (first fit concentrates on the start of the list)</li><li>However, simulations have shown that next fit actually gives <strong>worse performance</strong> than first fit</li></ul></li><li>Best fit:<ul><li><strong>First fit</strong> just looks for the <strong>first available hole</strong><ul><li>It doesnâ€™t take into account that there may be <strong>a hole later</strong> in the list that <strong>exactly(-ish)</strong> fits the requested size</li><li>First fit <strong>may break up a big hole</strong> when the right size hole exists later on</li></ul></li><li><strong>Next fit</strong> doesnâ€™t improve that model</li><li>The <strong>best fit algorithm</strong> always <strong>searches the entire linked list</strong> to find the <strong>smallest hole big enough</strong> to satisfy the memory request<ul><li>It is <strong>slower</strong> than first fit</li><li>It also results in <strong>more wasted memory</strong> (memory is more likely to fill up with tiny-useless-holes, first fit generates larger holes on the average)</li></ul></li></ul></li><li>Worst fit:<ul><li><strong>Tiny holes</strong> are created when <strong>best fit</strong> splits an empty partition</li><li>The <strong>worst fit algorithm</strong> finds the <strong>largest available empty partition</strong> and splits it<ul><li>The <strong>left over part will still be large</strong> (and <strong>potentially more useful</strong>)</li><li>Simulations have also shown that worst fit is <strong>not very good either</strong></li></ul></li></ul></li><li>Summary:<ul><li><strong>First fit</strong>: allocate <strong>first block</strong> that is <strong>large enough</strong></li><li><strong>Next fit</strong>: allocate <strong>next block</strong> that is large enough, i.e. <strong>starting from the current location</strong></li><li><strong>Best fit</strong>: choose block that <strong>matches</strong> required size <strong>closet</strong> - O(N) complexity</li><li><strong>Worst fit</strong>: choose the <strong>larget possible block</strong> - O(N) complexity</li></ul></li><li>Quick fit and others:<ul><li><strong>Quick fit</strong> maintains <strong>lists of commonly used sizes</strong><ul><li>For example a separate list for each of 4K, 8K, 12K, 16K, etc. holes</li><li><strong>Odd sizes</strong> can either go into the <strong>nearest size</strong> or into a <strong>special separate list</strong></li></ul></li><li>It is <strong>much faster</strong> to find the required size holes using <strong>quick fit</strong> (table of entries, entries point to head of holes)</li><li>Similar to next fit, it has the problem of creating <strong>many tiny holes</strong></li><li>Finding neighbours for <strong>coalescing</strong> (combining empty partitions) becomes more difficult/time consuming</li></ul></li></ul></li><li>Managing Available Memory: Coalescing<ul><li><strong>Coalescing</strong> (joining together) takes place when two <strong>adjacent entries</strong> in the linked list <strong>become free</strong><ul><li>There may be three adjacent free entries if a used block in-between two free blocks is freed</li></ul></li><li>Both <strong>neighbours</strong> are examined when a <strong>block is freed</strong><ul><li>If either (or both) are <strong>also free</strong></li><li>Then the two (or three) <strong>entries are combined</strong> into one larger block by adding up the sizes<ul><li>The earlier block in the linked list gives the <strong>start point</strong></li><li>The <strong>separate links are deleted</strong> and a single link inserted</li></ul></li></ul></li></ul></li><li>Managing Available Memory: Compacting (ç´§å‡‘)<ul><li>Even with coalescing happening automatically, <strong>free blocks</strong> may still <strong>distributed across memory</strong><ul><li>=&gt; <strong>Compacting</strong> can be used to join free and used memory (but is <strong>time consuming</strong>)</li></ul></li><li><strong>Compacting is more difficult and time consuming</strong> to implement than coalescing (processes have to be moved)<ul><li>Each process is <strong>swapped out</strong> &amp; <strong>free space coalesced</strong></li><li>Process swapped back in at lowest available location</li></ul></li><li>é€šè¿‡ç§»åŠ¨åˆ†é…ç»™è¿›ç¨‹çš„å†…å­˜åˆ†åŒºï¼Œä»¥åˆå¹¶å¤–ç¢ç‰‡</li><li>ç¢ç‰‡ç´§å‡‘çš„æ¡ä»¶<ul><li>æ‰€æœ‰çš„åº”ç”¨ç¨‹åºå¯åŠ¨æ€é‡å®šä½</li></ul></li></ul></li><li>Difficulties of Dynamic Partitioning<ul><li>The exact <strong>memory requirements</strong> may <strong>not be known</strong> in advance (<strong>heap</strong> and <strong>stack</strong> grow dynamically)</li><li><strong>External fragmentation</strong><ul><li><strong>Swapping</strong> a process out of memory will create a <strong>â€œholeâ€</strong></li><li>A new process may not use the entire â€œholeâ€, leaving a small <strong>unused block</strong></li><li>A new process may be <strong>too large</strong> for a given â€œholeâ€</li></ul></li><li>The <strong>overhead</strong> of memory <strong>compaction</strong> to <strong>revocer holes</strong> can be <strong>prohibitive</strong> and requires <strong>dynamic relocation</strong><ul><li>Requires a lot of CPU time</li></ul></li></ul></li><li>Overview and Shortcomings<ul><li>Different contiguous memory allocation schemes have different advantages/disadvantages<ul><li><strong>Mono-programming</strong> is easy but does result in <strong>low resource utilisation</strong></li><li><strong>Fixed partitioning</strong> facilitates <strong>multi-programming</strong> but results in <strong>internal fragmentation</strong></li><li><strong>Dynamic partitioning</strong> facilitates <strong>multi-programming</strong>, reduces <strong>internal fragmentation</strong>, but results in <strong>external fragmentation</strong> (allocation methods, coalescing, and compacting help)</li></ul></li></ul></li></ol><h4 id="5-Code-relocation-and-protection"><a href="#5-Code-relocation-and-protection" class="headerlink" title="5. Code relocation and protection"></a>5. Code relocation and protection</h4><ol><li>Principles:</li></ol><ul><li><strong>Relocation</strong>: when a program is run, it <strong>does not know in advance</strong> which <strong>partition/address</strong> it will occupy<ul><li>The program cannot simply generate <strong>static address</strong> (e.g. jump instructions) that are <strong>absolute</strong></li><li>Addresses should be <strong>relative to where the program has been loaded</strong></li><li><strong>Relocation must be solved</strong> in an operating system that allows processes to run at <strong>changing memory locations (on the fly)</strong></li></ul></li><li><strong>Protection</strong>: once you can have two programs in memory at the same time, protection must be enforced</li></ul><ol><li>Address Types</li></ol><ul><li>A <strong>logical address</strong> is a memory address <strong>seen by the process</strong><ul><li>It is <strong>independent</strong> of the current <strong>physical memory</strong> assignment</li><li>It is, e.g., <strong>relative to the start of the program</strong></li></ul></li><li>A <strong>physical address</strong> refers to an <strong>actual location</strong> in <strong>main memory</strong></li><li>The <strong>logical address space</strong> must be mapped onto the machineâ€™s <strong>physical address space</strong></li></ul><ol><li>Approaches</li></ol><ul><li><strong>Static â€œrelocationâ€ at compile time:</strong> a process has to be located at the same location every single time (impractical)</li><li><strong>Dynamic relocation</strong> at <strong>load time</strong><ul><li>An <strong>offset</strong> is added to every logical address to <strong>account for its physical location</strong> in memory</li><li><strong>Slows down</strong> the loading of a process, does not account for <strong>swapping</strong></li></ul></li><li><strong>Dynamic relocation</strong> at <strong>runtime</strong><ul><li>æ¯ä¸ªCPUé…ç½®2ä¸ªç‰¹æ®Šçš„ç¡¬ä»¶å¯„å­˜å™¨ï¼Œå«ä½œ<strong>åŸºå€å¯„å­˜å™¨</strong>å’Œ<strong>ç•Œé™å¯„å­˜å™¨</strong>ï¼Œå½“ä¸€ä¸ªç¨‹åºè¿è¡Œæ—¶ï¼Œç¨‹åºçš„èµ·å§‹ç‰©ç†åœ°å€è£…è½½åˆ°<strong>åŸºå€å¯„å­˜å™¨</strong>ä¸­ï¼Œç¨‹åºçš„é•¿åº¦è£…è½½åˆ°<strong>ç•Œé™å¯„å­˜å™¨</strong>ä¸­ï¼Œæ¯æ¬¡ä¸€ä¸ªè¿›ç¨‹è®¿é—®å†…å­˜ï¼Œå–ä¸€æ¡æŒ‡ä»¤ï¼Œè¯»æˆ–å†™ä¸€ä¸ªæ•°æ®å­—ï¼ŒCPUç¡¬ä»¶ä¼šåœ¨æŠŠåœ°å€å‘é€åˆ°å†…å­˜æ€»çº¿ä¹‹å‰ï¼Œè‡ªåŠ¨æŠŠåŸºå€å€¼åŠ åˆ°è¿›ç¨‹å‘å‡ºçš„åœ°å€å€¼ä¸Šï¼ŒåŒæ—¶ï¼Œå®ƒæ£€æŸ¥ç¨‹åºæä¾›çš„åœ°å€æ˜¯å¦ç­‰äºæˆ–å¤§äºç•Œé™å¯„å­˜å™¨é‡Œçš„å€¼ï¼Œå¦‚æœåœ°å€è¶…å‡ºç•Œé™ï¼Œåˆ™äº§ç”Ÿé”™è¯¯å¹¶ä¸­æ­¢è®¿é—®</li><li>Two special purpose registers are maintained in the CPU (the <strong>MMU</strong>), containing a <strong>base address</strong> and <strong>limit</strong><ul><li>The <strong>base register</strong> stores the <strong>start address</strong> of the partition</li><li>The <strong>limit register</strong> holds the <strong>size</strong> of the partition (end of program)</li></ul></li><li><strong>At runtime:</strong><ul><li>The <strong>base register</strong> is added to the <strong>logical (relative) address</strong> to generate the <strong>physical address</strong></li><li>The resulting address is <strong>compared</strong> against the <strong>limit address</strong></li></ul></li><li>The Relocation also provides a measure of <strong>protection</strong>: each process image is <strong>isolated</strong> by the contents of the base and bounds registers and <strong>safe from unwanted accesses</strong> by other processes.</li><li>ç¼ºç‚¹ï¼š<ul><li>æ¯æ¬¡è®¿é—®å†…å­˜éƒ½éœ€è¦è¿›è¡ŒåŠ æ³•å’Œæ¯”è¾ƒè¿ç®—ï¼ŒåŠ æ³•ç”±äºè¿›ä½ä¼ é€’æ—¶é—´çš„é—®é¢˜ï¼Œåœ¨æ²¡æœ‰ä½¿ç”¨ç‰¹æ®Šç”µè·¯çš„æƒ…å†µä¸‹ä¼šæ˜¾å¾—å¾ˆæ…¢</li></ul></li></ul></li></ul><h4 id="6-Non-Contiguous-Memory-éè¿ç»­å†…å­˜"><a href="#6-Non-Contiguous-Memory-éè¿ç»­å†…å­˜" class="headerlink" title="6. Non-Contiguous Memory (éè¿ç»­å†…å­˜)"></a>6. Non-Contiguous Memory (éè¿ç»­å†…å­˜)</h4><ol><li>Paging (åˆ†é¡µ)</li></ol><ul><li>Principles<ul><li><strong>Paging</strong> uses the principles of <strong>fixed partitioning</strong> and <strong>code re-location</strong> to devise a new <strong>non-contiguous management scheme:</strong><ul><li>Memory is split into much <strong>smaller blocks</strong> and <strong>one or more blocks</strong> are allocated to a process<ul><li>e.g., a 11kb process would take up 3 blocks of 4kb</li></ul></li><li>These blocks <strong>do not have to be contiguous in main memory</strong>, but the process still <strong>perceives them to be contiguous</strong></li></ul></li><li>Benefits compared to contiguous schemes include:<ul><li><strong>Internal fragmentation</strong> is reduced to the <strong>last â€œblockâ€</strong> only</li><li>There is <strong>no external fragmentation</strong>, since physical blocks are <strong>stacked directly onto each other</strong> in main memory</li></ul></li></ul></li><li>Definitions<ul><li>A <strong>page</strong> is a small block of <strong>contiguous memory</strong> in the <strong>logical address space</strong>, i.e. as seen by the process</li><li>A <strong>page frame (é¡µæ¡†)</strong> is a <strong>small contiguous block</strong> in <strong>physical memory</strong></li><li>Pages and frames (usually) have the <strong>same size:</strong><ul><li>The size is usually a power of 2</li><li>Sizes range between 512 bytes and 1Gb</li></ul></li></ul></li><li>Relocation<ul><li><strong>Logical address</strong> (page number, offset within page) needs to be <strong>translated</strong> into a <strong>physical address</strong> (frame number, offset within frame)</li><li><strong>Multiple â€œbase registersâ€</strong> will be required:<ul><li>Each logical page needs <strong>a separate â€œbase registerâ€</strong> that specifies the start of the associated frame</li><li>i.e., a <strong>set of base registers</strong> has to be maintained for each process</li></ul></li><li>The base registers are stored in the <strong>page table</strong></li></ul></li><li>Relocation: Page Tables<ul><li>The page table can be seen as <strong>a function</strong>, that <strong>maps the page number</strong> of the logical address <strong>onto the frame number</strong> of the physical address<ul><li>frameNumber = f(pageNumber)</li></ul></li><li>The <strong>page number</strong> is used as <strong>index to the page table</strong> that lists the <strong>number of associated frame</strong>, i.e. it contains the location of the frame in memory</li><li>Every process has its <strong>own page table</strong> containing its own â€œbase registersâ€</li><li>The <strong>operating system</strong> maintains a <strong>list of free frames</strong></li></ul></li><li>Address Translation: Implementation<ul><li>A <strong>logical (physical) address</strong> is relative to the start of the <strong>program (memory)</strong> and consists of two parts:<ul><li>The <strong>right most</strong>  <strong>bits</strong> that represent the <strong>offset within the page (frame)</strong><ul><li>e.g. 12 bits fot the offset, allowing up to 4096 (212) bytes per page (frame)</li></ul></li><li>The <strong>left most</strong>  <strong>bits</strong> that represent the <strong>page (frame) number</strong><ul><li>e.g. 4 bits for the page number allowing 16 (24) pages (frames)</li></ul></li></ul></li><li>The <strong>offset</strong> within the page and frame <strong>remains the same</strong> (they are the same size)</li><li>The page number to frame number mapping is held in the <strong>page table</strong></li><li><img src="/2020/11/10/Memory-Management/Screen%20Shot%202020-12-23%20at%205.13.44%20PM.png?lastModify=1630990878" alt="img"></li></ul></li><li>Relocation: Address Translation<ul><li>Steps in <strong>address translation:</strong><ul><li>1  <strong>Extract the page number</strong> from the logical address</li><li>2  Use page number as an index to <strong>retrieve the frame number</strong> in the page table</li><li>3  <strong>Add the â€œlogical offset within the pageâ€</strong> to the start of the physical frame</li></ul></li><li><strong>Hardware implementation</strong> of address translation<ul><li>1  The CPUâ€™s <strong>memory management unit</strong> (MMU) intercepts logical address</li><li>2  MMU uses a page table as above</li><li>3  The resulting <strong>physical address</strong> is put on the <strong>memory bus</strong></li></ul></li></ul></li></ul><h4 id="7-Virtual-Memory-è™šæ‹Ÿå†…å­˜"><a href="#7-Virtual-Memory-è™šæ‹Ÿå†…å­˜" class="headerlink" title="7. Virtual Memory (è™šæ‹Ÿå†…å­˜)"></a>7. Virtual Memory (è™šæ‹Ÿå†…å­˜)</h4><ul><li>Principle of Locality (å±€éƒ¨æ€§åŸç†)<ul><li><strong>Principle of Locality:</strong> the program and data references within a process tend to <strong>cluster</strong><ul><li><strong>localities</strong> constitute <strong>groups of pages</strong> that are <strong>used together</strong>, e.g., related to a function (code, data, etc.)</li><li>Code execution and data manipulation are usually <strong>restricted to a small subset</strong> (i.e. limited number of pages) at any point in time</li><li>I.e. <strong>code</strong> and <strong>data references</strong> within a process are usually <strong>clustered</strong> =&gt; This is called the <strong>principle of locality</strong></li></ul></li><li>ç¨‹åºåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªè¾ƒçŸ­æ—¶æœŸï¼Œæ‰€æ‰§è¡Œçš„æŒ‡ä»¤åœ°å€å’ŒæŒ‡ä»¤çš„æ“ä½œæ•°åœ°å€ï¼Œåˆ†åˆ«å±€é™äºä¸€å®šåŒºåŸŸ<ul><li>æ—¶é—´å±€éƒ¨æ€§<ul><li>ä¸€æ¡æŒ‡ä»¤çš„ä¸€æ¬¡æ‰§è¡Œå’Œä¸‹æ¬¡æ‰§è¡Œï¼Œä¸€ä¸ªæ•°æ®çš„ä¸€æ¬¡è®¿é—®å’Œä¸‹æ¬¡è®¿é—®éƒ½é›†ä¸­åœ¨ä¸€ä¸ªè¾ƒçŸ­æ—¶æœŸå†…</li><li>å³ï¼šå¦‚æœç¨‹åºä¸­çš„æŸæ¡æŒ‡ä»¤ä¸€æ—¦æ‰§è¡Œï¼Œåˆ™ä¸ä¹…ä¹‹åè¯¥æŒ‡ä»¤å¯èƒ½å†æ¬¡è¢«æ‰§è¡Œï¼›å¦‚æœæŸæ•°æ®è¢«è®¿é—®ï¼Œåˆ™ä¸ä¹…ä¹‹åè¯¥æ•°æ®å¯èƒ½å†æ¬¡è¢«è®¿é—®ã€‚</li></ul></li><li>ç©ºé—´å±€éƒ¨æ€§<ul><li>å½“å‰æŒ‡ä»¤å’Œé‚»è¿‘çš„å‡ æ¡æŒ‡ä»¤ï¼Œå½“å‰è®¿é—®çš„æ•°æ®å’Œé‚»è¿‘çš„å‡ ä¸ªæ•°æ®éƒ½é›†ä¸­åœ¨ä¸€ä¸ªè¾ƒå°åŒºåŸŸå†…</li><li>å³ï¼šå¦‚æœæŸä¸ªä½ç½®çš„ä¿¡æ¯è¢«è®¿é—®ï¼Œé‚£å’Œå®ƒç›¸é‚»çš„ä¿¡æ¯ä¹Ÿå¾ˆæœ‰å¯èƒ½è¢«è®¿é—®åˆ°ã€‚</li></ul></li><li>åˆ†æ”¯å±€éƒ¨æ€§<ul><li>ä¸€æ¡è·³è½¬æŒ‡ä»¤çš„ä¸¤æ¬¡æ‰§è¡Œï¼Œå¾ˆå¯èƒ½è·³åˆ°ç›¸åŒçš„å†…å­˜ä½ç½®</li></ul></li></ul></li><li><strong>Not all pages</strong> have to be <strong>loaded</strong> in memory at the same time =&gt; <strong>virtual memory</strong><ul><li>Loading an entire set of pages for an entire program/data set into memory is <strong>wasteful</strong></li><li>Desired blocks could be <strong>loaded on demand</strong></li></ul></li></ul></li><li>Definition<ul><li>Virtual Memory: A storage allocation scheme in which <strong>secondary memory</strong> can be addressed as though it was part of main memory</li></ul></li><li>Page Faults (ç¼ºé¡µ)<ul><li>The <strong>resident set (å¸¸é©»é›†)</strong> refers to the pages that are loaded in main memory</li><li>A <strong>page fault</strong> is generated if the processor accesses a page that is <strong>not in memory</strong><ul><li>A page fault results in an <strong>interrupt</strong> (process enters <strong>blocked state</strong>)</li><li>An <strong>I/O operation</strong> is started to bring the missing page into main memory</li><li>A <strong>context switch</strong> (may) take place</li><li>An <strong>interrupt signals</strong> that the I/O operation is complete (process enters <strong>ready state</strong>)</li></ul></li></ul></li><li>The Benefits<ul><li>Being able to maintain <strong>more processes</strong> in main memory through the use of virtual memory <strong>improves CPU utilisation</strong><ul><li>Individual processes take up less memory since they are only <strong>partially</strong> loaded</li></ul></li><li>Virtual memory allows the <strong>logical address space</strong> (i.e. processes) to be <strong>larger than physical address space</strong> (i.e. main memory)</li></ul></li><li>åŸºæœ¬ç‰¹å¾<ul><li>ä¸è¿ç»­æ€§<ul><li>ç‰©ç†å†…å­˜åˆ†é…éè¿ç»­</li><li>è™šæ‹Ÿåœ°å€ç©ºé—´ä½¿ç”¨éè¿ç»­</li></ul></li><li>å¤§ç”¨æˆ·ç©ºé—´<ul><li>æä¾›ç»™ç”¨æˆ·çš„è™šæ‹Ÿå†…å­˜å¯å¤§äºå®é™…çš„ç‰©ç†å†…å­˜</li></ul></li><li>éƒ¨åˆ†äº¤æ¢<ul><li>è™šæ‹Ÿå­˜å‚¨åªå¯¹éƒ¨åˆ†è™šæ‹Ÿåœ°å€ç©ºé—´è¿›è¡Œè°ƒå…¥å’Œè°ƒå‡º</li></ul></li></ul></li><li>Contents of a Page Entry<ul><li>A <strong>â€œpresent/absent bitâ€</strong> that is set if the page/frame is in memory (page fault)</li><li>A <strong>â€œmodified bitâ€</strong> that is set if the page/frame has been modified (only modified pages have to be written back to disk when evicted) (page usage)</li><li>A <strong>â€œreferenced bitâ€</strong> that is set if the page is in usage (page usage)</li><li><strong>Protection and sharing bits:</strong> read, write, execute or combinations thereof</li></ul></li><li>Dealing with Large Page Tables<ul><li>Solution: Page the page table!</li><li>We keep tree-like structures to hold page tables</li><li>Divide the page number into<ul><li>An index to a page table of second level</li><li>A page within a second level page table</li></ul></li><li>No need to keep all page tables in memory all time</li></ul></li><li>Multi-level Page Tables<ul><li><img src="/2020/11/10/Memory-Management/Screen%20Shot%202020-12-24%20at%205.05.59%20PM.png?lastModify=1630990878" alt="img"></li><li><img src="file:///Users/apple/Desktop/Y3/OSC/diagrams/Screen%20Shot%202020-12-24%20at%205.06.20%20PM.png?lastModify=1630990878" alt="img"></li></ul></li><li>Access Speed<ul><li><strong>Memory organisation</strong> of multi-level page tables:<ul><li>The <strong>root page table</strong> is always maintained in memory</li><li>Page tables themselves are maintained in <strong>virtual memory</strong> due to their size</li><li>Page table size is proportional to that of the virtual address space</li></ul></li><li>Assume that a <strong>fetch</strong> from main memory (=&gt; memory access) takes T nano seconds<ul><li>With a <strong>single page table level</strong>, access is 2T (1. è®¿é—®å†…å­˜ä¸­çš„é¡µè¡¨ï¼›2. è®¿é—®ç›®æ ‡å†…å­˜å•å…ƒ)</li><li>With <strong>two page table levels</strong>, access is 3T (1. è®¿é—®å†…å­˜ä¸­çš„é¡¶çº§é¡µè¡¨ï¼ˆé¡µç›®å½•è¡¨ï¼‰ï¼›2. è®¿é—®å†…å­˜ä¸­çš„äºŒçº§é¡µè¡¨ï¼›3. è®¿é—®ç›®æ ‡å†…å­˜å•å…ƒ )</li></ul></li></ul></li><li>Translation Look Aside Buffers (TLBs, ç®€ç§°ä¸ºå¿«è¡¨)<ul><li><strong>Translation look aside buffer</strong> (TLBs) are (usually) located inside the memory management unit<ul><li>They <strong>cache</strong> the most <strong>frequently</strong> used page table entries</li><li>They can be searched <strong>in parallel</strong></li></ul></li><li>The principle behind TLBs is similar to other types of <strong>caching in operating systems</strong></li><li><img src="/2020/11/10/Memory-Management/Screen%20Shot%202020-12-24%20at%205.56.16%20PM.png?lastModify=1630990878" alt="img"></li><li>Memory access with TLBs:<ul><li>Assume a 20ns associative <strong>TLB lookup</strong></li><li>Assume a 100ns <strong>memory access time</strong> and with a single level page table<ul><li><strong>TLB Hit</strong> -&gt; </li><li><strong>TLB Miss</strong> -&gt; </li></ul></li></ul></li><li>Performance evaluation of TLBs:<ul><li>For an 80% hit rate, the estimated access time is:<ul><li> (i.e. 40% slowdown)</li></ul></li><li>For a 98% hit rate, the estimated access time is:<ul><li> (i.e. 22% slowdown)</li></ul></li></ul></li><li>Note that <strong>page tables</strong> can be <strong>held in virtual memory</strong> -&gt; further (initial) slow down due to page faults</li></ul></li><li>Inverted Page Tables (åç½®é¡µè¡¨)<ul><li>A <strong>â€œnormalâ€ page tableâ€™s</strong> size is proportional to the number of pages in the virtual address space (drawback to multi-level/single-level page table)</li><li>An <strong>â€œinvertedâ€ page tableâ€™s</strong> size is proportional to the size of main memory<ul><li>The inverted table contains one <strong>entry for every frame</strong> (i.e. not for every page)</li><li>A <strong>hash function</strong> based on the page number is used to index the inverted page table</li><li>The inverted table <strong>indexes entries by frame number</strong>, not by page number</li></ul></li><li>The OS maintains a <strong>single inverted page table</strong> for all processes</li><li><img src="/2020/11/10/Memory-Management/Screen%20Shot%202020-12-24%20at%208.56.49%20PM.png?lastModify=1630990878" alt="img"></li><li>Advantages:<ul><li>The OS maintains a <strong>single inverted page table</strong> for all processes</li><li>It saves lots of space (especially when the virtual address space is much larger than the physical memory)</li></ul></li><li>Disadvantages:<ul><li>Virtual-to-physical <strong>translations becomes much harder</strong>. We need to use hash tables to avoid searching the whole inverted table (be aware of potential collisions)</li></ul></li><li>It is used in combination with TLBs to speed up the search.</li></ul></li><li>Demand Paging (æŒ‰éœ€è°ƒé¡µ)<ul><li><strong>Demand paging</strong> starts the process with <strong>no pages in memory</strong><ul><li>The first instruction will immediately cause <strong>a page fault</strong></li><li><strong>More page faults</strong> will follow, but they will <strong>stabilise over time</strong> until moving to the <strong>next locality</strong></li><li>The set of pages that is currently being used is called its <strong>working set</strong> (resident set)</li></ul></li><li>Pages are only <strong>loaded when needed</strong>, i.e. following <strong>page faults</strong></li></ul></li><li>Pre-Paging (é¢„è°ƒé¡µ)<ul><li>When the process is started, all pages <strong>expected</strong> to be used (i.e. the working set) could be <strong>brought into memory at once</strong><ul><li>This can drastically <strong>reduce the page fault rate</strong></li><li>Retrieving multiple (<strong>contiguously stored</strong>) pages <strong>reduces transfer time</strong> (seek time, rotational latency, etc.)</li></ul></li><li><strong>Pre-paging</strong> loads pages (as much as possible) <strong>before page faults are generated</strong> (-&gt; a similar mechanism is used when processes are <strong>swapped out/in</strong>)</li></ul></li><li>Implementation Details<ul><li>Avoid <strong>unnecessary pages</strong> and <strong>page replacement</strong> is important</li><li>Let ma, p, and pft denote the <strong>memory access time</strong> (10-200ns), <strong>page fault rate</strong>, and <strong>page fault time</strong>, the <strong>page access time</strong> is then given by: </li><li>The expected access time is <strong>proportional to page fault rate</strong> when keeping page faults into account</li></ul></li><li>Page Replacement<ul><li>The OS must choose a <strong>page to remove</strong> when a new <strong>one is loaded</strong> (and all are occupied)</li><li><strong>Objective</strong> of replacement: the page that is removed should be the page <strong>least likely</strong> to be referenced in the <strong>near future</strong>. (reduce page fault rate)</li><li>This choice is made by <strong>page replacement algorithms</strong> and <strong>takes into account</strong><ul><li>When the page is <strong>last used/expected to be used</strong> again</li><li>Whether the <strong>page has been modified</strong> (only modified pages need to be written)</li></ul></li><li>Replacement choices have to be <strong>made intelligently</strong> (&lt;=&gt; random) to <strong>save time</strong>/avoid <strong>thrashing</strong></li></ul></li><li>Optimal Page Replacement (æœ€ä½³ç½®æ¢ç®—æ³•)<ul><li>In an <strong>ideal/optimal</strong> world<ul><li>Each page is labeled with the <strong>number of instructions</strong> that will be executed/length of time before it is <strong>used again</strong></li><li>The page which will be <strong>not referenced</strong> for the <strong>longest time</strong> is the optimal one to remove</li></ul></li><li>The <strong>optimal approach</strong> is <strong>not possible to implement</strong><ul><li>It can be used for <strong>post-execution analysis</strong> -&gt; what would have been the minimum number of page faults</li><li>It provides a <strong>lower bound</strong> on the <strong>number of page faults</strong> (used for comparison with other algorithms)</li></ul></li></ul></li><li>First-In, First-Out (FIFO) (å…ˆè¿›å…ˆå‡ºç½®æ¢ç®—æ³•)<ul><li>FIFO maintains a <strong>linked list</strong> and <strong>new pages</strong> are added at the end of the list</li><li>The <strong>oldest page</strong> at the <strong>head of the list</strong> is evicted when a page faults occurs</li><li>The <strong>(dis-)advantages</strong> of FIFO include:<ul><li>It is <strong>easy</strong> to understand/implement</li><li>It <strong>performs poorly</strong> =&gt; heavily used pages are just as likely to be evicted as a lightly used pages</li></ul></li></ul></li><li>Second Chance FIFO (ç¬¬äºŒæ¬¡æœºä¼šç½®æ¢ç®—æ³•)<ul><li>Second chance is a <strong>modification of FIFO</strong>:<ul><li>If a page at the front of the list has <strong>not been referenced</strong> it is <strong>evicted</strong></li><li>If the reference bit is set, the page is <strong>placed at the end</strong> of list and its <strong>reference bit reset</strong></li></ul></li><li>The <strong>(dis-)advantages</strong> of second chance FIFO include:<ul><li>It <strong>works better</strong> than standard FIFO</li><li>The algorithm is <strong>relatively simple</strong>, but it is <strong>costly to implement</strong> because the list is constantly changing (pages have to be added to the end of the list again)</li><li>The algorithm <strong>can degrade to FIFO</strong> if all pages were initially referenced</li></ul></li></ul></li><li>Not Recently Used (NRU) (æœ€è¿‘æœªä½¿ç”¨ç½®æ¢ç®—æ³•)<ul><li><strong>Referenced</strong> and <strong>modified</strong> bits are kept in the page table<ul><li>Referenced bits are clear at the start, and <strong>nulled at regular intervals</strong> (e.g. system clock interrupt)</li></ul></li><li>Four different <strong>page â€œtypesâ€</strong> exist<ul><li>class 0: not referenced, not modified</li><li>class 1: not referenced, modified</li><li>class 2: referenced, not modified</li><li>class 3: referenced, modified</li></ul></li><li><strong>Page table entries</strong> are inspected upon every <strong>page fault</strong> -&gt; a page from the <strong>lowest numbered non-empty class</strong> is removed (can be implemented as a clock)</li><li>The NRU algorithm provides a <strong>reasonable performance</strong> and is easy to understand and implement</li></ul></li><li>Least-Recently-Used (æœ€è¿‘æœ€ä¹…æœªä½¿ç”¨ç½®æ¢ç®—æ³•)<ul><li>Least recently used <strong>evicts the page</strong> that has <strong>not been used the longest</strong><ul><li>The OS must <strong>keep track</strong> of when a page was <strong>last used</strong></li><li>Every <strong>page table entry</strong> contains a <strong>field for the counter</strong></li><li>This is <strong>not cheap</strong> to implement as we need to maintain a <strong>list of pages</strong> which are <strong>sorted</strong> in the order in which they have been used (or search for the page)</li></ul></li><li>The algorithm can be <strong>implemented in hardware</strong> using a <strong>counter</strong> that is incremented after each instruction</li></ul></li><li>Resident Set (å¸¸é©»é›†)<ul><li>How many pages should be allocated to individual processes:<ul><li><strong>Small resident sets</strong> enable to store <strong>more processes</strong> in memory -&gt; improve CPU utilisation</li><li><strong>Small resident sets</strong> may result in <strong>more page faults</strong></li><li><strong>Large resident sets</strong> may <strong>no longer reduce</strong> the <strong>page fault rate</strong></li></ul></li><li>A trade-off exists between the <strong>sizes of the resident sets</strong> and <strong>system utilisation</strong></li><li>Resident set sizes may be <strong>fixed</strong> or <strong>variable</strong> (i.e. adjusted at runtime)</li><li>For <strong>variable sized</strong> resident sets, <strong>replacement policies</strong> can be:<ul><li><strong>Local scope:</strong> a page of the same process is replaced</li><li><strong>Global scope:</strong> a page can be taken away from a different process</li></ul></li><li>Variable sized sets require <strong>careful evaluation of their size</strong> when a <strong>local scope</strong> is used (often based on the <strong>working set</strong> or the <strong>page fault frequency</strong>)</li><li><strong>Global replacement policies (global scope)</strong> can select frames from the entire set, i.e., they can be â€œtakenâ€ from other processes<ul><li>Frames are <strong>allocated dynamically</strong> to processes</li><li>Processes cannot control their own page fault frequency, i.e., the <strong>PFF</strong> of one process is <strong>influenced by other processes</strong></li></ul></li><li><strong>Local replacement policies (local scope)</strong> can only select frames that are allocated to the current process<ul><li>Every process has a <strong>fixed fraction of memory</strong></li><li>The locally <strong>â€œoldest pageâ€</strong> is not necessarily the globally â€œoldest pageâ€</li></ul></li><li>Windows uses a <strong>variable approach</strong> with <strong>local replacement</strong></li></ul></li><li>Working Sets (å·¥ä½œé›†/é©»ç•™é›†)<ul><li>The <strong>resident set</strong> comprises the set of pages of the process that are in memory</li><li>The <strong>working set</strong> W(t, k) comprises the set referenced pages in the last k virtual time units for the process at time t</li><li>k can be defined as <strong>memory references</strong><ul><li>The set of most recently used pages</li><li>The set of pages used within a pre-specified time interval</li></ul></li><li>The <strong>working set size</strong> can be used as a guide for the number frames that should be allocated to a process</li><li>The working set is a <strong>function of time</strong> t:<ul><li>Processes <strong>move between localities</strong>, hence, the pages that are included in the working set <strong>change over time</strong></li></ul></li><li>Choosing the right value of k is paramount:<ul><li>Too <strong>small</strong>: inaccurate, pages are missing</li><li>Too <strong>large</strong>: too many unused pages present</li><li><strong>Infinity</strong>: all pages of the process are in the working set</li></ul></li><li>Working sets can be used to guide the <strong>size of the resident sets</strong><ul><li>Monitor the working set</li><li>Remove pages from the resident set that are not in the working set (LRU)</li></ul></li><li>The working set is costly to maintain -&gt; <strong>page fault frequency</strong> can be used as an approximation<ul><li>If the PFF is increased -&gt; we need to increase k</li><li>If the PFF is reduced -&gt; we may try to decrease k</li></ul></li></ul></li><li>Paging Daemon (åˆ†é¡µå®ˆæŠ¤è¿›ç¨‹): Pre-cleaning (demand-cleaning)<ul><li>å¦‚æœå‘ç”Ÿç¼ºé¡µä¸­æ–­æ—¶ç³»ç»Ÿä¸­æœ‰å¤§é‡çš„ç©ºé—²é¡µæ¡†ï¼Œæ­¤æ—¶åˆ†é¡µç³»ç»Ÿå·¥ä½œåœ¨æœ€ä½³çŠ¶æ€ã€‚å¦‚æœæ¯ä¸ªé¡µæ¡†éƒ½è¢«å ç”¨ï¼Œè€Œä¸”è¢«ä¿®æ”¹è¿‡çš„è¯ï¼Œå†æ¢å…¥ä¸€ä¸ªæ–°é¡µé¢æ—¶ï¼Œæ—§é¡µé¢åº”é¦–å…ˆè¢«å†™å›ç£ç›˜ã€‚ä¸ºä¿è¯æœ‰è¶³å¤Ÿçš„ç©ºé—²é¡µæ¡†ï¼Œå¾ˆå¤šåˆ†é¡µç³»ç»Ÿæœ‰ä¸€ä¸ªç§°ä¸ºåˆ†é¡µå®ˆæŠ¤è¿›ç¨‹ï¼ˆpaging daemonï¼‰çš„åå°è¿›ç¨‹ï¼Œå®ƒåœ¨å¤§å¤šæ•°æ—¶å€™ç¡çœ ï¼Œä½†å®šæœŸè¢«å”¤é†’ä»¥æ£€æŸ¥å†…å­˜çš„çŠ¶æ€ã€‚å¦‚æœç©ºé—²é¡µæ¡†è¿‡å°‘ï¼Œåˆ†é¡µå®ˆæŠ¤è¿›ç¨‹é€šè¿‡é¢„å®šçš„é¡µé¢ç½®æ¢ç®—æ³•é€‰æ‹©é¡µé¢æ¢å‡ºå†…å­˜ã€‚å¦‚æœè¿™äº›é¡µé¢è£…å…¥å†…å­˜åè¢«ä¿®æ”¹è¿‡ï¼Œåˆ™å°†å®ƒä»¬å†™å›ç£ç›˜ã€‚</li><li>It is more efficient to <strong>proactively (ä¸»åŠ¨åœ°)</strong> keep a number of <strong>free pages</strong> for <strong>future page faults</strong><ul><li>If not, we may have to <strong>find a page</strong> to evict and we <strong>write it to the drive</strong> (modified) first when a page fault occurs</li></ul></li><li>Many systems have a background process called a <strong>paging daemon</strong><ul><li>This process <strong>runs at periodic intervals</strong></li><li>It inspect the state of the frames and, if too few pages are free, it <strong>selects pages to evict</strong> (using page replacement algorithms)</li></ul></li><li>Paging daemons can be combined with <strong>buffering</strong> (free and modifies lists) write the modified pages but keep them in main memory when possible</li><li>åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œé¡µé¢ä¸­åŸå…ˆçš„å†…å®¹éƒ½è¢«è®°å½•ä¸‹æ¥ã€‚å½“éœ€è¦ä½¿ç”¨ä¸€ä¸ªå·²è¢«æ·˜æ±°çš„é¡µé¢æ—¶ï¼Œå¦‚æœè¯¥é¡µæ¡†è¿˜æ²¡æœ‰è¢«è¦†ç›–ï¼Œå°†å…¶ä»ç©ºé—²é¡µæ¡†ç¼“å†²æ± ä¸­ç§»å‡ºå³å¯æ¢å¤è¯¥é¡µé¢ã€‚ä¿å­˜ä¸€å®šæ•°ç›®çš„é¡µæ¡†ä¾›ç»™æ¯”ä½¿ç”¨æ‰€æœ‰å†…å­˜å¹¶åœ¨éœ€è¦æ—¶æœç´¢ä¸€ä¸ªé¡µæ¡†æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚åˆ†é¡µå®ˆæŠ¤è¿›ç¨‹è‡³å°‘ä¿è¯äº†æ‰€æœ‰çš„ç©ºé—²é¡µæ¡†æ˜¯â€œå¹²å‡€â€çš„ï¼Œæ‰€ä»¥ç©ºé—²é¡µæ¡†åœ¨è¢«åˆ†é…æ—¶ä¸å¿…å†æ€¥ç€å†™å›ç£ç›˜ã€‚</li></ul></li><li>Thrashing (æŠ–åŠ¨)<ul><li>Assume <strong>all available pages are in active use</strong> and a new page needs to be loaded:<ul><li>The page that will be <strong>evicted</strong> will have to be <strong>reloaded soon afterwards</strong>, i.e., it is still active</li></ul></li><li><strong>Thrashing</strong> occurs when pieces are swapped out and loaded again immediately</li><li>CPU utilisation is too low -&gt; scheduler (medium term scheduler) <strong>increases degree of multi-programming</strong><ul><li>-&gt; Frames are allocated to new processes and <strong>taken away from existing processes</strong><ul><li>-&gt; I/O <strong>repuests are queued</strong> up as a consequence of page faults</li></ul></li></ul></li><li>CPU <strong>utilisation drops further</strong> -&gt; scheduler increases degree of multi-programming</li><li><img src="/2020/11/10/Memory-Management/20200610182224879.png"></li><li><strong>Causes</strong> of thrashing include:<ul><li>The degree of multi-programming is too high, i.e., the total <strong>demand</strong> (i.e., the sum of all <strong>working set</strong> sizes) <strong>exceeds supply</strong> (i.e. the available frames)</li><li>An individual process is allocated <strong>too few pages</strong></li></ul></li><li>This can be <strong>prevented</strong> by, e.g., using good <strong>page replacement policies</strong>, reducing the <strong>degree of multi-programming</strong> (medium term scheduler), or adding more memory</li><li>The <strong>page fault frequency</strong> can be used to detect that a system is thrashing</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deadlock</title>
      <link href="2020/10/20/Deadlock/"/>
      <url>2020/10/20/Deadlock/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Definition"><a href="#1-Definition" class="headerlink" title="1. Definition"></a>1. Definition</h4><ul><li>A set of processes is deadlocked if <strong>each process</strong> in the set is waiting for <strong>an event</strong> that only <strong>the other process</strong> in the set can cause<ul><li>Each <strong>deadlocked process</strong> is <strong>waiting for</strong> a resource held by <strong>another deadlocked process</strong> (which cannot run and hence cannot release the resources)</li><li>This can happen between <strong>any number of processes</strong> and for <strong>any number of resources</strong></li></ul></li></ul><h4 id="2-How-do-they-occur"><a href="#2-How-do-they-occur" class="headerlink" title="2. How do they occur?"></a>2. How do they occur?</h4><ul><li>On occasions, <strong>multiple processes</strong> will <strong>require access</strong> to <strong>multiple mutually exclusive resources</strong></li><li>Process A and B request the resources in <strong>opposite orders</strong> and end up in deadlock<ul><li>Deadlocks can occur on the <strong>same machine</strong> or between <strong>mutiple machines</strong> (e.g. resources are requested over the network) and <strong>any number of resources</strong></li></ul></li><li>A resource (e.g. a devide, a data record, file, semaphore) can be <strong>acquired, used,</strong> and <strong>released</strong><ul><li>A resource can be <strong>preemptable</strong>, i.e., it can be forcefully taken away from the process without permanent adverse effect</li><li>A resource can be <strong>non-preemptable</strong>, i.e., it cannot be taken away from a process without permanent adverse effect</li></ul></li><li><strong>Deadlocks only occur</strong> for <strong>non-preemptable resources</strong> since preemptable resources can be temporarily taken away to recover from the deadlock</li><li>If a non-preemptable resource is requested but not available, the <strong>process is made to wait</strong></li></ul><h4 id="3-Minimum-Conditions"><a href="#3-Minimum-Conditions" class="headerlink" title="3. Minimum Conditions"></a>3. Minimum Conditions</h4><ul><li><strong>Four conditions</strong> must hold for deadlocks to occur:<ul><li><strong>Mutual exclusion</strong>: a resource can be assigned to at most one process at a time</li><li><strong>Hold and wait condition</strong>: a resource can be held whilst requesting new resources</li><li><strong>No preemption</strong>: resources cannot be forcefully taken away from a process</li><li><strong>Circular wait</strong>: there is a circular chain of two or more processes, waiting for a resource held by the other processes</li></ul></li><li><strong>No deadlocks</strong> can occur if one of the conditions is <strong>not satisfied</strong></li></ul><h4 id="4-Detecting-Deadlocks-A-Graph-Based-Approach"><a href="#4-Detecting-Deadlocks-A-Graph-Based-Approach" class="headerlink" title="4. Detecting Deadlocks (A Graph Based Approach)"></a>4. Detecting Deadlocks (A Graph Based Approach)</h4><ul><li>Deadlocks can be modeled using <strong>directed graphs</strong>:<ul><li><strong>Resources</strong> are represented by <strong>squares</strong> and <strong>processes</strong> are represented by <strong>circles</strong></li><li>A directed arc from a <strong>square</strong> (resource) and a <strong>circle</strong> (process) means that the resource was <strong>requested and granted</strong>, i.e. is allocated to the process</li><li>A directed arc from a <strong>circle</strong> (process) to a <strong>square</strong> (resource) indecates that the process has requested the resource and is <strong>waiting to obtain it</strong></li></ul></li><li>A <strong>cycle</strong> in the graph means that a <strong>deadlock</strong> occurs for the respective resources and processes</li></ul><h4 id="5-Matrix-approach-detection"><a href="#5-Matrix-approach-detection" class="headerlink" title="5. Matrix approach (detection)"></a>5. Matrix approach (detection)</h4><ul><li>A <strong>matrix based algorithm</strong> is used when <strong>multiple â€œcopiesâ€ of</strong> the same <strong>resource</strong> exist</li><li>Let $P_1$ to $P_n$ denote $n$ <strong>processes</strong></li><li>Let there exist $m$ <strong>resources</strong> classes<ul><li>Let $E_i$ denote the â€œexistingâ€ resources of type $i$</li><li>Let $A_i$ denote the number of allocated and available resources ($A_i$) of type $i$ is equal to $E_i$</li></ul></li><li>The algorithm uses <strong>two vectors</strong> describing the existing and available resources ($E$ and $A$), and <strong>two matrices</strong> to describe the <strong>current</strong> and <strong>requested</strong> resources per process ($C$ and $R$)</li><li>Graph Approach (cycle detection algorithm)<ul><li>Select a process for which the requested resource allocation can be satisfied<ul><li>$R_{ij}\leq A_i$ for all j in [1..m]</li><li>Run the process and â€˜markâ€™ it as completed</li></ul></li><li>Reclaim the processâ€™s resources by adding row $C_i$ to $A_i$</li><li>Repeat the above and terminate the algorithm if no â€˜unmarkedâ€™ or â€˜completableâ€™ process can be found</li></ul></li></ul><h4 id="6-Recover-from-Deadlocks"><a href="#6-Recover-from-Deadlocks" class="headerlink" title="6. Recover from Deadlocks"></a>6. Recover from Deadlocks</h4><ul><li><strong>Preemption (æŠ¢å )</strong>: the resource is forcefully removed from one of the processes (this is likely to have an ill effect)<ul><li>Take a resource away from a process, have another process use it, and then give it back. (difficult/impossible)</li></ul></li><li><strong>Rollback mechanisms (å›æ»š)</strong>: build in check points that allow the process to be restarted (periodically)<ul><li>The check points contain the <strong>memory image</strong> and <strong>resource states</strong></li><li>Multiple checkpoints should be maintained (not overwrite)</li><li>The process that owns the â€œdeadlockedâ€ resources is rolled back</li></ul></li><li><strong>Kill</strong> a strategically chosen <strong>process</strong> to release its resources<ul><li>The process should be easy to restart</li><li>The process can be re-run from the beginning with no ill effect</li></ul></li></ul><h4 id="7-Avoidance"><a href="#7-Avoidance" class="headerlink" title="7. Avoidance"></a>7. Avoidance</h4><ul><li>Deadlock detection approaches are <strong>reactive</strong>, i.e., they only detect and recover from deadlocks, but do not <strong>prevent</strong> them</li><li><strong>Deadlocks can be avoided</strong> by carefully considering resource allocation</li><li>A <strong>safe state</strong> is one where there is <strong>a feasible order</strong> for the processes to finish <strong>without deadlock</strong></li><li>A state might <strong>not</strong> be <strong>in deadlocked</strong>, but <strong>still</strong> be <strong>unsafe</strong></li><li>The â€œ<strong>bankers algorithm</strong>â€œ (Dijkstra) can be used to avoid deadlocks<ul><li>Find customer closet to max resource allocation</li><li>Check whether remaining resources can satisfy the maximum request</li><li>Return the resources from this process to the set of available resources</li><li>Find next process closest to its max resource allocation</li></ul></li><li>The state is safe <em>iff</em> all processes can finish, even when they request all their resources at the same time</li><li>The bankers algorithm for <strong>multiple resources</strong> is a genrealisation of the bankers algorithm for a single resource<ul><li><strong>Two matrices</strong> are maintained, one for the allocated resources $C$, one for the remaining resources that are required $R$</li><li><strong>Three vectors</strong> are maintained: the existing resources, the possessed resources, the available resources</li><li>Find a row in $R$ for which all corresponding resource requirements are less or equal to $A$ (selection order has no influence)<ul><li>If no row satisfies this, the state is <strong>unsafe</strong></li><li>else â€˜run the processâ€™ and add its resources to $A$</li></ul></li><li>Repeat the above until all processes have finished<ul><li>The state is <strong>safe</strong> if <strong>all processes</strong> complete successfully</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Concurrency</title>
      <link href="2020/10/16/Concurrency/"/>
      <url>2020/10/16/Concurrency/</url>
      
        <content type="html"><![CDATA[<h5 id="ç«äº‰æ¡ä»¶-race-conditions-å¤šä¸ªçº¿ç¨‹æˆ–è€…è¿›ç¨‹åœ¨è¯»å†™ä¸€ä¸ªå…±äº«æ•°æ®æ—¶ç»“æœä¾èµ–äºå®ƒä»¬æ‰§è¡Œçš„ç›¸å¯¹æ—¶é—´çš„æƒ…å½¢ã€‚"><a href="#ç«äº‰æ¡ä»¶-race-conditions-å¤šä¸ªçº¿ç¨‹æˆ–è€…è¿›ç¨‹åœ¨è¯»å†™ä¸€ä¸ªå…±äº«æ•°æ®æ—¶ç»“æœä¾èµ–äºå®ƒä»¬æ‰§è¡Œçš„ç›¸å¯¹æ—¶é—´çš„æƒ…å½¢ã€‚" class="headerlink" title="ç«äº‰æ¡ä»¶(race conditions): å¤šä¸ªçº¿ç¨‹æˆ–è€…è¿›ç¨‹åœ¨è¯»å†™ä¸€ä¸ªå…±äº«æ•°æ®æ—¶ç»“æœä¾èµ–äºå®ƒä»¬æ‰§è¡Œçš„ç›¸å¯¹æ—¶é—´çš„æƒ…å½¢ã€‚"></a>ç«äº‰æ¡ä»¶(race conditions): å¤šä¸ªçº¿ç¨‹æˆ–è€…è¿›ç¨‹åœ¨è¯»å†™ä¸€ä¸ªå…±äº«æ•°æ®æ—¶ç»“æœä¾èµ–äºå®ƒä»¬æ‰§è¡Œçš„ç›¸å¯¹æ—¶é—´çš„æƒ…å½¢ã€‚</h5><ul><li>A <strong>race condition occurs</strong> when multiple threads/processes <strong>access shared data</strong> and the result is dependent on <strong>the order in which the instructions are interleaved</strong></li></ul><h5 id="é˜²æ­¢ç«äº‰æ¡ä»¶-ç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªè¿›ç¨‹å¯ä»¥æ“ä½œå˜é‡ï¼Œå³è¿›ç¨‹éœ€è¦è¿›è¡ŒåŒæ­¥ã€‚"><a href="#é˜²æ­¢ç«äº‰æ¡ä»¶-ç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªè¿›ç¨‹å¯ä»¥æ“ä½œå˜é‡ï¼Œå³è¿›ç¨‹éœ€è¦è¿›è¡ŒåŒæ­¥ã€‚" class="headerlink" title="é˜²æ­¢ç«äº‰æ¡ä»¶: ç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªè¿›ç¨‹å¯ä»¥æ“ä½œå˜é‡ï¼Œå³è¿›ç¨‹éœ€è¦è¿›è¡ŒåŒæ­¥ã€‚"></a>é˜²æ­¢ç«äº‰æ¡ä»¶: ç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªè¿›ç¨‹å¯ä»¥æ“ä½œå˜é‡ï¼Œå³è¿›ç¨‹éœ€è¦è¿›è¡ŒåŒæ­¥ã€‚</h5><h4 id="1-ä¸´ç•ŒåŒº-critical-section-critical-region"><a href="#1-ä¸´ç•ŒåŒº-critical-section-critical-region" class="headerlink" title="1. ä¸´ç•ŒåŒº(critical section/critical region):"></a>1. ä¸´ç•ŒåŒº(critical section/critical region):</h4><p>å½“ä¸€ä¸ªè¿›ç¨‹åœ¨ä¸´ç•ŒåŒºå†…æ—¶ï¼Œå…¶ä»–è¿›ç¨‹ä¸å…è®¸è¿›å…¥ä¸´ç•ŒåŒºæ‰§è¡Œã€‚</p><h5 id="ä¸´ç•ŒåŒºé—®é¢˜çš„è§£å†³æ–¹æ¡ˆéœ€æ»¡è¶³ä¸‰ä¸ªè¦æ±‚ï¼š"><a href="#ä¸´ç•ŒåŒºé—®é¢˜çš„è§£å†³æ–¹æ¡ˆéœ€æ»¡è¶³ä¸‰ä¸ªè¦æ±‚ï¼š" class="headerlink" title="ä¸´ç•ŒåŒºé—®é¢˜çš„è§£å†³æ–¹æ¡ˆéœ€æ»¡è¶³ä¸‰ä¸ªè¦æ±‚ï¼š"></a>ä¸´ç•ŒåŒºé—®é¢˜çš„è§£å†³æ–¹æ¡ˆéœ€æ»¡è¶³ä¸‰ä¸ªè¦æ±‚ï¼š</h5><ol><li>äº’æ–¥è®¿é—®(Mutual exclusion)ï¼šå¦‚æœä¸€ä¸ªè¿›ç¨‹åœ¨ä¸´ç•ŒåŒºæ‰§è¡Œï¼Œå…¶ä»–è¿›ç¨‹ä¸èƒ½è¿›å…¥ä¸´ç•ŒåŒº<ul><li>only one process can be in its critical section at any one point in time</li></ul></li><li>ç©ºé—²è®©è¿›/è¿›æ­¥(Progress)ï¼šå¦‚æœæ²¡æœ‰è¿›ç¨‹åœ¨ä¸´ç•ŒåŒºï¼Œä½†æœ‰äº›è¿›ç¨‹éœ€è¦è¿›å…¥ä¸´ç•ŒåŒºï¼Œä¸èƒ½æ— é™æœŸåœ°å»¶é•¿ä¸‹ä¸€ä¸ªè¦è¿›å…¥ä¸´ç•ŒåŒºçš„ç­‰å¾…æ—¶é—´ã€‚å³ä¸åœ¨ä¸´ç•ŒåŒºçš„è¿›ç¨‹ä¸èƒ½é˜»æ­¢å¦ä¸€ä¸ªè¿›ç¨‹è¿›å…¥ä¸´ç•ŒåŒºã€‚<ul><li>any process must be able to enter its critical section at some point in time</li></ul></li><li>æœ‰é™ç­‰å¾…(Bounded waiting)ï¼šå½“ä¸€ä¸ªè¿›ç¨‹æå‡ºè¦è¿›å…¥ä¸´ç•ŒåŒºè¯·æ±‚åï¼Œåªéœ€è¦ç­‰å¾…ä¸´ç•ŒåŒºè¢«ä½¿ç”¨æœ‰ä¸Šé™çš„æ¬¡æ•°åï¼Œè¯¥è¿›ç¨‹å°±å¯ä»¥è¿›å…¥ä¸´ç•ŒåŒºã€‚å³è¿›ç¨‹ä¸åº”è¯¥é¥¿æ­»åœ¨ä¸´ç•ŒåŒºå…¥å£å¤„ã€‚<ul><li>processes cannot be made to wait indefinitely</li></ul></li></ol><h4 id="2-ç¦æ­¢ä¸­æ–­-disabling-interrupts"><a href="#2-ç¦æ­¢ä¸­æ–­-disabling-interrupts" class="headerlink" title="2. ç¦æ­¢ä¸­æ–­(disabling interrupts)"></a>2. ç¦æ­¢ä¸­æ–­(disabling interrupts)</h4><ol><li>åœ¨å•å¤„ç†æœºä¸­å¹¶å‘è¿›ç¨‹ä¸èƒ½é‡å æ‰§è¡Œï¼Œå®ƒä»¬åªèƒ½è¢«æ’å…¥ï¼Œè€Œä¸”è¿›ç¨‹å°†ç»§ç»­æ‰§è¡Œç›´åˆ°å®ƒè°ƒç”¨æ“ä½œç³»ç»ŸæœåŠ¡æˆ–è¢«ä¸­æ–­ï¼Œæ‰€ä»¥ï¼Œä¸ºä¿è¯äº’æ–¥ï¼Œç¦æ­¢è¿›ç¨‹è¢«ä¸­æ–­å°±å·²è¶³å¤Ÿã€‚</li><li>å› ä¸ºä¸´ç•Œç‚¹ä¸èƒ½è¢«ä¸­æ–­ï¼Œäº’æ–¥å°±èƒ½å¾—åˆ°ä¿è¯ã€‚</li><li>ç¼ºç‚¹ï¼š<ul><li>ä»£ä»·é«˜ï¼Œæ‰§è¡Œæ•ˆç‡é™ä½ï¼Œå› ä¸ºå¤„ç†æœºå—åˆ°ä¸èƒ½æ’å…¥çš„é™åˆ¶ã€‚</li><li>ä¸é€‚ç”¨äºå¤šå¤„ç†æœºç³»ç»Ÿã€‚</li></ul></li></ol><h4 id="3-å¿™ç­‰å¾…-busy-waiting"><a href="#3-å¿™ç­‰å¾…-busy-waiting" class="headerlink" title="3. å¿™ç­‰å¾…(busy waiting)"></a>3. å¿™ç­‰å¾…(busy waiting)</h4><ol><li>æŒç»­æµ‹è¯•æŸä¸ªå˜é‡ç›´åˆ°è¯¥å˜é‡å˜ä¸ºç‰¹å®šå€¼ã€‚</li><li>ç¼ºç‚¹ï¼š<ul><li>æµªè´¹CPUæ—¶é—´ã€‚</li></ul></li></ol><h4 id="4-è‡ªæ—‹é”-spin-lock"><a href="#4-è‡ªæ—‹é”-spin-lock" class="headerlink" title="4. è‡ªæ—‹é”(spin lock)"></a>4. è‡ªæ—‹é”(spin lock)</h4><ol><li>åˆ©ç”¨äº†å¿™ç­‰å¾…ï¼ˆå³è‡ªæ—‹ï¼‰çš„é”æœºåˆ¶ç§°ä¸ºè‡ªæ—‹é”ï¼Œæˆ–è€…è¯´è‡ªæ—‹é”å°±æ˜¯å¿™ç­‰å¾…ã€‚</li><li>ä¸‹é¢æåˆ°çš„åˆ©ç”¨test_and_setæ–¹æ³•å’Œcompare_and_swapæ–¹æ³•çš„ä¸¤ä¸ªä¾‹å­ä»¥åŠPetersonç®—æ³•ï¼Œéƒ½å¯ç§°ä¸ºè‡ªæ—‹é”ã€‚</li><li>ç¼ºç‚¹ï¼š<ul><li>é€ æˆæ­»é”</li><li>è¿‡å¤šå ç”¨cpuèµ„æº</li></ul></li><li>ä¼˜ç‚¹ï¼š<ul><li>é˜²æ­¢ä¸Šä¸‹æ–‡åˆ‡æ¢</li><li>è¾ƒé€‚ç”¨äºé”ä½¿ç”¨è€…ä¿æŒé”æ—¶é—´æ¯”è¾ƒçŸ­çš„æƒ…å†µã€‚</li></ul></li></ol><h4 id="5-äº’æ–¥é”-mutex"><a href="#5-äº’æ–¥é”-mutex" class="headerlink" title="5. äº’æ–¥é”(mutex)"></a>5. äº’æ–¥é”(mutex)</h4><ol><li><p>äº’æ–¥é”çš„å®ç°æ–¹å¼ä¹‹ä¸€å°±æ˜¯è‡ªæ—‹é”ã€‚</p></li><li><p>ä¸€ä¸ªäº’æ–¥é”å°±æ˜¯ä¸€ä¸ªå¯å…±äº«çš„å˜é‡ï¼Œæœ‰ä¸¤ç§çŠ¶æ€ï¼šâ€œé”å®šâ€(locked)å’Œâ€œéé”å®šâ€(unlocked)</p></li><li><p>ä¸¤ä¸ªåŸå­å‡½æ•°æ¥æ“ä½œäº’æ–¥é”ï¼š</p><ul><li><p>acquire()ï¼šåœ¨è¿›ç¨‹è¿›å…¥ä¸´ç•ŒåŒºå‰è°ƒç”¨ï¼Œå°†boolå€¼è®¾ç½®ä¸ºfalse</p><pre class="line-numbers language-c"><code class="language-c"><span class="token function">acquire</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>available<span class="token punctuation">)</span> <span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// busy wait</span>  available <span class="token operator">=</span> false<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>release()ï¼šåœ¨æŸè¿›ç¨‹é€€å‡ºä¸´ç•ŒåŒºåè°ƒç”¨ï¼Œå°†boolå€¼è®¾ä¸ºtrue</p><pre class="line-numbers language-c"><code class="language-c"><span class="token function">release</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  available <span class="token operator">=</span> true<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>available</p></li><li><p>è¿™ä¸¤ä¸ªå‡½æ•°å¿…é¡»æ˜¯åŸå­æ“ä½œ</p></li><li><p>è¿™ç§äº’æ–¥é”ä¹Ÿç§°ä¸ºè‡ªæ—‹é”ï¼Œå› ä¸ºè°ƒç”¨è€…ä¼šè¿›å…¥å¿™ç­‰å¾…</p></li><li><p>ä¼˜ç¼ºç‚¹åŒè‡ªæ—‹é”</p></li></ul></li><li><p>çœŸæ­£çš„äº’æ–¥é”ä¸ä¸Šè¿°ä¸åŒçš„æ˜¯ï¼Œè°ƒç”¨è€…åœ¨é”æ²¡é‡Šæ”¾ä¹‹å‰ä¼šè¿›å…¥é˜»å¡æˆ–ç¡çœ çŠ¶æ€ï¼Œè€Œä¸æ˜¯è¿›å…¥å¿™ç­‰å¾…ï¼Œæ— é™å¾ªç¯åœ°å»æµ‹è¯•é”æ˜¯å¦é‡Šæ”¾ã€‚</p></li></ol><pre class="line-numbers language-c"><code class="language-c"><span class="token function">acquire</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>available<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// è¿›å…¥ç¡çœ æˆ–é˜»å¡</span>    <span class="token comment" spellcheck="true">// ç›´åˆ°é”é‡Šæ”¾äº†å†å”¤é†’</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="5"><li><p>å¿…é¡»æ˜¯åŒä¸€ä¸ªè¿›ç¨‹ä¸Šé”å’Œè§£é”ï¼ˆä¸ä¹‹åçš„ä¿¡å·é‡æ¯”è¾ƒï¼‰</p></li><li><p>ç¼ºç‚¹ï¼š</p><ul><li>éœ€è¦æ¶‰åŠä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œå¼€é”€æ¯”è‡ªæ—‹é”å¤§</li></ul></li></ol><h4 id="6-æ­»é”-deadlock"><a href="#6-æ­»é”-deadlock" class="headerlink" title="6. æ­»é”(deadlock)"></a>6. æ­»é”(deadlock)</h4><ol><li>æ˜¯æŒ‡ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„è¿›ç¨‹åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œç”±äºç«äº‰èµ„æºæˆ–è€…ç”±äºå½¼æ­¤é€šä¿¡è€Œé€ æˆçš„ä¸€ç§é˜»å¡çš„ç°è±¡ï¼Œè‹¥æ— å¤–åŠ›ä½œç”¨ï¼Œå®ƒä»¬éƒ½å°†æ— æ³•æ¨è¿›ä¸‹å»ã€‚æ­¤æ—¶ç§°ç³»ç»Ÿå¤„äºæ­»é”çŠ¶æ€æˆ–ç³»ç»Ÿäº§ç”Ÿäº†æ­»é”ï¼Œè¿™äº›æ°¸è¿œåœ¨äº’ç›¸ç­‰å¾…çš„è¿›ç¨‹ç§°ä¸ºæ­»é”è¿›ç¨‹ã€‚</li><li>è§„èŒƒå®šä¹‰ï¼šé›†åˆä¸­çš„æ¯ä¸€ä¸ªè¿›ç¨‹éƒ½åœ¨ç­‰å¾…åªèƒ½ç”±æœ¬é›†åˆä¸­çš„å…¶ä»–è¿›ç¨‹æ‰èƒ½å¼•å‘çš„äº‹ä»¶ï¼Œé‚£ä¹ˆè¯¥ç»„è¿›ç¨‹æ˜¯æ­»é”çš„ã€‚</li><li>å¿…è¦æ¡ä»¶ï¼š<ul><li>äº’æ–¥æ¡ä»¶ï¼šæŒ‡ä¸€æ®µæ—¶é—´å†…æŸèµ„æºåªç”±ä¸€ä¸ªè¿›ç¨‹å ç”¨ï¼Œå³ä¸€ä¸ªèµ„æºåªèƒ½è¢«ä¸€ä¸ªè¿›ç¨‹ä½¿ç”¨</li><li>è¯·æ±‚ä¸ä¿æŒæ¡ä»¶ï¼šæŒ‡è¿›ç¨‹å·²ç»ä¿æŒè‡³å°‘ä¸€ä¸ªèµ„æºï¼Œä½†åˆæå‡ºäº†æ–°çš„èµ„æºè¯·æ±‚ï¼Œè€Œè¯¥èµ„æºå·²è¢«å…¶å®ƒè¿›ç¨‹å æœ‰ï¼Œæ­¤æ—¶è¯·æ±‚è¿›ç¨‹é˜»å¡ï¼Œä½†åˆå¯¹è‡ªå·±å·²è·å¾—çš„å…¶å®ƒèµ„æºä¿æŒä¸æ”¾ã€‚</li><li>ä¸å‰¥å¤ºæ¡ä»¶ï¼šæŒ‡è¿›ç¨‹å·²è·å¾—çš„èµ„æºï¼Œåœ¨æœªä½¿ç”¨å®Œä¹‹å‰ï¼Œä¸èƒ½è¢«å‰¥å¤ºï¼Œåªèƒ½åœ¨ä½¿ç”¨å®Œæ—¶ç”±è‡ªå·±é‡Šæ”¾ã€‚</li><li>ç¯è·¯ç­‰å¾…æ¡ä»¶ï¼šæŒ‡åœ¨å‘ç”Ÿæ­»é”æ—¶ï¼Œå¿…ç„¶å­˜åœ¨ä¸€ä¸ªè¿›ç¨‹â€”â€”èµ„æºçš„ç¯å½¢é“¾ï¼Œå³è¿›ç¨‹é›†åˆ{P0ï¼ŒP1ï¼ŒP2ï¼ŒÂ·Â·Â·ï¼ŒPn}ä¸­çš„P0æ­£åœ¨ç­‰å¾…ä¸€ä¸ªP1å ç”¨çš„èµ„æºï¼›P1æ­£åœ¨ç­‰å¾…P2å ç”¨çš„èµ„æºï¼Œâ€¦â€¦ï¼ŒPnæ­£åœ¨ç­‰å¾…å·²è¢«P0å ç”¨çš„èµ„æºã€‚</li></ul></li><li>é¢„é˜²ï¼Œè§£å†³æ–¹æ³•ï¼Œæ’é™¤æ–¹æ³•ï¼ˆè¿˜æ²¡è®²&#x1F605;ï¼‰</li></ol><h4 id="7-Petersonç®—æ³•-è½¯ä»¶å®ç°"><a href="#7-Petersonç®—æ³•-è½¯ä»¶å®ç°" class="headerlink" title="7. Petersonç®—æ³•(è½¯ä»¶å®ç°)"></a>7. Petersonç®—æ³•(è½¯ä»¶å®ç°)</h4><ol><li><p>å‡è®¾LOADå’ŒSTOREä¸¤ä¸ªæŒ‡ä»¤éƒ½æ˜¯åŸå­çš„ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸èƒ½è¢«æ‰“æ–­</p></li><li><p>ä¸¤ä¸ªè¿›ç¨‹Pi, Pjå…±äº«ä¸¤ä¸ªå˜é‡ï¼š</p></li></ol><ul><li><strong>int</strong> turn: è¡¨æ˜å“ªä¸ªè¿›ç¨‹æ˜¯ä¸‹ä¸€ä¸ªè¿›å…¥ä¸´ç•ŒåŒºçš„</li><li><strong>boolean</strong> flag[2]: è¡¨æ˜æŸä¸ªè¿›ç¨‹å‡†å¤‡å¥½è¿›å…¥ä¸´ç•ŒåŒºï¼Œ<strong>flag[i]</strong> = trueè¡¨ç¤ºè¿›ç¨‹Piå·²ç»å‡†å¤‡å¥½è¿›å…¥ä¸´ç•ŒåŒº</li></ul><ol start="3"><li><p>è¿›ç¨‹Piå’ŒPjçš„ç»“æ„</p><pre class="line-numbers language-c"><code class="language-c"><span class="token comment" spellcheck="true">// è¿›ç¨‹Piçš„ç»“æ„</span><span class="token keyword">do</span> <span class="token punctuation">{</span>    flag<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> true<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// i wants to enter critical section</span>    turn <span class="token operator">=</span> j<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// allow j to access first</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>flag<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&amp;&amp;</span> turn <span class="token operator">==</span> j<span class="token punctuation">)</span> <span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// busy waiting</span>    <span class="token comment" spellcheck="true">// ä¸´ç•ŒåŒº</span>    flag<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> false<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// å‰©ä½™åŒº</span><span class="token punctuation">}</span><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// è¿›ç¨‹Pjçš„ç»“æ„</span><span class="token keyword">do</span> <span class="token punctuation">{</span>    flag<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> true<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// j wants to enter critical section</span>    turn <span class="token operator">=</span> i<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// allow i to access first</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>flag<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&amp;&amp;</span> turn <span class="token operator">==</span> i<span class="token punctuation">)</span> <span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// busy waiting</span>    <span class="token comment" spellcheck="true">// ä¸´ç•ŒåŒº</span>    flag<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> false<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// å‰©ä½™åŒº</span><span class="token punctuation">}</span><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>è¯¥ç®—æ³•æ»¡è¶³è§£å†³ä¸´ç•ŒåŒºé—®é¢˜çš„ä¸‰ä¸ªå¿…é¡»æ ‡å‡†ï¼šäº’æ–¥è®¿é—®ï¼Œè¿›å…¥ï¼ˆå³ä¸æ­»é”ï¼‰ï¼Œæœ‰é™ç­‰å¾…ï¼ˆå³ä¸é¥¿æ­»ï¼‰</p><ul><li><p>äº’æ–¥è®¿é—®ï¼šå˜é‡turnåªèƒ½æœ‰ä¸€ä¸ªå€¼</p><ul><li>flag[i]å’Œflag[j]éƒ½ä¸ºtrueå½“Piå’ŒPjéƒ½æƒ³è¿›å…¥ä¸´ç•ŒåŒº</li><li>turnåªèƒ½ç­‰äºiæˆ–jå…¶ä¸­ä¸€ä¸ªå€¼</li><li>while (flag[i] &amp;&amp; turn == i)å’Œwhile (flag[j] &amp;&amp; turn == j)ä¸­åªæœ‰ä¸€ä¸ªä¸ºtrueï¼Œä¸ºtrueçš„é‚£ä¸ªè¿›ç¨‹è¿›å…¥å¿™ç­‰å¾…(busy waiting)ï¼Œè€Œå¦ä¸€ä¸ªè¿›ç¨‹å¯ä»¥è¿›å…¥ä¸´ç•ŒåŒº</li><li>å› æ­¤ï¼Œæœ€å¤šåªæœ‰ä¸€ä¸ªè¿›ç¨‹å¯ä»¥è¿›å…¥ä¸´ç•ŒåŒº</li></ul></li><li><p>ç©ºé—²è®©è¿›ï¼š</p><ul><li><p><strong>æƒ…å†µä¸€</strong>ï¼š</p></li><li><p>å‡è®¾Pjæ­£åœ¨ä¸´ç•ŒåŒºï¼ŒPiæ­£åœ¨å¿™ç­‰å¾…</p></li><li><p>å½“Pjé€€å‡ºä¸´ç•ŒåŒºåï¼ˆå³æ²¡æœ‰è¿›ç¨‹åœ¨ä¸´ç•ŒåŒºï¼‰ï¼Œæ­¤æ—¶flag[j]å˜ä¸ºfalse</p></li><li><p>while (flag[j] &amp;&amp; turn == j) å°†ä¼šåœæ­¢Piçš„å¿™ç­‰å¾…ï¼Œæ­¤æ—¶Piå°±å¯ä»¥è¿›å…¥ä¸´ç•ŒåŒº</p></li><li><p><strong>æƒ…å†µäºŒ</strong>ï¼š</p></li><li><p>å‡è®¾Piå’ŒPjéƒ½æƒ³è¿›å…¥ä¸´ç•ŒåŒºï¼Œå³flag[i] = flag[j] = true</p></li><li><p>turnç­‰äºiæˆ–j =&gt; å‡è®¾turn = i</p></li><li><p>while (flag[j] &amp;&amp; turn == j)ç»ˆæ­¢ï¼ŒPiè¿›å…¥ä¸´ç•ŒåŒºï¼ŒPjè¿›å…¥å¿™ç­‰å¾…</p></li><li><p>Pié€€å‡ºä¸´ç•ŒåŒºï¼Œflag[i] = false</p></li><li><p>while (flag[i] &amp;&amp; turn == i)ç»ˆæ­¢ï¼ŒPjè¿›å…¥ä¸´ç•ŒåŒº</p></li></ul></li><li><p>æœ‰é™ç­‰å¾…ï¼šPetersonç®—æ³•æ˜¾ç„¶è®©è¿›ç¨‹ç­‰å¾…ä¸è¶…è¿‡1æ¬¡çš„ä¸´ç•ŒåŒºä½¿ç”¨ï¼Œå³å¯è·å¾—æƒé™è¿›å…¥ä¸´ç•ŒåŒºã€‚</p><ul><li>ç”±ä¸Šè¿°æƒ…å†µå¯çŸ¥ï¼Œä¸€ä¸ªè¿›ç¨‹æœ€å¤šåœ¨å¦ä¸€ä¸ªè¿›ç¨‹è¿›å…¥ä¸´ç•ŒåŒºä¸€æ¬¡åå°±èƒ½è¿›å…¥</li></ul></li></ul></li><li><p>åˆ†æï¼ˆâ€œè°¦è®©å¼â€ï¼‰</p><ul><li>é¦–å…ˆï¼Œå¦‚æœæ˜¯è¿›ç¨‹iç¬¬ä¸€æ¬¡å¼€å§‹æ‰§è¡Œï¼Œé‚£å®ƒå¯ä»¥é¡ºåˆ©è¿›å…¥ä¸´ç•ŒåŒºï¼Œå› ä¸ºflag[j] = falseï¼Œè¿›ç¨‹jè¿˜ä¸æƒ³è¿›å…¥ä¸´ç•ŒåŒºã€‚</li><li>å…¶æ¬¡ï¼Œå¦‚æœè¿›ç¨‹iå’Œè¿›ç¨‹jå·²ç»åœ¨å¹¶å‘æ‰§è¡Œäº†ï¼Œå®ƒä»¬çš„è°ƒåº¦é¡ºåºæ˜¯æœªçŸ¥çš„ï¼Œå‡è®¾æ¯ä¸ªè¿›ç¨‹æ¯æ¬¡æ‰§è¡Œä¸€è¡Œä»£ç ï¼Œäº¤æ›¿æ‰§è¡Œã€‚é‚£å…ˆæ‰§è¡Œçš„è¿›ç¨‹å°±â€œèµšäº†â€ï¼Œæ¯”å¦‚è¿›ç¨‹iå…ˆæ‰§è¡Œï¼Œé‚£ä¹ˆå®ƒä¼šå…ˆå°†turnâ€œè°¦è®©â€åœ°è®¾ç½®ä¸ºjï¼Œä½†æ¥ä¸‹æ¥è½®åˆ°è¿›ç¨‹jæ‰§è¡Œäº†ï¼Œå®ƒä¹Ÿâ€œè°¦è®©â€åœ°å°†turnè®¾ç½®ä¸ºiã€‚è¿™æ—¶åˆè½®åˆ°äº†è¿›ç¨‹iæ‰§è¡Œäº†ï¼Œè€Œä¸”æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œwhileä¸­ç¬¬äºŒä¸ªæ¡ä»¶å·²ç»ä¸æ»¡è¶³äº†ï¼è¿™æ—¶è¿›ç¨‹iå°±è¿›å…¥äº†ä¸´ç•ŒåŒºï¼ç„¶åæˆ‘ä»¬æŠŠæƒ…å†µä¸€èˆ¬åŒ–ï¼Œä¸å†å‡è®¾æ¯ä¸ªè¿›ç¨‹äº¤æ›¿åœ°æ‰§è¡Œä¸€è¡Œä»£ç ï¼Œåªè¦ä¸€ä¸ªè¿›ç¨‹åæ‰§è¡Œäº†turn = i;(æˆ–turn = j;)è¿™æ¡è¯­å¥ï¼Œé‚£ä¹ˆå¦ä¸€ä¸ªè¿›ç¨‹å°±å¯ä»¥è¿›å…¥ä¸´ç•ŒåŒºã€‚ï¼ˆåˆ†æçš„æ—¶å€™é‡ç‚¹å…³æ³¨ä¸€ç‚¹ï¼šå¦ä¸€ä¸ªè¿›ç¨‹åˆ°åº•æƒ³ä¸æƒ³è¿›å…¥ä¸´ç•ŒåŒºï¼Ÿï¼‰</li></ul></li></ol><h4 id="8-ç¡¬ä»¶åŒæ­¥æ–¹æ³•"><a href="#8-ç¡¬ä»¶åŒæ­¥æ–¹æ³•" class="headerlink" title="8. ç¡¬ä»¶åŒæ­¥æ–¹æ³•"></a>8. ç¡¬ä»¶åŒæ­¥æ–¹æ³•</h4><ol><li><p>test_and_set()</p><pre class="line-numbers language-c"><code class="language-c"><span class="token comment" spellcheck="true">// test and set method</span>bool <span class="token function">test_and_set</span><span class="token punctuation">(</span>boolean<span class="token operator">*</span> lock<span class="token punctuation">)</span> <span class="token punctuation">{</span>  bool rv <span class="token operator">=</span> <span class="token operator">*</span>lock<span class="token punctuation">;</span>  <span class="token operator">*</span>lock <span class="token operator">=</span> true<span class="token punctuation">;</span>  <span class="token keyword">return</span> rv<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Example of using test and set method</span><span class="token keyword">do</span> <span class="token punctuation">{</span>  <span class="token comment" spellcheck="true">// while the lock is in use (i.e. true)</span>  <span class="token comment" spellcheck="true">// apply busy waiting</span>  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token function">test_and_set</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>lock<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">;</span>   <span class="token comment" spellcheck="true">// lock from false to true, the loop terminates</span>    <span class="token comment" spellcheck="true">//critical section</span>  lock <span class="token operator">=</span> false<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//remainder section</span><span class="token punctuation">}</span><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>compare_and_swap()</p><pre class="line-numbers language-c"><code class="language-c"><span class="token comment" spellcheck="true">// compare and swap method (version1)</span><span class="token comment" spellcheck="true">// æ€»æ˜¯è¿”å›æ—§å€¼(expected)ï¼Œå¯åœ¨casæ“ä½œä¹‹åå¯¹å…¶è¿›è¡Œæµ‹è¯•ï¼Œä»¥æŸ¥çœ‹æ˜¯å¦åŒ¹é…æ—§å€¼</span><span class="token comment" spellcheck="true">// å…¶ä»–versionè¿”å›boolå€¼ï¼Œæ¥åˆ¤æ–­æ˜¯å¦æˆåŠŸæ›´æ–°</span><span class="token keyword">int</span> <span class="token function">compare_and_swap</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>lock<span class="token punctuation">,</span> <span class="token keyword">int</span> expected<span class="token punctuation">,</span> <span class="token keyword">int</span> new_value<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> temp <span class="token operator">=</span> <span class="token operator">*</span>lock<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">*</span>lock <span class="token operator">==</span> expected<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">*</span>lock <span class="token operator">=</span> new_value<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> temp<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Example of using compare and swap method</span><span class="token keyword">do</span> <span class="token punctuation">{</span>  <span class="token comment" spellcheck="true">// while the lock is in use (i.e. true or 1), applying busy waiting</span>  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token function">compare_and_swap</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>lock<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//lock from false to true or from 0 to 1, the loop terminates</span>    <span class="token comment" spellcheck="true">//critical section</span>  lock <span class="token operator">=</span> false<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// lock = 0</span>  <span class="token comment" spellcheck="true">//remainder section</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>ä¸Šè¿°ä¸¤ç§æ–¹æ³•éƒ½æ˜¯ç”±ç¡¬ä»¶ä¿è¯åŒæ­¥çš„ï¼Œå³ç¡¬ä»¶ä¿è¯è¿™ä¸‰æ¡è¯­å¥å¿…é¡»åŸå­æ‰§è¡Œï¼Œä¸­é—´ä¸å‘ç”Ÿä»»ä½•ä¸­æ–­ã€‚å¦‚æœä¸­æ–­ï¼Œåˆ™ä¼šæœ‰ç«äº‰æ¡ä»¶å‘ç”Ÿã€‚</p></li><li><p>å¦‚æœä¸Šè¿°ä¸¤ç§æ–¹æ³•è¢«åŒæ—¶è°ƒç”¨ï¼Œåˆ™æŒ‰é¡ºåºæ‰§è¡Œã€‚</p></li><li><p>ç¼ºç‚¹ï¼š</p><ul><li>åˆ©ç”¨äº†å¿™ç­‰å¾…(busy waiting)</li><li>å¯èƒ½é€ æˆæ­»é”</li></ul></li></ol><h4 id="9-ä¿¡å·é‡-Semaphores"><a href="#9-ä¿¡å·é‡-Semaphores" class="headerlink" title="9. ä¿¡å·é‡(Semaphores)"></a>9. ä¿¡å·é‡(Semaphores)</h4><ol><li><p>å®ç°ç”±æ“ä½œç³»ç»Ÿæä¾›</p></li><li><p>ç›¸æ¯”äº’æ–¥é‡åªèƒ½å–0å’Œ1ä¸¤ä¸ªå€¼ï¼Œä¿¡å·é‡å¯ä»¥ä¸º0-Nï¼Œç”¨æ¥å®ç°æ›´åŠ å¤æ‚çš„åŒæ­¥ï¼Œäº’æ–¥é‡å¯çœ‹ä½œæ˜¯ä¿¡å·é‡å–åªå–0å’Œ1æ—¶çš„ç‰¹æ®Šæƒ…å†µ</p></li><li><p>ä¿¡å·é‡é€šè¿‡ä¸€ä¸ªè®¡æ•°å™¨æ§åˆ¶å¯¹å…±äº«èµ„æºçš„è®¿é—®ï¼Œä¿¡å·é‡çš„å€¼æ˜¯ä¸€ä¸ªéè´Ÿæ•´æ•°ï¼Œæ‰€æœ‰é€šè¿‡å®ƒçš„çº¿ç¨‹éƒ½ä¼šå°†è¯¥æ•´æ•°å‡ä¸€ã€‚å¦‚æœè®¡æ•°å™¨å¤§äº0ï¼Œåˆ™è®¿é—®è¢«å…è®¸ï¼Œè®¡æ•°å™¨å‡1ï¼›å¦‚æœä¸º0ï¼Œåˆ™è®¿é—®è¢«ç¦æ­¢ï¼Œæ‰€æœ‰è¯•å›¾é€šè¿‡å®ƒçš„çº¿ç¨‹éƒ½å°†å¤„äºç­‰å¾…çŠ¶æ€ã€‚</p></li><li><p>ä¿¡å·é‡å®šä¹‰ï¼š</p><pre class="line-numbers language-c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> value<span class="token punctuation">;</span>    <span class="token keyword">struct</span> process <span class="token operator">*</span> list<span class="token punctuation">;</span><span class="token punctuation">}</span> semaphore<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>ä¸¤ä¸ªåŸå­å‡½æ•°ç”¨æ¥æ“ä½œä¿¡å·é‡</p><ul><li><p>wait()è¢«è°ƒç”¨å½“ä¸€ä¸ªèµ„æºè¢«éœ€è¦æ—¶</p><pre><code>wait(semaphore * S) &#123;    S -&gt; value--;    if (S -&gt; value &lt; 0) &#123;        add process to S -&gt; list        block(); // system call    &#125;&#125;</code></pre></li><li><p>signal()/post()è¢«è°ƒç”¨å½“ä¸€ä¸ªèµ„æºé‡Šæ”¾</p><pre><code>signal(semaphore * S) &#123;    S -&gt; value++;    if (S -&gt; value &lt;= 0) &#123;        remove a process P from S -&gt; list        wakeup(P); // system call    &#125;&#125;</code></pre></li></ul></li><li><p>è°ƒç”¨wait()ï¼šå½“è®¡æ•°å™¨å°äº0æ—¶ï¼Œä¼šé˜»å¡è¿›ç¨‹</p><ul><li>è¿›ç¨‹è¿›å…¥<strong>é˜»å¡é˜Ÿåˆ—</strong></li><li>è¿›ç¨‹çŠ¶æ€ç”±<strong>è¿è¡Œ</strong>å˜ä¸º<strong>é˜»å¡</strong></li><li>è¿›ç¨‹æ§åˆ¶äº¤ç”±<strong>è¿›ç¨‹è°ƒåº¦å™¨</strong></li></ul></li><li><p>è°ƒç”¨signal()/post()ï¼šå½“è®¡æ•°å™¨å°äºç­‰äº0æ—¶ï¼Œä»é˜»å¡é˜Ÿåˆ—ä¸­ç§»é™¤è¿›ç¨‹</p><ul><li>è¿›ç¨‹çŠ¶æ€ç”±<strong>é˜»å¡</strong>å˜ä¸º<strong>å°±ç»ª</strong></li></ul></li><li><p>è´Ÿä¿¡å·å€¼ä»£è¡¨æœ‰å‡ ä¸ªè¿›ç¨‹æ­£åœ¨ç­‰èµ„æº</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Thread</title>
      <link href="2020/10/14/Thread/"/>
      <url>2020/10/14/Thread/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Thread-Usage"><a href="#1-Thread-Usage" class="headerlink" title="1. Thread Usage"></a>1. Thread Usage</h4><ul><li>Thread can be viewed as <strong>miniprocesses</strong> within a process</li><li>Why do we need multiple threads in a process?<ul><li>Multiple <strong>related activities</strong> apply to the <strong>same resources</strong>, these resources should be accessible/shared (share address space and data)</li><li>Easy to create and destroy.<ul><li>10 - 100 times faster than creating a process</li></ul></li></ul></li></ul><h4 id="2-User-Threads-Many-to-One"><a href="#2-User-Threads-Many-to-One" class="headerlink" title="2. User Threads (Many-to-One)"></a>2. User Threads (Many-to-One)</h4><ul><li><p><strong>Thread management</strong> (creating, destroying, scheduling, thread control block manipulation) is carried out <strong>in user space</strong> with the help of a <strong>user library</strong></p></li><li><p>The process maintains a <strong>thread table</strong> managed by the <strong>runtime system</strong> without the <strong>kernelâ€™s knowledge</strong></p><ul><li>Similar to <strong>process table</strong></li><li>Used for <strong>thread switching</strong></li><li>Tracks thread related information</li></ul></li><li><p>They can be implemented on <strong>OS</strong> that <strong>does not support multithreading</strong></p></li><li><img src="/2020/10/14/Thread/Screen Shot 2020-12-21 at 9.15.22 PM.png" style="zoom:50%;"></li><li><p>Advantages:</p><ul><li>Threads are in user space (i.e., <strong>no mode switches</strong> required)</li><li><strong>Full control</strong> over the thread scheduler (e.g. website server)</li><li><strong>OS independent</strong> (threads can run on OS that do not support them)</li><li>The runtime system can <strong>switch local blocking threads</strong> in user space (e.g. wait for another thread to complete)</li></ul></li><li><p>Disadvantages:</p><ul><li><strong>Blocking system calls</strong> suspend the entire process (user threads are mapped onto a single process, managed by the kernel)</li><li><strong>Page fault</strong> result in blocking the process</li><li><strong>No true parallelism</strong> (a process is scheduled on a single CPU)\</li></ul></li></ul><h4 id="3-Kernel-Threads-One-to-One"><a href="#3-Kernel-Threads-One-to-One" class="headerlink" title="3. Kernel Threads (One-to-One)"></a>3. Kernel Threads (One-to-One)</h4><ul><li><img src="/2020/10/14/Thread/Screen Shot 2020-12-21 at 9.41.55 PM.png" style="zoom:50%;"></li><li>The <strong>kernel manages</strong> the threads, user application accesses threading facilities through <strong>API</strong> and <strong>System calls</strong><ul><li><strong>Thread table</strong> is in the kernel, containing thread control blocks (subset of process control blocks)</li><li>If a <strong>thread blocks</strong>, the kernel chooses thread from same or different process</li></ul></li><li>Advantages:<ul><li><strong>True parallelism</strong> can be achieved</li><li>No run-time system needed</li></ul></li><li>Frequent <strong>mode switches</strong> take place, resulting in lower performance</li></ul><h4 id="4-Hybrid-Implementation"><a href="#4-Hybrid-Implementation" class="headerlink" title="4. Hybrid Implementation"></a>4. Hybrid Implementation</h4><ul><li>User threads are <strong>multiplexed</strong> onto kernel threads</li><li>Kernel sees and schedules the kernel threads (a limited number)</li><li>User application sees user threads and creates/schedules these (an â€œunrestrictedâ€ number)</li><li><img src="/2020/10/14/Thread/Screen Shot 2020-12-22 at 2.14.12 PM.png" style="zoom:50%;"></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Process Scheduling</title>
      <link href="2020/10/13/Process-scheduling/"/>
      <url>2020/10/13/Process-scheduling/</url>
      
        <content type="html"><![CDATA[<h4 id="1-CPUå¯†é›†å‹è¿›ç¨‹"><a href="#1-CPUå¯†é›†å‹è¿›ç¨‹" class="headerlink" title="1. CPUå¯†é›†å‹è¿›ç¨‹"></a>1. CPUå¯†é›†å‹è¿›ç¨‹</h4><ol><li>CPUå¯†é›†å‹ä¹Ÿå«è®¡ç®—å¯†é›†å‹ï¼ŒæŒ‡çš„æ˜¯ç³»ç»Ÿçš„ç¡¬ç›˜ã€å†…å­˜æ€§èƒ½ç›¸å¯¹CPUè¦å¥½å¾ˆå¤šï¼Œæ­¤æ—¶ï¼Œç³»ç»Ÿè¿ä½œå¤§éƒ¨åˆ†çš„çŠ¶å†µæ˜¯CPU Loading 100%ï¼ŒCPUè¦è¯»/å†™I/O(ç¡¬ç›˜/å†…å­˜)ï¼ŒI/Oåœ¨å¾ˆçŸ­çš„æ—¶é—´å°±å¯ä»¥å®Œæˆï¼Œè€ŒCPUè¿˜æœ‰è®¸å¤šè¿ç®—è¦å¤„ç†ï¼ŒCPU Loadingå¾ˆé«˜ã€‚</li><li>åœ¨å¤šé‡ç¨‹åºç³»ç»Ÿä¸­ï¼Œå¤§éƒ¨ä»½æ—¶é—´ç”¨æ¥åšè®¡ç®—ã€é€»è¾‘åˆ¤æ–­ç­‰CPUåŠ¨ä½œçš„ç¨‹åºç§°ä¹‹CPU boundã€‚ä¾‹å¦‚ä¸€ä¸ªè®¡ç®—åœ†å‘¨ç‡è‡³å°æ•°ç‚¹ä¸€åƒä½ä»¥ä¸‹çš„ç¨‹åºï¼Œåœ¨æ‰§è¡Œçš„è¿‡ç¨‹å½“ä¸­ç»å¤§éƒ¨ä»½æ—¶é—´ç”¨åœ¨ä¸‰è§’å‡½æ•°å’Œå¼€æ ¹å·çš„è®¡ç®—ï¼Œä¾¿æ˜¯å±äºCPU boundçš„ç¨‹åºã€‚</li><li>CPU boundçš„ç¨‹åºä¸€èˆ¬è€Œè¨€CPUå ç”¨ç‡ç›¸å½“é«˜ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºä»»åŠ¡æœ¬èº«ä¸å¤ªéœ€è¦è®¿é—®I/Oè®¾å¤‡ï¼Œä¹Ÿå¯èƒ½æ˜¯å› ä¸ºç¨‹åºæ˜¯å¤šçº¿ç¨‹å®ç°å› æ­¤å±è”½æ‰äº†ç­‰å¾…I/Oçš„æ—¶é—´ã€‚</li></ol><h4 id="2-IOå¯†é›†å‹è¿›ç¨‹"><a href="#2-IOå¯†é›†å‹è¿›ç¨‹" class="headerlink" title="2. IOå¯†é›†å‹è¿›ç¨‹"></a>2. IOå¯†é›†å‹è¿›ç¨‹</h4><ol><li>IOå¯†é›†å‹æŒ‡çš„æ˜¯ç³»ç»Ÿçš„CPUæ€§èƒ½ç›¸å¯¹ç¡¬ç›˜ã€å†…å­˜è¦å¥½å¾ˆå¤šï¼Œæ­¤æ—¶ï¼Œç³»ç»Ÿè¿ä½œï¼Œå¤§éƒ¨åˆ†çš„çŠ¶å†µæ˜¯CPUåœ¨ç­‰I/O (ç¡¬ç›˜/å†…å­˜) çš„è¯»/å†™æ“ä½œï¼Œæ­¤æ—¶CPU Loadingå¹¶ä¸é«˜ã€‚</li><li>I/O boundçš„ç¨‹åºä¸€èˆ¬åœ¨è¾¾åˆ°æ€§èƒ½æé™æ—¶ï¼ŒCPUå ç”¨ç‡ä»ç„¶è¾ƒä½ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºä»»åŠ¡æœ¬èº«éœ€è¦å¤§é‡I/Oæ“ä½œï¼Œè€Œpipelineåšå¾—ä¸æ˜¯å¾ˆå¥½ï¼Œæ²¡æœ‰å……åˆ†åˆ©ç”¨å¤„ç†å™¨èƒ½åŠ›ã€‚</li></ol><h4 id="3-CPUå¯†é›†å‹-vs-IOå¯†é›†å‹"><a href="#3-CPUå¯†é›†å‹-vs-IOå¯†é›†å‹" class="headerlink" title="3. CPUå¯†é›†å‹ vs IOå¯†é›†å‹"></a>3. CPUå¯†é›†å‹ vs IOå¯†é›†å‹</h4><ol><li><p>è®¡ç®—å¯†é›†å‹ä»»åŠ¡çš„ç‰¹ç‚¹æ˜¯è¦è¿›è¡Œå¤§é‡çš„è®¡ç®—ï¼Œæ¶ˆè€—CPUèµ„æºï¼Œæ¯”å¦‚è®¡ç®—åœ†å‘¨ç‡ã€å¯¹è§†é¢‘è¿›è¡Œé«˜æ¸…è§£ç ç­‰ç­‰ï¼Œå…¨é CPUçš„è¿ç®—èƒ½åŠ›ã€‚è¿™ç§è®¡ç®—å¯†é›†å‹ä»»åŠ¡è™½ç„¶ä¹Ÿå¯ä»¥ç”¨å¤šä»»åŠ¡å®Œæˆï¼Œä½†æ˜¯ä»»åŠ¡è¶Šå¤šï¼ŒèŠ±åœ¨ä»»åŠ¡åˆ‡æ¢çš„æ—¶é—´å°±è¶Šå¤šï¼ŒCPUæ‰§è¡Œä»»åŠ¡çš„æ•ˆç‡å°±è¶Šä½ï¼Œ<strong>æ‰€ä»¥ï¼Œè¦æœ€é«˜æ•ˆåœ°åˆ©ç”¨CPUï¼Œè®¡ç®—å¯†é›†å‹ä»»åŠ¡åŒæ—¶è¿›è¡Œçš„æ•°é‡åº”å½“ç­‰äºCPUçš„æ ¸å¿ƒæ•°ã€‚</strong></p><p>è®¡ç®—å¯†é›†å‹ä»»åŠ¡ç”±äºä¸»è¦æ¶ˆè€—CPUèµ„æºï¼Œå› æ­¤ï¼Œä»£ç è¿è¡Œæ•ˆç‡è‡³å…³é‡è¦ã€‚Pythonè¿™æ ·çš„è„šæœ¬è¯­è¨€è¿è¡Œæ•ˆç‡å¾ˆä½ï¼Œå®Œå…¨ä¸é€‚åˆè®¡ç®—å¯†é›†å‹ä»»åŠ¡ã€‚å¯¹äºè®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼Œæœ€å¥½ç”¨Cè¯­è¨€ç¼–å†™ã€‚</p></li><li><p>ç¬¬äºŒç§ä»»åŠ¡çš„ç±»å‹æ˜¯IOå¯†é›†å‹ï¼Œæ¶‰åŠåˆ°ç½‘ç»œã€ç£ç›˜IOçš„ä»»åŠ¡éƒ½æ˜¯IOå¯†é›†å‹ä»»åŠ¡ï¼Œè¿™ç±»ä»»åŠ¡çš„ç‰¹ç‚¹æ˜¯CPUæ¶ˆè€—å¾ˆå°‘ï¼Œä»»åŠ¡çš„å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨ç­‰å¾…IOæ“ä½œå®Œæˆï¼ˆå› ä¸ºIOçš„é€Ÿåº¦è¿œè¿œä½äºCPUå’Œå†…å­˜çš„é€Ÿåº¦ï¼‰ã€‚å¯¹äºIOå¯†é›†å‹ä»»åŠ¡ï¼Œä»»åŠ¡è¶Šå¤šï¼ŒCPUæ•ˆç‡è¶Šé«˜ï¼Œä½†ä¹Ÿæœ‰ä¸€ä¸ªé™åº¦ã€‚å¸¸è§çš„å¤§éƒ¨åˆ†ä»»åŠ¡éƒ½æ˜¯IOå¯†é›†å‹ä»»åŠ¡ï¼Œæ¯”å¦‚Webåº”ç”¨ã€‚</p><p>IOå¯†é›†å‹ä»»åŠ¡æ‰§è¡ŒæœŸé—´ï¼Œ99%çš„æ—¶é—´éƒ½èŠ±åœ¨IOä¸Šï¼ŒèŠ±åœ¨CPUä¸Šçš„æ—¶é—´å¾ˆå°‘ï¼Œå› æ­¤ï¼Œç”¨è¿è¡Œé€Ÿåº¦æå¿«çš„Cè¯­è¨€æ›¿æ¢ç”¨Pythonè¿™æ ·è¿è¡Œé€Ÿåº¦æä½çš„è„šæœ¬è¯­è¨€ï¼Œå®Œå…¨æ— æ³•æå‡è¿è¡Œæ•ˆç‡ã€‚å¯¹äºIOå¯†é›†å‹ä»»åŠ¡ï¼Œæœ€åˆé€‚çš„è¯­è¨€å°±æ˜¯å¼€å‘æ•ˆç‡æœ€é«˜ï¼ˆä»£ç é‡æœ€å°‘ï¼‰çš„è¯­è¨€ï¼Œè„šæœ¬è¯­è¨€æ˜¯é¦–é€‰ï¼ŒCè¯­è¨€æœ€å·®ã€‚</p></li></ol><h4 id="4-è¿›ç¨‹è°ƒåº¦"><a href="#4-è¿›ç¨‹è°ƒåº¦" class="headerlink" title="4. è¿›ç¨‹è°ƒåº¦"></a>4. è¿›ç¨‹è°ƒåº¦</h4><ol><li><strong>Classification by Time Horizon</strong></li></ol><ul><li><strong>Long term</strong>: applies to new processes and controls the <strong>degree of multiprogramming</strong> by deciding which processes to admit to the system when a good <strong>mix</strong> of <strong>CPU</strong> and <strong>I/O bound processes</strong> is favorable to keep all resources as busy as possible.</li><li><strong>Medium term</strong>: controls <strong>swapping</strong> and the <strong>degree of multi-programming</strong> (Memory management).</li><li><strong>Short term (dispatcher)</strong>: decide which process to run next.</li></ul><ol start="2"><li><strong>Classification by Approach</strong></li></ol><ul><li><strong>Non-preemptive(éæŠ¢å å¼æˆ–éå‰¥å¤ºå¼)</strong>: processes are only interrupted voluntarily</li><li><strong>Preemptive(æŠ¢å å¼æˆ–å‰¥å¤ºå¼)</strong>: processes can be <strong>interrupted forcefully</strong> or <strong>voluntarily</strong><ul><li>E.g. preemptive scheduling algorithm picks a process and lets it run for a maximum of some fixed time. (clock interrupt)</li><li>This requires context switches, which generates <strong>overhead</strong></li><li>Prevents processes from <strong>monopolizing(å„æ–­ï¼Œç‹¬å ) the CPU</strong></li><li><strong>Most popular</strong> modern operation systems are preemptive</li></ul></li></ul><h4 id="5-æ€§èƒ½è¯„ä¼°"><a href="#5-æ€§èƒ½è¯„ä¼°" class="headerlink" title="5. æ€§èƒ½è¯„ä¼°"></a>5. æ€§èƒ½è¯„ä¼°</h4><ol><li><strong>User oriented criteria</strong>: </li></ol><ul><li><p><strong>Response time(å“åº”æ—¶é—´)</strong>: minimize the time between creating the job and its first</p><p>execution</p></li><li><p><strong>Turnaround time(å‘¨è½¬æ—¶é—´)</strong>: minimize the time between creating the job and finishing it</p></li></ul><ol start="2"><li><strong>System oriented criteria</strong>:</li></ol><ul><li><strong>Throughput(ååé‡)</strong>: maximize the number of jobs processed per hour</li><li><strong>Fairness(å…¬å¹³)</strong>: <ul><li>Are processing power/waiting time equally distributed?</li><li>Is there any process with excessively long waiting time? (<strong>starvation</strong>)</li></ul></li></ul><h4 id="6-è°ƒåº¦ç®—æ³•"><a href="#6-è°ƒåº¦ç®—æ³•" class="headerlink" title="6. è°ƒåº¦ç®—æ³•"></a>6. è°ƒåº¦ç®—æ³•</h4><ol><li>Overview:</li></ol><ul><li><strong>Algorithms</strong>:<ul><li>First Come First Served (FCFS) / First In First Out (FIFO) (<strong>Batch System</strong>)</li><li>Shortest job first (<strong>Batch System</strong>)</li><li>Round Robin (<strong>Interactive System</strong>)</li><li>Priority Queue (<strong>Interactive System</strong>)</li></ul></li><li>Performance measured used:<ul><li><strong>Average response time(å¹³å‡å“åº”æ—¶é—´)</strong>: the average of the time taken for all the processes to start</li><li><strong>Average turnaround time(å¹³å‡å‘¨è½¬æ—¶é—´)</strong>: the average time taken for all the processes to finish</li></ul></li></ul><ol start="2"><li><strong>First Come First Served</strong>:</li></ol><ul><li>Concept: a <strong>non-preemptive algorithm</strong> that operates as a <strong>strict queueing mechanism</strong> and schedules the processes in the same order that they were added to the queue</li><li>Advantages:<ul><li><strong>positional fairness</strong> and easy to implement</li></ul></li><li>Disadvantages:<ul><li><strong>Favours long processes</strong> over short ones (think of the supermarket checkout!)</li><li>Could <strong>compromise resource utilisation</strong>, i.e., CPU vs. I/O devices</li></ul></li></ul><ol start="3"><li><strong>Shortest Job First:</strong></li></ol><ul><li>Concept: A <strong>non-preemptive algorithm</strong> that starts processes in order of <strong>ascending processing time</strong> using a provided/known estimate of the processing</li><li>Advantages: results in the <strong>optimal turn around time</strong></li><li>Disadvantages:<ul><li><strong>Starvation</strong> might occur</li><li><strong>Fairness</strong> is compromised</li><li><strong>Processing times have to be known</strong> beforehand or estimated by</li></ul></li></ul><ol start="4"><li><strong>Round Robin:</strong></li></ol><ul><li>Concept: a <strong>preemptive version of FCFS</strong> that forces <strong>context switches</strong> at <strong>periodic intervals</strong> or <strong>time slices (Time quantum)</strong><ul><li>Processes run in the order that they were added to the queue</li><li>Processes are forcefully <strong>interrupted by the timer</strong></li></ul></li><li>Advantages:<ul><li>Improved <strong>response time</strong></li><li>Effective for general purpose <strong>time sharing systems</strong></li></ul></li><li>Disadvantages:<ul><li>Increased <strong>context switching</strong> and thus overhead</li><li>Can <strong>reduce to FCFS</strong> (åªè¦æ—¶é—´ç‰‡è¶³å¤Ÿé•¿ï¼Œå°±æ˜¯FCFSç®—æ³•)</li></ul></li></ul><ol start="5"><li><strong>Priority Queues:</strong></li></ol><ul><li>Concept: A <strong>preemptive algorithm</strong> that schedules processes by priority (high to low)<ul><li>The process priority is saved in the <strong>process control block</strong></li></ul></li><li>Advantages:<ul><li>can <strong>prioritise I/O bound jobs</strong></li></ul></li><li>Disadvantages:<ul><li>low priority processes may suffer from <strong>starvation</strong> (with static priorities)</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Process</title>
      <link href="2020/10/10/Process/"/>
      <url>2020/10/10/Process/</url>
      
        <content type="html"><![CDATA[<h4 id="1-Definition"><a href="#1-Definition" class="headerlink" title="1. Definition"></a>1. Definition</h4><ul><li>The simplified definition: â€œa process is a <strong>running instance</strong> of a programâ€<ul><li>A program is <strong>passive</strong> entity and â€œsitsâ€ on a disk, not doing anything.</li><li>A process has <strong>control structures</strong> associated with it, may be <strong>active</strong>, and may have <strong>resources</strong> assigned to it (e.g. I/O devices, memory, processor). It has a program, input, output and a state.</li><li>A single <strong>processor</strong> may be shared among several <strong>processes</strong>.</li></ul></li><li>A process is registered with the OS using its <strong>â€œcontrol structuresâ€</strong>: i.e. an entry in the OSâ€™s <strong>process table</strong> to a <strong>process control blocks</strong> (PCB)</li><li>The <strong>process control block</strong> contains all information necessary to <strong>administer the process</strong> and is <strong>essential</strong> for <strong>context switching</strong> in <strong>multiprogramming systems</strong></li></ul><h4 id="2-Menory-Image-of-Processes"><a href="#2-Menory-Image-of-Processes" class="headerlink" title="2. Menory Image of Processes"></a>2. Menory Image of Processes</h4><ul><li>A <strong>processâ€™ memory image</strong> contains:<ul><li>The program <strong>code</strong> (could be shared between multiple processes running the same code)</li><li>A <strong>data</strong> segment: process-specified data (input and output, global variable)</li><li>call <strong>stack</strong>: keep track of active subroutines (function parameters, local variables)</li><li><strong>Heap</strong>: hold intermediate computation data generated during run time</li></ul></li><li>Every process has its own <strong>logical address space</strong>, in which the <strong>stack</strong> and <strong>heap</strong> are placed at <strong>opposite sides</strong> to allow them to grow</li></ul><h4 id="3-Process-States-and-Transitions"><a href="#3-Process-States-and-Transitions" class="headerlink" title="3. Process States and Transitions"></a>3. Process States and Transitions</h4><ul><li><p>Diagram</p><img src="/2020/10/10/Process/Screen Shot 2020-12-21 at 1.50.28 PM.png" style="zoom:50%;"></li><li><p>State transitions include:</p><ul><li>1  <strong>New -&gt; ready</strong>: admit the process and commit to execution</li><li>2  <strong>Running -&gt; blocked</strong>: e.g. process is waiting for input or carried out a system call</li><li>3  <strong>Ready -&gt; running</strong>: the process is selected by the <strong>process sceduler</strong></li><li>4  <strong>Blocked -&gt; ready</strong>: event happens, e.g. I/O operation has finished</li><li>5  <strong>Running -&gt; ready</strong>: the process is preempted, e.g., by a <strong>timer interrupt</strong> or by <strong>pause</strong></li><li>6  <strong>Running -&gt; exit</strong>: process has finished, e.g. program ended or exception encountered</li></ul></li></ul><h4 id="4-Context-Switching-Multiprogramming"><a href="#4-Context-Switching-Multiprogramming" class="headerlink" title="4. Context Switching (Multiprogramming)"></a>4. Context Switching (Multiprogramming)</h4><ul><li><p>Modern computers are <strong>multiprogramming</strong> systems:</p></li><li><p>Assuming a <strong>single processor system</strong>, the instructions of individual processes are executed <strong>sequentially</strong></p><ul><li>CPUâ€™s rapid switching back and forth from process to process is called <strong>multiprogramming</strong>.</li><li>Multiprogramming is achieved by <strong>alternating</strong> processes and <strong>context switching</strong></li><li><strong>True parallelism</strong> requires <strong>mutiple processors</strong></li></ul></li><li><p>When a <strong>context switch</strong> takes place, the system <strong>saves the state</strong> of the old process and <strong>loads the state</strong> of the new process (created <strong>overhead</strong>)</p><ul><li><strong>Saved</strong> =&gt; the process control block is <strong>updated</strong></li><li><strong>(Re-)started</strong> =&gt; the process control block <strong>read</strong></li></ul></li><li><p>A <strong>trade-off</strong> exists between <strong>â€œresponsivenessâ€</strong> and <strong>â€œoverheadâ€</strong></p><ul><li><strong>Short time slices</strong> result in <strong>good response time</strong> but <strong>low effective â€œutilisationâ€</strong></li><li><strong>Long time slices</strong> result in <strong>poor response time</strong> but <strong>better effective â€œutilisationâ€</strong></li></ul></li><li><p>The OS uses <strong>process control block</strong> and a <strong>process table</strong> to manage processes and maintain their information</p></li><li><p>A <strong>process control block</strong> contains three types of <strong>attributes</strong>:</p><ul><li><strong>Process identification</strong> (PID, UID, Parent PID)</li><li><strong>Process state information</strong> (user registers, program counters, stack pointer, program status word, memory management information, files, etc.)</li><li><strong>Process control information</strong> (process state, scheduling information, etc.)</li></ul></li><li><p><strong>Process control blocks</strong> are <strong>kernel data structures</strong>, i.e. they are <strong>protected</strong> and only accessible in <strong>kernel mode!</strong></p><ul><li>Allowing user applications to access them directly could <strong>compromise their integrity</strong></li><li>The <strong>operating system manages</strong> them on the userâ€™s behalf through <strong>system calls</strong></li></ul></li><li><p>Switching Processes</p><ul><li><img src="/2020/10/10/Process/Screen Shot 2020-12-21 at 3.42.30 PM.png" style="zoom:50%;"></li><li><p>1  Save process state (program counter, registers)</p></li><li><p>2  Update PCB (running -&gt; ready)</p></li><li><p>3  Move PCB to appropriate queue (ready/blocked)</p></li><li><p>4  Run scheduler, select new process</p></li><li><p>5  Update to running state in PCB</p></li><li><p>6  Update memory structures</p></li><li><p>7  Restore process</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> class notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>äºŒå‰æ ‘æœ‰å…³ç®—æ³•</title>
      <link href="2020/09/16/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9C%89%E5%85%B3%E7%AE%97%E6%B3%95/"/>
      <url>2020/09/16/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9C%89%E5%85%B3%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h4 id="1-äºŒå‰æ ‘å®šä¹‰-java"><a href="#1-äºŒå‰æ ‘å®šä¹‰-java" class="headerlink" title="1. äºŒå‰æ ‘å®šä¹‰(java)"></a>1. äºŒå‰æ ‘å®šä¹‰(java)</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// Definition for a binary tree node.</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TreeNode</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> val<span class="token punctuation">;</span>  TreeNode left<span class="token punctuation">;</span>  TreeNode right<span class="token punctuation">;</span>  <span class="token function">TreeNode</span><span class="token punctuation">(</span><span class="token keyword">int</span> x<span class="token punctuation">)</span> <span class="token punctuation">{</span> val <span class="token operator">=</span> x<span class="token punctuation">;</span> <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-äºŒå‰æ ‘ç¿»è½¬"><a href="#2-äºŒå‰æ ‘ç¿»è½¬" class="headerlink" title="2. äºŒå‰æ ‘ç¿»è½¬"></a>2. äºŒå‰æ ‘ç¿»è½¬</h4><img src="/2020/09/16/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9C%89%E5%85%B3%E7%AE%97%E6%B3%95/æˆªå±2020-09-16 ä¸‹åˆ4.04.19.png" style="zoom:50%;"><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//ç®€å•é€’å½’å³å¯å®ç°</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">{</span>  <span class="token keyword">public</span> TreeNode <span class="token function">invertTree</span><span class="token punctuation">(</span>TreeNode root<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>root <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token keyword">return</span> null<span class="token punctuation">;</span>    TreeNode left <span class="token operator">=</span> <span class="token function">invertTree</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>left<span class="token punctuation">)</span><span class="token punctuation">;</span>    TreeNode right <span class="token operator">=</span> <span class="token function">invertTree</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>right<span class="token punctuation">)</span><span class="token punctuation">;</span>    root<span class="token punctuation">.</span>right <span class="token operator">=</span> left<span class="token punctuation">;</span>    root<span class="token punctuation">.</span>left <span class="token operator">=</span> right<span class="token punctuation">;</span>    <span class="token keyword">return</span> root<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// å½“ç„¶è¿˜å¯ä»¥ç”¨å››ç§éå†æ¥è§£å†³è¿™é“é¢˜</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> å­¦ä¹ ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
            <tag> æœªå®Œå¾…ç»­ </tag>
            
            <tag> Java </tag>
            
            <tag> æ•°æ®ç»“æ„ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ’åºæ–¹æ³•æ±‡æ€»</title>
      <link href="2020/09/15/%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"/>
      <url>2020/09/15/%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h4 id="1-å†’æ³¡æ’åº"><a href="#1-å†’æ³¡æ’åº" class="headerlink" title="1. å†’æ³¡æ’åº"></a>1. å†’æ³¡æ’åº</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span><span class="token punctuation">{</span>  <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">BubbleSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// æ•´æ•°æ•°ç»„å‡åº</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> i<span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>          nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>          nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ç¬¬ä¸€æ¬¡å¾ªç¯ï¼Œé€šè¿‡ä¾æ¬¡æ¯”è¾ƒç›¸é‚»å…ƒç´ ï¼Œè‹¥å‰ä¸€ä¸ªå¤§äºåä¸€ä¸ªåˆ™äº¤æ¢ä½ç½®ï¼Œå¾ªç¯ç»“æŸåï¼Œæ•°ç»„å†…æœ€å¤§å€¼å°†ä½äºæ•°ç»„æœ€åä¸€ä¸ªä½ç½®ï¼›ç¬¬äºŒæ¬¡å¾ªç¯ï¼Œä¹Ÿä¾æ¬¡æ¯”è¾ƒç›¸é‚»å…ƒç´ ï¼Œé™¤äº†æœ€åä¸€å¯¹ï¼ˆå› ä¸ºæœ€åä¸€ä¸ªæ˜¯æœ€å¤§å€¼ï¼Œå‰ä¸€ä¸ªè‚¯å®šæ¯”åä¸€ä¸ªå°ï¼‰,å¾ªç¯ç»“æŸæ•°ç»„å†…å€’æ•°ç¬¬äºŒå¤§çš„å€¼å°†ä½äºæ•°ç»„å€’æ•°ç¬¬äºŒä¸ªä½ç½®ï¼›â€¦â€¦ç›´åˆ°æ²¡æœ‰ä¸€å¯¹æ•°å­—éœ€è¦æ¯”è¾ƒï¼Œæ­¤æ—¶æ•°ç»„ä»¥å‡åºæ’åˆ—ã€‚</p><p>å†’æ³¡æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n<sup>2</sup>)ï¼Œç©ºé—´å¤æ‚åº¦ä¸ºO(1)ï¼Œè®¡ç®—æ–¹æ³•è¯·å‚è§â€œ<a href="https://scycy2.github.io/2020/07/29/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/">ç®—æ³•å¤æ‚åº¦</a>â€ä¸€æ–‡ã€‚</p><h4 id="2-é€‰æ‹©æ’åº"><a href="#2-é€‰æ‹©æ’åº" class="headerlink" title="2. é€‰æ‹©æ’åº"></a>2. é€‰æ‹©æ’åº</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span><span class="token punctuation">{</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">SelectionSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">int</span> minIndex <span class="token operator">=</span> i<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// è®°å½•æœ€å°å€¼çš„ä¸‹æ ‡</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length<span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>minIndex<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          minIndex <span class="token operator">=</span> j<span class="token punctuation">;</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span>      <span class="token comment" spellcheck="true">// äº¤æ¢æœ€å°å€¼å’Œå½“å‰ä½ç½®</span>      <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>      nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>minIndex<span class="token punctuation">]</span><span class="token punctuation">;</span>      nums<span class="token punctuation">[</span>minIndex<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ç¬¬ä¸€æ¬¡å¾ªç¯æ‰¾å‡ºå½“å‰æ•°ç»„æœ€å°å€¼çš„ä¸‹æ ‡ï¼Œå¹¶æ”¾åˆ°æ•°ç»„å¼€å¤´ï¼›ç¬¬äºŒæ¬¡å¾ªç¯æ‰¾å‡ºé™¤äº†æ•°ç»„ç¬¬ä¸€ä¸ªå€¼çš„æ•°ç»„æœ€å°å€¼ï¼Œå¹¶äº¤æ¢åˆ°ç¬¬äºŒä¸ªä½ç½®ï¼›â€¦â€¦ç›´åˆ°æ•°ç»„æœ€åä¸¤ä¸ªå€¼æ¯”è¾ƒï¼ˆå¹¶äº¤æ¢ï¼‰ï¼Œæ­¤æ—¶æ•°ç»„æŒ‰ä»å°åˆ°å¤§é¡ºåºæ’åˆ—ã€‚</p><p>é€‰æ‹©æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n<sup>2</sup>)ï¼Œç©ºé—´å¤æ‚åº¦ä¸ºO(1)ã€‚</p><h4><span id="3">3. ç›´æ¥æ’å…¥æ’åº</span></h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span><span class="token punctuation">{</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">InsertionSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// å½“å‰å€¼ä¸å‰é¢å·²æ’å¥½åºçš„å€¼æ¯”è¾ƒ</span>      <span class="token keyword">int</span> j<span class="token punctuation">;</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span>j <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> j <span class="token operator">>=</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> temp<span class="token punctuation">;</span> <span class="token operator">--</span>j<span class="token punctuation">)</span> <span class="token punctuation">{</span>        nums<span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// å¦‚æœå½“å‰å€¼å°äºå‰é¢çš„å€¼ï¼Œåˆ™å°†å‰é¢çš„å€¼å‘åç§»</span>      <span class="token punctuation">}</span>      nums<span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// ç›´åˆ°å½“å‰å€¼å¤§äºç­‰äºå‰é¢çš„æŸä¸ªå€¼æˆ–è€…å‰é¢æ²¡æœ‰å€¼çš„æ—¶å€™ï¼Œå°†è¯¥å€¼æ’å…¥</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ç¬¬ä¸€æ¬¡å¾ªç¯ï¼Œè·å–å½“å‰å€¼temp=nums[1]ï¼Œå°†tempä¸nums[0]æ¯”è¾ƒï¼Œè‹¥å°äºnums[0]ï¼Œå°†nums[0]çš„å€¼å¾€åç§»å˜ä¸ºnums[1]ï¼Œç„¶åtempæ’å…¥åˆ°nums[1]å‰å³nums[0]çš„ä½ç½®ï¼›ç¬¬äºŒæ¬¡å¾ªç¯ï¼ˆå‰ä¸¤ä¸ªå€¼å·²æ’å¥½åºï¼‰ï¼Œè·å–temp=nums[2]ï¼Œå…ˆä¸nums[1]æ¯”è¾ƒï¼Œè‹¥å¤§äºåˆ™ä¸å˜ï¼Œå°äºåˆ™å°†nums[1]çš„å€¼å¾€åç§»å˜ä¸ºnums[2]ï¼Œå†æ¯”è¾ƒtempä¸nums[0]å¹¶é‡å¤ä¹‹å‰çš„è¿‡ç¨‹ï¼›â€¦â€¦æœ€ç»ˆæ•°ç»„ä»¥å‡åºæ’åºã€‚</p><p>æ’å…¥æ’åºçš„ç©ºé—´å¤æ‚åº¦ä¸ºO(1)ï¼Œæ—¶é—´å¤æ‚åº¦åˆ™ä¸åŸæ•°ç»„æ’åˆ—é¡ºåºæœ‰å…³ï¼Œå¦‚æœåŸæ•°ç»„å·²æŒ‰å‡åºæ’åºï¼Œåˆ™è¯¥ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n)ï¼ˆæœ€å¥½çš„æƒ…å†µï¼‰ï¼›è‹¥æŒ‰é™åºæ’åˆ—ï¼Œåˆ™æ—¶é—´å¤æ‚åº¦ä¸ºO(n<sup>2</sup>)ï¼ˆæœ€å·®çš„æƒ…å†µï¼‰ã€‚</p><h4 id="4-å¿«é€Ÿæ’åº"><a href="#4-å¿«é€Ÿæ’åº" class="headerlink" title="4. å¿«é€Ÿæ’åº"></a>4. å¿«é€Ÿæ’åº</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span><span class="token punctuation">{</span>  <span class="token comment" spellcheck="true">// startä¸ºå¾…æ’åºæ•°ç»„å¼€å§‹çš„ä¸‹æ ‡ï¼Œendä¸ºç»“æŸä¸‹æ ‡</span>  <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">quickSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">,</span> <span class="token keyword">int</span> start<span class="token punctuation">,</span> <span class="token keyword">int</span> end<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> pivot <span class="token operator">=</span> nums<span class="token punctuation">[</span>start<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// å–æ•°ç»„æŸä¸ªå€¼(æ­¤å¤„é€‰ç¬¬ä¸€ä¸ªå€¼)ä½œä¸ºå‚ç…§ï¼Œæ¯”å®ƒå°çš„æ”¾åœ¨å®ƒå·¦è¾¹ï¼Œå¤§çš„æ”¾åœ¨å³è¾¹</span>    <span class="token keyword">int</span> i <span class="token operator">=</span> start<span class="token punctuation">;</span>    <span class="token keyword">int</span> j <span class="token operator">=</span> end<span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> pivot<span class="token punctuation">)</span> <span class="token punctuation">{</span>        j<span class="token operator">--</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// ä»å³å¾€å·¦ï¼Œæœ¬å°±æ¯”å‚ç…§å¤§çš„æ•°åˆ™ä¸åŠ¨</span>      <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> j <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;</span> pivot<span class="token punctuation">)</span> <span class="token punctuation">{</span>        i<span class="token operator">++</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// ä»å·¦å¾€å³ï¼Œæœ¬å°±æ¯”å‚ç…§å°çš„æ•°ä¸åŠ¨</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&amp;&amp;</span> i <span class="token operator">&lt;</span> j<span class="token punctuation">)</span> <span class="token punctuation">{</span>        i<span class="token operator">++</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// äº¤æ¢</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>        nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">></span> start<span class="token punctuation">)</span> nums <span class="token operator">=</span> <span class="token function">quickSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> start<span class="token punctuation">,</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token keyword">if</span> <span class="token punctuation">(</span>j <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&lt;</span> end<span class="token punctuation">)</span> nums <span class="token operator">=</span> <span class="token function">quickSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> nums<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ç¬¬ä¸€è¶Ÿæ’åºå°†æ•°ç»„åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†å°äºå‚ç…§å€¼ï¼Œå¦ä¸€éƒ¨åˆ†åˆ™å¤§äºå‚ç…§å€¼ï¼›å†åˆ†åˆ«å¯¹ä¸¤éƒ¨åˆ†è¿›è¡Œæ’åºï¼ˆé€’å½’ï¼‰ã€‚å½“ä¸¤éƒ¨åˆ†éƒ½æœ‰åºæ—¶ï¼Œåˆ™æ•´ä¸ªæ•°ç»„éƒ½ä¸ºæœ‰åºçŠ¶æ€ã€‚</p><p>å¿«é€Ÿæ’åºçš„ç©ºé—´å¤æ‚åº¦ä¸ºO(1)ï¼Œå…¶æ—¶é—´å¤æ‚åº¦ä¸é€‰å–çš„å‚ç…§æœ‰å…³ï¼Œè‹¥æ¯æ¬¡é€‰å–çš„å‚ç…§å¯ä½¿æ•°ç»„ç­‰åˆ†ï¼Œåˆ™ç»è¿‡log<sub>2</sub>nèººåˆ’åˆ†ï¼Œå¯å®Œæˆæ’åºï¼Œæ­¤æ—¶æ—¶é—´å¤æ‚åº¦ä¸ºO(nlog<sub>2</sub>n)ï¼›è‹¥æ¯æ¬¡é€‰å–çš„å‚ç…§ä¸ºæœ€å¤§å€¼æˆ–æœ€å°å€¼ï¼Œåˆ™éœ€è¦ç»è¿‡nèººåˆ’åˆ†ï¼Œå¯å®Œæˆæ’åºï¼Œæ­¤æ—¶æ—¶é—´å¤æ‚åº¦ä¸ºO(n<sup>2</sup>)ã€‚</p><h4 id="5-å¸Œå°”æ’åº"><a href="#5-å¸Œå°”æ’åº" class="headerlink" title="5. å¸Œå°”æ’åº"></a>5. å¸Œå°”æ’åº</h4><p>å¸Œå°”æ’åºæ˜¯æ’å…¥æ’åºçš„ä¸€ç§ï¼Œåˆç§°â€œç¼©å°å¢é‡æ’åºâ€ã€‚</p><p>å¸Œå°”æ’åºå°±æ˜¯å°†æ•°ç»„æ ¹æ®ä¸‹æ ‡çš„ä¸€å®šå¢é‡åˆ†ç»„ï¼Œç„¶åå¯¹æ¯ä¸€ç»„è¿›è¡Œç›´æ¥æ’å…¥æ’åºï¼›éšåå¢é‡å‡å°‘ï¼Œæ¯æ¬¡å¢é‡ä¸åŒï¼Œéƒ½è¿›è¡Œä¸€æ¬¡ç›´æ¥æ’å…¥æ’åºï¼Œç›´åˆ°å¢é‡ä¸º1ï¼Œæ­¤æ—¶å°±æ˜¯ä¸Šé¢æ‰€æåˆ°çš„<a href="#3">ç›´æ¥æ’å…¥æ’åº</a>ã€‚</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">shellSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span>length<span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> step <span class="token operator">=</span> n <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span> step <span class="token operator">>=</span> <span class="token number">1</span><span class="token punctuation">;</span> step <span class="token operator">/=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// æ­¥é•¿</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> step<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// å†…å¾ªç¯ä¸¤å±‚ä¸ºæ’å…¥æ’åº</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> j <span class="token operator">=</span> i <span class="token operator">-</span> step<span class="token punctuation">;</span>          <span class="token keyword">while</span> <span class="token punctuation">(</span>j <span class="token operator">>=</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> temp<span class="token punctuation">)</span> <span class="token punctuation">{</span>            nums<span class="token punctuation">[</span>j <span class="token operator">+</span> step<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>          j <span class="token operator">-=</span> step<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        nums<span class="token punctuation">[</span>j <span class="token operator">+</span> step<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>      <span class="token punctuation">}</span>       <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ç¬¬ä¸€æ¬¡å¾ªç¯å¢é‡ï¼ˆæ­¥é•¿ï¼‰stepä¸ºæ•°ç»„é•¿åº¦nçš„ä¸€åŠï¼Œæ­¤æ—¶æ ¹æ®å¢é‡å°†æ•°ç»„åˆ†ä¸ºn/2ç»„ï¼Œåˆ†åˆ«ä¸º(nums[0], nums[step])ï¼Œ(nums[1], nums[1+step])ï¼Œâ€¦â€¦(nums[step-1], nums[2*step-1])ï¼Œç„¶åå¯¹æ¯ç»„è¿›è¡Œç›´æ¥æ’å…¥æ’åºï¼›ç¬¬äºŒæ¬¡å¾ªç¯å¢é‡å†å‡åŠï¼Œæ ¹æ®å¢é‡æ•°ç»„å¯åˆ†ä¸ºå¤šç»„ï¼Œå†å¯¹å„ç»„è¿›è¡Œç›´æ¥æ’å…¥æ’åºï¼›â€¦â€¦æœ€åå¢é‡ä¸º1ï¼Œå³æ™®é€šçš„ç›´æ¥æ’å…¥æ’åºã€‚</p><p>å¸Œå°”æ’åºçš„ç©ºé—´å¤æ‚åº¦ä¸ºO(1)ï¼Œä½†æ—¶é—´å¤æ‚åº¦å¾ˆéš¾è®¡ç®—ï¼ŒæŸ¥é˜…èµ„æ–™åå¯å¾—å¸Œå°”æ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸ºO(n<sup>3/2</sup>)ï¼ˆæ³¨æ„è¿™é‡Œæ˜¯<strong>å¹³å‡</strong>)ã€‚</p><p>å¸Œå°”æ’åºè¾ƒç›´æ¥æ’å…¥æ’åºå¿«æ˜¯å› ä¸ºå½“å¢é‡å¤§æ—¶ï¼Œè¿›è¡Œç›´æ¥æ’å…¥æ’åºçš„å…ƒç´ å°‘ï¼Œé€Ÿåº¦å¿«ï¼›å½“å¢é‡é€æ¸å‡å°‘ï¼Œæ­¤æ—¶æ•°ç»„å·²åŸºæœ¬æœ‰åºï¼Œæ­¤æ—¶ç›´æ¥æ’å…¥æ’åºå¯¹åŸºæœ¬æœ‰åºçš„åºåˆ—æ’åºæ•ˆç‡å¾ˆé«˜ã€‚</p><p>è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­æ¥è‡ªç»´åŸºç™¾ç§‘ï¼ˆä¸ªäººè®¤ä¸ºç»´åŸºç™¾ç§‘å°†æ­¤è¿‡ç¨‹é€šè¿‡åˆ—æ¥è¡¨è¾¾æ›´åŠ æ¸…æ™°æ˜“æ‡‚ï¼‰</p><p>æ­¤å¤„å¾…è¡¥å……ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚</p><h4>6. å½’å¹¶æ’åº</h4><p>å½’å¹¶æ’åºæ˜¯å»ºç«‹åœ¨å½’å¹¶æ“ä½œä¸Šçš„ä¸€ç§æœ‰æ•ˆçš„ã€ç¨³å®šçš„æ’åºç®—æ³•ï¼Œè¯¥ç®—æ³•é‡‡ç”¨äº†åˆ†æ²»æ³•(Divide and Conquer)ã€‚</p><p>å°†å·²æœ‰åºçš„å­åºåˆ—åˆå¹¶ï¼Œå¾—åˆ°å®Œå…¨æœ‰åºçš„åºåˆ—ï¼›å³å…ˆä½¿æ¯ä¸ªå­åºåˆ—æœ‰åºï¼Œå†ä½¿å­åºåˆ—æ®µé—´æœ‰åºã€‚</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span><span class="token punctuation">{</span>  <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">mergeSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> temp<span class="token punctuation">,</span> <span class="token keyword">int</span> start<span class="token punctuation">,</span> <span class="token keyword">int</span> end<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>start <span class="token operator">&lt;</span> end<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">int</span> mid <span class="token operator">=</span> <span class="token punctuation">(</span>start <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span>      <span class="token function">mergeSort</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span> temp<span class="token punctuation">,</span> start<span class="token punctuation">,</span> mid<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token function">mergeSort</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span> temp<span class="token punctuation">,</span> mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">merge</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span> temp<span class="token punctuation">,</span> start<span class="token punctuation">,</span> mid<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">merge</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> temp<span class="token punctuation">,</span> <span class="token keyword">int</span> start<span class="token punctuation">,</span> <span class="token keyword">int</span> mid<span class="token punctuation">,</span> <span class="token keyword">int</span> end<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> i <span class="token operator">=</span> start<span class="token punctuation">;</span>    <span class="token keyword">int</span> j <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> k <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;=</span> mid <span class="token operator">&amp;&amp;</span> j <span class="token operator">&lt;=</span> end<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> arr<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        temp<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token operator">++</span>i<span class="token punctuation">;</span>      <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>        temp<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> arr<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token operator">++</span>j<span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token operator">++</span>k<span class="token punctuation">;</span>    <span class="token punctuation">}</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;=</span> mid<span class="token punctuation">)</span> <span class="token punctuation">{</span>      temp<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>      <span class="token operator">++</span>i<span class="token punctuation">;</span>      <span class="token operator">++</span>k<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>j <span class="token operator">&lt;=</span> end<span class="token punctuation">)</span> <span class="token punctuation">{</span>      temp<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> arr<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>      <span class="token operator">++</span>j<span class="token punctuation">;</span>      <span class="token operator">++</span>k<span class="token punctuation">;</span>    <span class="token punctuation">}</span>        System<span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> arr<span class="token punctuation">,</span> start <span class="token operator">+</span> <span class="token number">0</span><span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4>7. å †æ’åº</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Sort</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">heapSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token punctuation">(</span>arr<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span> i <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">--</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token function">adjustHeap</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span> i<span class="token punctuation">,</span> arr<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> arr<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">--</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">int</span> temp  <span class="token operator">=</span> arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>            arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>            <span class="token function">adjustHeap</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>      <span class="token comment" spellcheck="true">//è°ƒæ•´æˆæœ€å¤§å †</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">adjustHeap</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr<span class="token punctuation">,</span> <span class="token keyword">int</span> parent<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> arr<span class="token punctuation">[</span>parent<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> leftNode <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> parent <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>leftNode <span class="token operator">&lt;</span> length<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">int</span> rightNode <span class="token operator">=</span> leftNode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>rightNode <span class="token operator">&lt;</span> length <span class="token operator">&amp;&amp;</span> arr<span class="token punctuation">[</span>leftNode<span class="token punctuation">]</span> <span class="token operator">&lt;</span> arr<span class="token punctuation">[</span>rightNode<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                leftNode<span class="token operator">++</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>temp <span class="token operator">>=</span> arr<span class="token punctuation">[</span>leftNode<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            arr<span class="token punctuation">[</span>parent<span class="token punctuation">]</span> <span class="token operator">=</span> arr<span class="token punctuation">[</span>leftNode<span class="token punctuation">]</span><span class="token punctuation">;</span>            parent <span class="token operator">=</span> leftNode<span class="token punctuation">;</span>            leftNode <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> leftNode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        arr<span class="token punctuation">[</span>parent<span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> è‡ªå­¦ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
            <tag> æœªå®Œå¾…ç»­ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>äºŒå‰æ ‘å››ç§éå†æ–¹å¼</title>
      <link href="2020/09/13/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%9B%9B%E7%A7%8D%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F/"/>
      <url>2020/09/13/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%9B%9B%E7%A7%8D%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h4 id="1-äºŒå‰æ ‘å®šä¹‰-java"><a href="#1-äºŒå‰æ ‘å®šä¹‰-java" class="headerlink" title="1. äºŒå‰æ ‘å®šä¹‰(java)"></a>1. äºŒå‰æ ‘å®šä¹‰(java)</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// Definition for a binary tree node.</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TreeNode</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> val<span class="token punctuation">;</span>  TreeNode left<span class="token punctuation">;</span>  TreeNode right<span class="token punctuation">;</span>  <span class="token function">TreeNode</span><span class="token punctuation">(</span><span class="token keyword">int</span> x<span class="token punctuation">)</span> <span class="token punctuation">{</span> val <span class="token operator">=</span> x<span class="token punctuation">;</span> <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-å‰ã€ä¸­ã€ååºéå†-é€’å½’ç‰ˆ"><a href="#2-å‰ã€ä¸­ã€ååºéå†-é€’å½’ç‰ˆ" class="headerlink" title="2. å‰ã€ä¸­ã€ååºéå†(é€’å½’ç‰ˆ)"></a>2. å‰ã€ä¸­ã€ååºéå†(é€’å½’ç‰ˆ)</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>  <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Integer<span class="token operator">></span> <span class="token function">preorderTraversal</span><span class="token punctuation">(</span>TreeNode root<span class="token punctuation">)</span> <span class="token punctuation">{</span>    List<span class="token operator">&lt;</span>Integer<span class="token operator">></span> res <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">helper</span><span class="token punctuation">(</span>root<span class="token punctuation">,</span> res<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> res<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">helper</span><span class="token punctuation">(</span>TreeNode root<span class="token punctuation">,</span> List <span class="token operator">&lt;</span>Integer<span class="token operator">></span> res<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>root <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token comment" spellcheck="true">// res.add(root.val); // å‰åºéå†ï¼Œå…ˆå°†rootçš„å€¼åŠ å…¥Listä¸­</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>root<span class="token punctuation">.</span>left <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token function">helper</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>left<span class="token punctuation">,</span> res<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token comment" spellcheck="true">// res.add(root.val); // ä¸­åºéå†ï¼Œå…ˆå°†å·¦è¾¹èŠ‚ç‚¹çš„å€¼åŠ å…¥Listä¸­ï¼Œå†åŠ å…¥rootçš„å€¼</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>root<span class="token punctuation">.</span>right <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>          <span class="token function">helper</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>right<span class="token punctuation">,</span> res<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token comment" spellcheck="true">// res.add(root.val); // ååºéå†ï¼Œå…ˆå°†å·¦å³èŠ‚ç‚¹çš„å€¼åŠ å…¥Listä¸­ï¼Œæœ€ååŠ å…¥rootçš„å€¼</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-å‰ã€ä¸­ã€ååºéå†-è¿­ä»£ç‰ˆ"><a href="#3-å‰ã€ä¸­ã€ååºéå†-è¿­ä»£ç‰ˆ" class="headerlink" title="3. å‰ã€ä¸­ã€ååºéå†(è¿­ä»£ç‰ˆ)"></a>3. å‰ã€ä¸­ã€ååºéå†(è¿­ä»£ç‰ˆ)</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//å‰åº</span><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Integer<span class="token operator">></span> <span class="token function">preorderTraversal</span><span class="token punctuation">(</span>TreeNode root<span class="token punctuation">)</span> <span class="token punctuation">{</span>      List<span class="token operator">&lt;</span>Integer<span class="token operator">></span> ans <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LinkedList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>root <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">return</span> ans<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    LinkedList<span class="token operator">&lt;</span>TreeNode<span class="token operator">></span> stack <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LinkedList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// éœ€è¦ä¸æ–­çš„å¢åˆ ï¼Œå› æ­¤ç”¨LinkedList</span>    stack<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>root<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>nodes<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      TreeNode n <span class="token operator">=</span> stack<span class="token punctuation">.</span><span class="token function">pollLast</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//æ ¹æ®stackå…ˆè¿›åå‡ºçš„åŸåˆ™ï¼Œå…ˆä»ä¸Šåˆ°ä¸‹è·å–æ‰€æœ‰å·¦èŠ‚ç‚¹çš„å€¼ï¼Œå†å¾€å³è·å–æ‰€æœ‰å³èŠ‚ç‚¹çš„å€¼</span>      ans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>n<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>n<span class="token punctuation">.</span>right <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>        stack<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>n<span class="token punctuation">.</span>right<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>n<span class="token punctuation">.</span>left <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>        stack<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>n<span class="token punctuation">.</span>left<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>        <span class="token keyword">return</span> ans<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// ä¸­åº</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-å±‚æ¬¡éå†"><a href="#4-å±‚æ¬¡éå†" class="headerlink" title="4. å±‚æ¬¡éå†"></a>4. å±‚æ¬¡éå†</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>  <span class="token keyword">public</span> List<span class="token operator">&lt;</span>List<span class="token operator">&lt;</span>Integer<span class="token operator">>></span> <span class="token function">levelOrder</span> <span class="token punctuation">(</span>TreeNode root<span class="token punctuation">)</span> <span class="token punctuation">{</span>    ArrayList<span class="token operator">&lt;</span>ArrayList<span class="token operator">&lt;</span>Integer<span class="token operator">>></span> ans <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Queue<span class="token operator">&lt;</span>TreeNode<span class="token operator">></span> queue <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LinkedList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    ArrayList<span class="token operator">&lt;</span>Integer<span class="token operator">></span> layer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>root <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>      queue<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>root<span class="token punctuation">)</span><span class="token punctuation">;</span>      layer<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">;</span>      ans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>queue<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      layer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">int</span> size <span class="token operator">=</span> queue<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        TreeNode temp <span class="token operator">=</span> queue<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>temp<span class="token punctuation">.</span>left <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>          queue<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>temp<span class="token punctuation">.</span>left<span class="token punctuation">)</span><span class="token punctuation">;</span>          layer<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>temp<span class="token punctuation">.</span>left<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>temp<span class="token punctuation">.</span>right <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>          queue<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>temp<span class="token punctuation">.</span>right<span class="token punctuation">)</span><span class="token punctuation">;</span>          layer<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>temp<span class="token punctuation">.</span>right<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>layer<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        ans<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> ans<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> è‡ªå­¦ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
            <tag> æœªå®Œå¾…ç»­ </tag>
            
            <tag> Java </tag>
            
            <tag> æ•°æ®ç»“æ„ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç®—æ³•å¤æ‚åº¦</title>
      <link href="2020/07/29/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/"/>
      <url>2020/07/29/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<h3 id="1-æ—¶é—´å¤æ‚åº¦"><a href="#1-æ—¶é—´å¤æ‚åº¦" class="headerlink" title="1. æ—¶é—´å¤æ‚åº¦"></a>1. æ—¶é—´å¤æ‚åº¦</h3><h4 id="1-1-å¤§Oè¡¨ç¤ºæ³•ï¼š"><a href="#1-1-å¤§Oè¡¨ç¤ºæ³•ï¼š" class="headerlink" title="1.1 å¤§Oè¡¨ç¤ºæ³•ï¼š"></a>1.1 å¤§Oè¡¨ç¤ºæ³•ï¼š</h4><p>ç”¨O(n)æ¥ä½“ç°ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ã€‚</p><p>å¤§Oè¡¨ç¤ºæ³•O(f(n))ä¸­f(n)å¯ä»¥æ˜¯1ã€n<sup>2</sup>ã€lognç­‰ï¼Œæ¥ä¸‹æ¥çœ‹çœ‹å¦‚ä½•æ¨å€’å¤§Oé˜¶ã€‚</p><h4 id="1-2-æ¨å¯¼å¤§Oé˜¶è§„åˆ™ï¼š"><a href="#1-2-æ¨å¯¼å¤§Oé˜¶è§„åˆ™ï¼š" class="headerlink" title="1.2 æ¨å¯¼å¤§Oé˜¶è§„åˆ™ï¼š"></a>1.2 æ¨å¯¼å¤§Oé˜¶è§„åˆ™ï¼š</h4><p>a. <strong>ç”¨1æ¥ä»£æ›¿è¿è¡Œæ—¶é—´ä¸­çš„æ‰€æœ‰åŠ æ³•å¸¸æ•°</strong></p><p>b. <strong>f(n)è‹¥æ˜¯å¤šé¡¹å¼ï¼Œåªä¿ç•™æœ€é«˜é˜¶é¡¹å³å¯</strong></p><p>c. <strong>å»æ‰æœ€é«˜é˜¶é¡¹ç³»æ•°</strong></p><h4 id="1-3"><a href="#1-3" class="headerlink" title="1.3"></a>1.3</h4><ul><li><p>å¸¸æ•°é˜¶</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"O"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>i<span class="token operator">--</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//æ¯ä¸€å¥éƒ½åªæ‰§è¡Œä¸€æ¬¡</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>è¿™æ®µä»£ç æ‰§è¡Œæ¬¡æ•°ä¸º4æ¬¡ï¼Œæ ¹æ®è§„åˆ™aï¼Œå…¶æ—¶é—´å¤æ‚åº¦ä¸ºO(1)ã€‚</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    i<span class="token operator">++</span><span class="token punctuation">;</span><span class="token punctuation">}</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>è¿™æ®µä»£ç è™½ç„¶å¾ªç¯äº†100æ¬¡ï¼Œä½†å®ƒçš„æ—¶é—´å¤æ‚åº¦ä¾ç„¶ä¸ºO(1)ï¼Œå› ä¸ºå®ƒçš„æ‰§è¡Œæ¬¡æ•°åªæ˜¯ä¸€ä¸ªè¾ƒå¤§çš„å¸¸æ•°.</p></li><li><p>çº¿æ€§é˜¶</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>æ­¤æ®µä»£ç ä¸ºforå¾ªç¯ï¼Œå…¶ä¸­<code>int i = 0</code>åªæ‰§è¡Œä¸€æ¬¡ï¼Œ<code>i &lt; n</code>æ‰§è¡Œnæ¬¡ï¼Œ<code>i++</code>æ‰§è¡Œnæ¬¡ï¼Œæ‰“å°è¯­å¥ä¹Ÿæ‰§è¡Œäº†næ¬¡ï¼Œå› æ­¤è¿™æ®µä»£ç æ‰§è¡Œæ¬¡æ•°ä¸º3n+1ï¼Œæ ¹æ®è§„åˆ™ï¼ŒT(n) = O(n)ã€‚</p></li><li><p>å¯¹æ•°é˜¶</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//æ‰§è¡Œä¸€æ¬¡</span><span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>     i <span class="token operator">*=</span> <span class="token number">2</span><span class="token punctuation">;</span><span class="token punctuation">}</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//æ‰§è¡Œä¸€æ¬¡</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ä¸­é—´å¾ªç¯ä½“<code>i &lt; n</code>ä»¥åŠ<code>i *= 2</code>éƒ½åˆ†åˆ«æ‰§è¡Œäº†log<sub>2</sub>næ¬¡ï¼Œå› ä¸ºiæ¯æ¬¡ç¿»å€å¢åŠ ï¼Œé€šè¿‡è®¡ç®—å¯çŸ¥ä¸­é—´å¾ªç¯ä½“å¾ªç¯äº†log<sub>2</sub>næ¬¡ï¼Œä¸€æ¬¡è¿™æ®µä»£ç æ‰§è¡Œæ¬¡æ•°ä¸º1+2log<sub>2</sub>nï¼Œæ ¹æ®è§„åˆ™ï¼ŒT(n) = O(logn)ã€‚</p></li><li><p>å¹³æ–¹é˜¶</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// for (int j = 0; j &lt; i + 1; j++)</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> j<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>æœ€å†…å±‚å¾ªç¯ä½“æ‰§è¡Œæ¬¡æ•°ä¸ºxn<sup>2</sup>(xä¸ºæŸå¸¸æ•°)ï¼Œå¯å¾—è¯¥æ®µä»£ç æ‰§è¡Œæ¬¡æ•°æœ€é«˜é˜¶é¡¹ä¸ºxn<sup>2</sup>ï¼Œæ ¹æ®è§„åˆ™ï¼ŒT(n) = O(n<sup>2</sup>)ã€‚</p><p>åŒæ ·å¯å¾—ç«‹æ–¹é˜¶ï¼Œå››æ¬¡æ–¹é˜¶â€¦â€¦</p></li><li><p>ç¢°åˆ°çš„è¾ƒå¤æ‚çš„ç®—æ³•å¤æ‚åº¦åˆ†æ</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">/** * Definition for singly-linked list. * public class ListNode { *     int val; *     ListNode next; *     ListNode(int x) { val = x; } * } */</span><span class="token comment" spellcheck="true">//åˆå¹¶Kä¸ªæœ‰åºé“¾è¡¨</span><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> ListNode <span class="token function">mergeKLists</span><span class="token punctuation">(</span>ListNode<span class="token punctuation">[</span><span class="token punctuation">]</span> lists<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>lists<span class="token punctuation">.</span>length <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> null<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        ListNode ans <span class="token operator">=</span> lists<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> lists<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>lists<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token keyword">continue</span><span class="token punctuation">;</span>            ans <span class="token operator">=</span> <span class="token function">mergeTwoLists</span><span class="token punctuation">(</span>ans<span class="token punctuation">,</span> lists<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> ans<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> ListNode <span class="token function">mergeTwoLists</span><span class="token punctuation">(</span>ListNode l1<span class="token punctuation">,</span> ListNode l2<span class="token punctuation">)</span> <span class="token punctuation">{</span>        ListNode head <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ListNode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ListNode curr <span class="token operator">=</span> head<span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>l1 <span class="token operator">!=</span> null <span class="token operator">&amp;&amp;</span> l2 <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>l1<span class="token punctuation">.</span>val <span class="token operator">&lt;=</span> l2<span class="token punctuation">.</span>val<span class="token punctuation">)</span> <span class="token punctuation">{</span>                curr<span class="token punctuation">.</span>next <span class="token operator">=</span> l1<span class="token punctuation">;</span>                curr <span class="token operator">=</span> curr<span class="token punctuation">.</span>next<span class="token punctuation">;</span>                l1 <span class="token operator">=</span> l1<span class="token punctuation">.</span>next<span class="token punctuation">;</span>            <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>                curr<span class="token punctuation">.</span>next <span class="token operator">=</span> l2<span class="token punctuation">;</span>                curr <span class="token operator">=</span> curr<span class="token punctuation">.</span>next<span class="token punctuation">;</span>                l2 <span class="token operator">=</span> l2<span class="token punctuation">.</span>next<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>l1 <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            curr<span class="token punctuation">.</span>next <span class="token operator">=</span> l2<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>l2 <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>            curr<span class="token punctuation">.</span>next <span class="token operator">=</span> l1<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> head<span class="token punctuation">.</span>next<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>é¦–å…ˆåˆ†æ<code>mergeTwoLists</code>å‡½æ•°çš„æ—¶é—´å¤æ‚åº¦ï¼Œå‡è®¾æ¯ä¸ªé“¾è¡¨çš„é•¿åº¦ä¸ºnï¼Œå¯ç®€å•åœ°å¾—å‡ºè¯¥å‡½æ•°çš„T(o) = O(n + n) = O(n) (ä¸ºç®€ä¾¿ï¼Œåªè®¡ç®—å¾ªç¯ä½“æ‰§è¡Œæ¬¡æ•°)ã€‚å†åˆ†æ<code>mergeKLists</code>å‡½æ•°çš„æ—¶é—´å¤æ‚åº¦ï¼ŒåŒæ ·çš„æ¯ä¸ªé“¾è¡¨é•¿åº¦éƒ½ä¸ºnï¼Œç¬¬ä¸€æ¬¡åˆå¹¶å‰ä¸¤ä¸ªé“¾è¡¨ï¼Œæ­¤æ—¶<code>ans</code> çš„é•¿åº¦éƒ½ä¸º2nï¼Œç¬¬xæ¬¡åˆå¹¶åï¼Œé•¿åº¦å˜ä¸ºxnï¼Œç¬¬xæ¬¡çš„æ—¶é—´ä»£ä»·ä¸ºO(n + (x - 1) $\times$ n) = O(x $\times$ n)ï¼Œæ­¤æ—¶æ€»çš„æ—¶é—´ä»£ä»·å¯ç”¨æ±‚å’Œå…¬å¼è®¡ç®—O($\sum_{i=1}^k(i\times n)$) = O($\frac{(1+k)\times k}{2}\times n$) = O(k<sup>2</sup>$\times $n)ï¼Œæ‰€ä»¥æ—¶é—´å¤æ‚åº¦ä¸ºO(k<sup>2</sup> $\times$ n)ã€‚</p></li></ul><h3 id="2-ç©ºé—´å¤æ‚åº¦"><a href="#2-ç©ºé—´å¤æ‚åº¦" class="headerlink" title="2. ç©ºé—´å¤æ‚åº¦"></a>2. ç©ºé—´å¤æ‚åº¦</h3><h4 id="2-1-ç©ºé—´å¤æ‚åº¦æ˜¯å¯¹ä¸€ä¸ªç®—æ³•åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ä¸´æ—¶å ç”¨å­˜å‚¨ç©ºé—´å¤§å°çš„ä¸€ä¸ªé‡åº¦ï¼Œä¸æ—¶é—´å¤æ‚åº¦ä¸€æ ·ååº”çš„æ˜¯ä¸€ä¸ªè¶‹åŠ¿ï¼Œç”¨S-n-æ¥å®šä¹‰ã€‚"><a href="#2-1-ç©ºé—´å¤æ‚åº¦æ˜¯å¯¹ä¸€ä¸ªç®—æ³•åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ä¸´æ—¶å ç”¨å­˜å‚¨ç©ºé—´å¤§å°çš„ä¸€ä¸ªé‡åº¦ï¼Œä¸æ—¶é—´å¤æ‚åº¦ä¸€æ ·ååº”çš„æ˜¯ä¸€ä¸ªè¶‹åŠ¿ï¼Œç”¨S-n-æ¥å®šä¹‰ã€‚" class="headerlink" title="2.1 ç©ºé—´å¤æ‚åº¦æ˜¯å¯¹ä¸€ä¸ªç®—æ³•åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ä¸´æ—¶å ç”¨å­˜å‚¨ç©ºé—´å¤§å°çš„ä¸€ä¸ªé‡åº¦ï¼Œä¸æ—¶é—´å¤æ‚åº¦ä¸€æ ·ååº”çš„æ˜¯ä¸€ä¸ªè¶‹åŠ¿ï¼Œç”¨S(n)æ¥å®šä¹‰ã€‚"></a>2.1 ç©ºé—´å¤æ‚åº¦æ˜¯å¯¹ä¸€ä¸ªç®—æ³•åœ¨è¿è¡Œè¿‡ç¨‹ä¸­ä¸´æ—¶å ç”¨å­˜å‚¨ç©ºé—´å¤§å°çš„ä¸€ä¸ªé‡åº¦ï¼Œä¸æ—¶é—´å¤æ‚åº¦ä¸€æ ·ååº”çš„æ˜¯ä¸€ä¸ªè¶‹åŠ¿ï¼Œç”¨S(n)æ¥å®šä¹‰ã€‚</h4><h4 id="2-2"><a href="#2-2" class="headerlink" title="2.2"></a>2.2</h4><p>ç©ºé—´å¤æ‚åº¦å¸¸ç”¨çš„æœ‰O(1), O(n), O(n<sup>2</sup>)</p><h4 id="2-3"><a href="#2-3" class="headerlink" title="2.3"></a>2.3</h4><ul><li><p>O(1)</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">BubbleSort</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> nums<span class="token punctuation">.</span>length <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> i<span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> temp <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>        nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> temp<span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ç»å…¸çš„å†’æ³¡æ’åºä»¥åŠæ’å…¥æ’åºã€é€‰æ‹©æ’åºç­‰éƒ½æ˜¯ç©ºé—´å¤æ‚åº¦ä¸ºO(1)çš„ç®—æ³•ï¼Œå› ä¸ºå®ƒæ²¡æœ‰ä¸´æ—¶å ç”¨é¢å¤–çš„å­˜å‚¨ç©ºé—´ï¼Œåªåœ¨è‡ªå·±çš„æ•°ç»„é‡Œè¿›è¡Œäº¤æ¢ã€‚</p></li><li><p>O(n)</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">climbStairs</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> dp <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">int</span><span class="token punctuation">[</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        dp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        dp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>n <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> dp<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        dp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>n <span class="token operator">>=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> dp<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> dp<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>è¿™æ˜¯leetcodeä¸Šä¸€é“ç®—æ³•é¢˜ï¼Œéœ€è¦ä½ è®¡ç®—çˆ¬åˆ°né˜¶ä¸”æ¯æ¬¡åªèƒ½çˆ¬1æˆ–2é˜¶æœ‰å¤šå°‘ç§ä¸åŒçš„æ–¹æ³•ã€‚å¾ˆæ˜¾ç„¶è¿™æ˜¯ä¸€é“åŠ¨æ€è§„åˆ’çš„é¢˜ç›®ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥newä¸€ä¸ªæ•°ç»„æ¥ä¿å­˜çˆ¬1ï½né˜¶å„æœ‰å¤šå°‘ç§æ–¹æ³•ï¼Œè€Œåˆ°né˜¶çš„æ–¹æ³•å°±æ˜¯åˆ°n-1é˜¶å’Œåˆ°n-2é˜¶çš„æ–¹æ³•å’Œã€‚è¿™é‡Œæˆ‘ä»¬newäº†ä¸€ä¸ªé•¿åº¦ä¸ºn+1çš„æ•°ç»„ï¼Œç”¨äº†é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨æˆ‘ä»¬éœ€è¦çš„æ•°æ®ï¼Œå› æ­¤ç©ºé—´å¤æ‚åº¦ä¸ºO(n+1) = O(n)ã€‚</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> è‡ªå­¦ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
            <tag> ç®—æ³•å¤æ‚åº¦ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo-theme-materyä¸»é¢˜éƒ¨åˆ†ä¼˜åŒ–</title>
      <link href="2020/07/18/hexo-theme-matery%E4%B8%BB%E9%A2%98%E9%83%A8%E5%88%86%E4%BC%98%E5%8C%96/"/>
      <url>2020/07/18/hexo-theme-matery%E4%B8%BB%E9%A2%98%E9%83%A8%E5%88%86%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>hexo-theme-materyä¸‹è½½ä¸é…ç½®: <a href="https://github.com/blinkfox/hexo-theme-matery">https://github.com/blinkfox/hexo-theme-matery</a></p><h3 id="1-å…³äºä¸ªäººä¿¡æ¯çš„æ·»åŠ åŠä¿®æ”¹ï¼š"><a href="#1-å…³äºä¸ªäººä¿¡æ¯çš„æ·»åŠ åŠä¿®æ”¹ï¼š" class="headerlink" title="1. å…³äºä¸ªäººä¿¡æ¯çš„æ·»åŠ åŠä¿®æ”¹ï¼š"></a>1. å…³äºä¸ªäººä¿¡æ¯çš„æ·»åŠ åŠä¿®æ”¹ï¼š</h3><p>ä»¥è‡ªå·±çš„ä¸ªäººä¿¡æ¯ä½œè¯´æ˜ï¼š</p><p>åŸï¼š<img src="/2020/07/18/hexo-theme-matery%E4%B8%BB%E9%A2%98%E9%83%A8%E5%88%86%E4%BC%98%E5%8C%96/yuan.png" style="zoom:50%;"></p><p>ç°ï¼š</p><img src="/2020/07/18/hexo-theme-matery%E4%B8%BB%E9%A2%98%E9%83%A8%E5%88%86%E4%BC%98%E5%8C%96/PersonalInfo.png" style="zoom:50%;"><p>é¦–å…ˆæ‰¾åˆ°<code>/hexo-theme-matery/layout/about.ejs</code> ï¼Œå¹¶æ‰¾åˆ°ä»£ç å¦‚ä¸‹ï¼š</p><pre class="line-numbers language-js"><code class="language-js"><span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"author"</span><span class="token operator">></span> <span class="token comment" spellcheck="true">//ä½œè€…ä¿¡æ¯</span>    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"post-statis hide-on-large-only"</span> data<span class="token operator">-</span>aos<span class="token operator">=</span><span class="token string">"zoom-in-right"</span><span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/post-statis'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span> <span class="token comment" spellcheck="true">//å¼•ç”¨å¦ä¸€ä¸ªæ–‡ä»¶ï¼Œè¡¨ç¤ºçš„æ˜¯å·¦è¾¹æ–‡ç« ã€åˆ†ç±»ã€æ ‡ç­¾ä»¥åŠä»–ä»¬çš„æ•°é‡</span>    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"title"</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> config<span class="token punctuation">.</span>author <span class="token operator">%</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span> <span class="token comment" spellcheck="true">//ä½œè€…åå­—ï¼Œåœ¨blog/_config.ymlä¸­é…ç½®</span>    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"career"</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> theme<span class="token punctuation">.</span>profile<span class="token punctuation">.</span>career <span class="token operator">%</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span> <span class="token comment" spellcheck="true">//ä½œè€…èŒä¸šï¼Œåœ¨/hexo-theme-matery/layout/about.ejsä¸­é…ç½®</span>    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"social-link hide-on-large-only"</span> data<span class="token operator">-</span>aos<span class="token operator">=</span><span class="token string">"zoom-in-left"</span><span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/social-link'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span> <span class="token comment" spellcheck="true">//å³è¾¹githubã€emailã€QQç­‰çš„é“¾æ¥ï¼Œä¹Ÿå¯è‡ªå·±å‡å°‘æˆ–å¢åŠ </span><span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>å› æ­¤æƒ³è¦ä¿®æ”¹æˆ–å¢åŠ è‡ªå·±çš„ä¿¡æ¯ï¼Œéœ€è¦åœ¨ç›¸åº”çš„é…ç½®æ–‡ä»¶é‡Œè¿›è¡Œä¿®æ”¹æˆ–å¢åŠ ã€‚</p><p>æ¯”å¦‚æˆ‘è‡ªå·±åšçš„ä¿®æ”¹ï¼Œé¦–å…ˆæ‰“å¼€<code>hexo-theme-matery</code>ä¸‹çš„<code>_config.yml</code>æ–‡ä»¶ï¼Œå¹¶æ‰¾åˆ°<code>profile</code>å±æ€§ï¼Œ</p><pre class="line-numbers language-yml"><code class="language-yml">profile:  avatar: /medias/å¤´åƒ.jpg  career: Undergraduate  school: University of Nottingham Ningbo China (UNNC)  major: Computer Science with Artificial Intelligence (4+0)  introduction: If you wish to succeed, you should use persistence as your good friend, experience as your reference, prudence as your brother and hope as your sentry.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>åœ¨<code>profile</code>é‡Œä¿®æ”¹äº†å¤´åƒï¼ŒèŒä¸šï¼Œä»¥åŠæ–°å¢äº†å­¦æ ¡å’Œä¸“ä¸šã€‚</p><p>é‚£ä¹ˆè¯¥å¦‚ä½•å°†è¿™äº›ç‰¹æ€§åœ¨ç½‘é¡µé‡Œæ˜¾ç¤ºå‡ºæ¥å‘¢ï¼Ÿæˆ‘ä»¬éœ€è¦åœ¨ä¸Šé¢è¯´çš„<code>about.ejs</code>è¿™ä¸ªæ–‡ä»¶é‡Œåšç›¸åº”çš„ä¿®æ”¹ã€‚</p><pre><code>&lt;div class=&quot;title&quot;&gt;&lt;%- config.author %&gt;&lt;/div&gt;&lt;div class=&quot;career&quot;&gt;&lt;%- theme.profile.career %&gt;&lt;/div&gt;&lt;div class=&quot;major&quot;&gt;&lt;%- theme.profile.major %&gt;&lt;/div&gt;&lt;div class=&quot;school&quot;&gt;&lt;%- theme.profile.school %&gt;&lt;/div&gt;</code></pre><p>åªè¦åŠ å‡ ä¸ª<code>div</code>å—å…ƒç´ ï¼Œå°±èƒ½æ˜¾ç¤ºä½ çš„å…¶ä»–ä¿¡æ¯ã€‚</p><h3 id="2-Postå°é¢å›¾ç‰‡çš„ä¿®æ”¹"><a href="#2-Postå°é¢å›¾ç‰‡çš„ä¿®æ”¹" class="headerlink" title="2. Postå°é¢å›¾ç‰‡çš„ä¿®æ”¹"></a>2. Postå°é¢å›¾ç‰‡çš„ä¿®æ”¹</h3><p>å…ˆæ‰¾åˆ°<code>/hexo-theme/matery/layout/_partial/post_cover.ejs</code>ä¸­çš„ä»£ç </p><pre class="line-numbers language-js"><code class="language-js"><span class="token keyword">if</span> <span class="token punctuation">(</span>page<span class="token punctuation">.</span>img<span class="token punctuation">)</span> <span class="token punctuation">{</span>    featureimg <span class="token operator">=</span> <span class="token function">url_for</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span>img<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// å¦‚æœè®¾ç½®äº†imgå±æ€§ï¼Œé‚£ä¹ˆå°é¢å›¾ç‰‡å°±æ˜¯ä½ è®¾ç½®çš„å›¾ç‰‡</span><span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> hashCode <span class="token operator">=</span> <span class="token keyword">function</span> <span class="token punctuation">(</span>str<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>str <span class="token operator">&amp;&amp;</span> str<span class="token punctuation">.</span>length <span class="token operator">===</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">var</span> hash <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">var</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> len <span class="token operator">=</span> str<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            hash <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>hash <span class="token operator">&lt;</span><span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">-</span> hash<span class="token punctuation">)</span> <span class="token operator">+</span> str<span class="token punctuation">.</span><span class="token function">charCodeAt</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>            hash <span class="token operator">|</span><span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> hash<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">;</span>    <span class="token keyword">var</span> len <span class="token operator">=</span> theme<span class="token punctuation">.</span>featureImages<span class="token punctuation">.</span>length<span class="token punctuation">;</span>    <span class="token keyword">var</span> num <span class="token operator">=</span> Math<span class="token punctuation">.</span><span class="token function">abs</span><span class="token punctuation">(</span><span class="token function">hashCode</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span>title<span class="token punctuation">)</span> <span class="token operator">%</span> len<span class="token punctuation">)</span><span class="token punctuation">;</span>    featureimg <span class="token operator">=</span> theme<span class="token punctuation">.</span>jsDelivr<span class="token punctuation">.</span>url            <span class="token operator">?</span> theme<span class="token punctuation">.</span>jsDelivr<span class="token punctuation">.</span>url <span class="token operator">+</span> <span class="token function">url_for</span><span class="token punctuation">(</span>theme<span class="token punctuation">.</span>featureImages<span class="token punctuation">[</span>num<span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token punctuation">:</span> <span class="token function">url_for</span><span class="token punctuation">(</span>theme<span class="token punctuation">.</span>featureImages<span class="token punctuation">[</span>num<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// å¦åˆ™å°†ä¼šé‡‡ç”¨ä½œè€…çš„ç®—æ³•ï¼Œæ ¹æ®titleçš„é•¿åº¦æ¥è®¡ç®—hashcodeï¼Œå†æ ¹æ®hashcodeä»é»˜è®¤çš„å›¾ç‰‡ä¸­é€‰å‡ºä¸€å¼ ã€‚å¦‚æœä¸¤ç¯‡æ–‡ç« çš„titleéƒ½æ˜¯å››ä¸ªå­—ï¼Œé‚£è¿™ä¸¤ç¯‡çš„å°é¢å°±æ˜¯åŒä¸€å¼ å›¾ç‰‡ã€‚</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>æ ¹æ®ä»£ç å¯çŸ¥ï¼Œæƒ³è¦ä¸€ç¯‡postç”¨ç‰¹å®šçš„å›¾ç‰‡ï¼Œå°±å¿…é¡»è®¾ç½®è¿™ç¯‡postçš„imgå±æ€§ã€‚å¦‚ä¸‹</p><img src="/2020/07/18/hexo-theme-matery%E4%B8%BB%E9%A2%98%E9%83%A8%E5%88%86%E4%BC%98%E5%8C%96/å±å¹•å¿«ç…§ 2020-07-20 ä¸‹åˆ2.41.07.png" style="zoom:50%;"><p>å¯å°†å›¾ç‰‡ç§»è‡³<code>hexo-theme-matery/source/medias/featureimages</code>ä¸‹ï¼Œå¹¶å°†imgå±æ€§è®¾ç½®ä¸º<code>/medias/featureimages/â€˜å›¾ç‰‡åâ€™</code>å³å¯ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ä¼˜åŒ– </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2020/07/16/hello-world/"/>
      <url>2020/07/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> åˆå§‹å†…å®¹ </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
